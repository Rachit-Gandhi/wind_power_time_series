{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('turbine1_df_final.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['# Date and time'] = pd.to_datetime(df['# Date and time'])\n",
    "# Perform cyclic encoding for month and hour\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['# Date and time'].dt.month / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['# Date and time'].dt.month / 12)\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['# Date and time'].dt.hour / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['# Date and time'].dt.hour / 24)\n",
    "\n",
    "# Drop the original 'Date and time' column\n",
    "df.drop('# Date and time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (78436, 66)\n",
      "Validation set shape: (26146, 66)\n",
      "Testing set shape: (26146, 66)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42, shuffle=False)\n",
    "\n",
    "# Print the shape of each split\n",
    "print('Training set shape:', train_df.shape)\n",
    "print('Validation set shape:', val_df.shape)\n",
    "print('Testing set shape:', test_df.shape)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=26146, step=1)\n"
     ]
    }
   ],
   "source": [
    "train_indices = train_df.index\n",
    "valid_indices = val_df.index\n",
    "test_indices = test_df.index\n",
    "print(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Power (kW)'\n",
    "features = [ col for col in train_df.columns if col not in target] \n",
    "\n",
    "X_train = train_df[features].values[train_indices]\n",
    "y_train = train_df[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "X_valid = val_df[features].values[valid_indices]\n",
    "y_valid = val_df[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "X_test = test_df[features].values[test_indices]\n",
    "y_test = test_df[target].values[test_indices].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 88 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "aug = RegressionSMOTE(p=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = TabNetRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.1118  | train_rmsle: 0.02869 | train_mae: 0.20705 | train_rmse: 0.23627 | train_mse: 0.05582 | valid_rmsle: 0.02827 | valid_mae: 0.20064 | valid_rmse: 0.22556 | valid_mse: 0.05088 |  0:00:04s\n",
      "epoch 1  | loss: 0.00654 | train_rmsle: 0.01661 | train_mae: 0.15329 | train_rmse: 0.19371 | train_mse: 0.03752 | valid_rmsle: 0.01447 | valid_mae: 0.14006 | valid_rmse: 0.17479 | valid_mse: 0.03055 |  0:00:09s\n",
      "epoch 2  | loss: 0.00445 | train_rmsle: 0.01014 | train_mae: 0.11991 | train_rmse: 0.14905 | train_mse: 0.02221 | valid_rmsle: 0.00939 | valid_mae: 0.11166 | valid_rmse: 0.13692 | valid_mse: 0.01875 |  0:00:13s\n",
      "epoch 3  | loss: 0.00417 | train_rmsle: 0.00658 | train_mae: 0.093   | train_rmse: 0.12689 | train_mse: 0.0161  | valid_rmsle: 0.00594 | valid_mae: 0.08595 | valid_rmse: 0.11543 | valid_mse: 0.01332 |  0:00:17s\n",
      "epoch 4  | loss: 0.00339 | train_rmsle: 0.00282 | train_mae: 0.06027 | train_rmse: 0.08143 | train_mse: 0.00663 | valid_rmsle: 0.00286 | valid_mae: 0.0574  | valid_rmse: 0.07695 | valid_mse: 0.00592 |  0:00:22s\n",
      "epoch 5  | loss: 0.00318 | train_rmsle: 0.00146 | train_mae: 0.0424  | train_rmse: 0.06041 | train_mse: 0.00365 | valid_rmsle: 0.00162 | valid_mae: 0.04122 | valid_rmse: 0.05938 | valid_mse: 0.00353 |  0:00:26s\n",
      "epoch 6  | loss: 0.00293 | train_rmsle: 0.00082 | train_mae: 0.03016 | train_rmse: 0.03998 | train_mse: 0.0016  | valid_rmsle: 0.00106 | valid_mae: 0.03213 | valid_rmse: 0.04317 | valid_mse: 0.00186 |  0:00:30s\n",
      "epoch 7  | loss: 0.00347 | train_rmsle: 0.00065 | train_mae: 0.02385 | train_rmse: 0.03633 | train_mse: 0.00132 | valid_rmsle: 0.00133 | valid_mae: 0.02929 | valid_rmse: 0.04807 | valid_mse: 0.00231 |  0:00:35s\n",
      "epoch 8  | loss: 0.00352 | train_rmsle: 0.00059 | train_mae: 0.02453 | train_rmse: 0.03595 | train_mse: 0.00129 | valid_rmsle: 0.00092 | valid_mae: 0.02652 | valid_rmse: 0.04136 | valid_mse: 0.00171 |  0:00:39s\n",
      "epoch 9  | loss: 0.0031  | train_rmsle: 0.00057 | train_mae: 0.02424 | train_rmse: 0.03324 | train_mse: 0.0011  | valid_rmsle: 0.0007  | valid_mae: 0.02514 | valid_rmse: 0.03526 | valid_mse: 0.00124 |  0:00:44s\n",
      "epoch 10 | loss: 0.00302 | train_rmsle: 0.00044 | train_mae: 0.02142 | train_rmse: 0.03077 | train_mse: 0.00095 | valid_rmsle: 0.00075 | valid_mae: 0.02403 | valid_rmse: 0.03739 | valid_mse: 0.0014  |  0:00:48s\n",
      "epoch 11 | loss: 0.00271 | train_rmsle: 0.00046 | train_mae: 0.02102 | train_rmse: 0.03105 | train_mse: 0.00096 | valid_rmsle: 0.00074 | valid_mae: 0.02426 | valid_rmse: 0.03652 | valid_mse: 0.00133 |  0:00:53s\n",
      "epoch 12 | loss: 0.00245 | train_rmsle: 0.00042 | train_mae: 0.02007 | train_rmse: 0.02974 | train_mse: 0.00088 | valid_rmsle: 0.00083 | valid_mae: 0.02326 | valid_rmse: 0.03718 | valid_mse: 0.00138 |  0:00:57s\n",
      "epoch 13 | loss: 0.0024  | train_rmsle: 0.00043 | train_mae: 0.02063 | train_rmse: 0.03128 | train_mse: 0.00098 | valid_rmsle: 0.00096 | valid_mae: 0.02402 | valid_rmse: 0.04111 | valid_mse: 0.00169 |  0:01:02s\n",
      "epoch 14 | loss: 0.00246 | train_rmsle: 0.00047 | train_mae: 0.02216 | train_rmse: 0.03378 | train_mse: 0.00114 | valid_rmsle: 0.00098 | valid_mae: 0.02543 | valid_rmse: 0.04325 | valid_mse: 0.00187 |  0:01:06s\n",
      "epoch 15 | loss: 0.00231 | train_rmsle: 0.00041 | train_mae: 0.01976 | train_rmse: 0.03025 | train_mse: 0.00091 | valid_rmsle: 0.00095 | valid_mae: 0.02436 | valid_rmse: 0.04163 | valid_mse: 0.00173 |  0:01:10s\n",
      "epoch 16 | loss: 0.00197 | train_rmsle: 0.00035 | train_mae: 0.01876 | train_rmse: 0.02848 | train_mse: 0.00081 | valid_rmsle: 0.00056 | valid_mae: 0.02312 | valid_rmse: 0.03507 | valid_mse: 0.00123 |  0:01:14s\n",
      "epoch 17 | loss: 0.00215 | train_rmsle: 0.00056 | train_mae: 0.02531 | train_rmse: 0.03464 | train_mse: 0.0012  | valid_rmsle: 0.00107 | valid_mae: 0.03278 | valid_rmse: 0.04635 | valid_mse: 0.00215 |  0:01:19s\n",
      "epoch 18 | loss: 0.00207 | train_rmsle: 0.00077 | train_mae: 0.03083 | train_rmse: 0.04605 | train_mse: 0.00212 | valid_rmsle: 0.0007  | valid_mae: 0.02843 | valid_rmse: 0.04089 | valid_mse: 0.00167 |  0:01:23s\n",
      "epoch 19 | loss: 0.00185 | train_rmsle: 0.00035 | train_mae: 0.01993 | train_rmse: 0.0298  | train_mse: 0.00089 | valid_rmsle: 0.00057 | valid_mae: 0.0228  | valid_rmse: 0.0342  | valid_mse: 0.00117 |  0:01:28s\n",
      "epoch 20 | loss: 0.00217 | train_rmsle: 0.00035 | train_mae: 0.02028 | train_rmse: 0.02846 | train_mse: 0.00081 | valid_rmsle: 0.00044 | valid_mae: 0.02163 | valid_rmse: 0.03205 | valid_mse: 0.00103 |  0:01:32s\n",
      "epoch 21 | loss: 0.00165 | train_rmsle: 0.00033 | train_mae: 0.01849 | train_rmse: 0.02629 | train_mse: 0.00069 | valid_rmsle: 0.00057 | valid_mae: 0.02322 | valid_rmse: 0.03631 | valid_mse: 0.00132 |  0:01:36s\n",
      "epoch 22 | loss: 0.00164 | train_rmsle: 0.00036 | train_mae: 0.01936 | train_rmse: 0.02674 | train_mse: 0.00072 | valid_rmsle: 0.00055 | valid_mae: 0.0235  | valid_rmse: 0.03553 | valid_mse: 0.00126 |  0:01:41s\n",
      "epoch 23 | loss: 0.00168 | train_rmsle: 0.00037 | train_mae: 0.01931 | train_rmse: 0.02743 | train_mse: 0.00075 | valid_rmsle: 0.00066 | valid_mae: 0.02494 | valid_rmse: 0.03957 | valid_mse: 0.00157 |  0:01:46s\n",
      "epoch 24 | loss: 0.00194 | train_rmsle: 0.0003  | train_mae: 0.01758 | train_rmse: 0.02501 | train_mse: 0.00063 | valid_rmsle: 0.00047 | valid_mae: 0.02187 | valid_rmse: 0.03193 | valid_mse: 0.00102 |  0:01:50s\n",
      "epoch 25 | loss: 0.00163 | train_rmsle: 0.00033 | train_mae: 0.01858 | train_rmse: 0.02561 | train_mse: 0.00066 | valid_rmsle: 0.00074 | valid_mae: 0.02466 | valid_rmse: 0.03845 | valid_mse: 0.00148 |  0:01:55s\n",
      "epoch 26 | loss: 0.0016  | train_rmsle: 0.00037 | train_mae: 0.02032 | train_rmse: 0.02957 | train_mse: 0.00087 | valid_rmsle: 0.00056 | valid_mae: 0.02181 | valid_rmse: 0.03349 | valid_mse: 0.00112 |  0:01:59s\n",
      "epoch 27 | loss: 0.00161 | train_rmsle: 0.0004  | train_mae: 0.02149 | train_rmse: 0.0312  | train_mse: 0.00097 | valid_rmsle: 0.00077 | valid_mae: 0.0238  | valid_rmse: 0.03712 | valid_mse: 0.00138 |  0:02:03s\n",
      "epoch 28 | loss: 0.00163 | train_rmsle: 0.00032 | train_mae: 0.0181  | train_rmse: 0.02654 | train_mse: 0.0007  | valid_rmsle: 0.00064 | valid_mae: 0.02408 | valid_rmse: 0.03675 | valid_mse: 0.00135 |  0:02:08s\n",
      "epoch 29 | loss: 0.00183 | train_rmsle: 0.00031 | train_mae: 0.01803 | train_rmse: 0.02703 | train_mse: 0.00073 | valid_rmsle: 0.00069 | valid_mae: 0.02425 | valid_rmse: 0.04073 | valid_mse: 0.00166 |  0:02:12s\n",
      "epoch 30 | loss: 0.00164 | train_rmsle: 0.00046 | train_mae: 0.01986 | train_rmse: 0.03    | train_mse: 0.0009  | valid_rmsle: 0.00076 | valid_mae: 0.02659 | valid_rmse: 0.04018 | valid_mse: 0.00161 |  0:02:17s\n",
      "epoch 31 | loss: 0.00156 | train_rmsle: 0.00029 | train_mae: 0.01732 | train_rmse: 0.02506 | train_mse: 0.00063 | valid_rmsle: 0.00054 | valid_mae: 0.02047 | valid_rmse: 0.03209 | valid_mse: 0.00103 |  0:02:21s\n",
      "epoch 32 | loss: 0.00163 | train_rmsle: 0.0004  | train_mae: 0.0211  | train_rmse: 0.03044 | train_mse: 0.00093 | valid_rmsle: 0.00059 | valid_mae: 0.0221  | valid_rmse: 0.03318 | valid_mse: 0.0011  |  0:02:25s\n",
      "epoch 33 | loss: 0.00145 | train_rmsle: 0.0003  | train_mae: 0.01812 | train_rmse: 0.02657 | train_mse: 0.00071 | valid_rmsle: 0.00057 | valid_mae: 0.0207  | valid_rmse: 0.03348 | valid_mse: 0.00112 |  0:02:30s\n",
      "epoch 34 | loss: 0.00166 | train_rmsle: 0.00032 | train_mae: 0.01837 | train_rmse: 0.02724 | train_mse: 0.00074 | valid_rmsle: 0.00043 | valid_mae: 0.01988 | valid_rmse: 0.03018 | valid_mse: 0.00091 |  0:02:34s\n",
      "epoch 35 | loss: 0.00159 | train_rmsle: 0.00034 | train_mae: 0.0193  | train_rmse: 0.02833 | train_mse: 0.0008  | valid_rmsle: 0.00036 | valid_mae: 0.01795 | valid_rmse: 0.0272  | valid_mse: 0.00074 |  0:02:38s\n",
      "epoch 36 | loss: 0.00133 | train_rmsle: 0.00038 | train_mae: 0.02014 | train_rmse: 0.0301  | train_mse: 0.00091 | valid_rmsle: 0.00064 | valid_mae: 0.02393 | valid_rmse: 0.03738 | valid_mse: 0.0014  |  0:02:42s\n",
      "epoch 37 | loss: 0.00136 | train_rmsle: 0.00027 | train_mae: 0.01539 | train_rmse: 0.02393 | train_mse: 0.00057 | valid_rmsle: 0.00116 | valid_mae: 0.02943 | valid_rmse: 0.05535 | valid_mse: 0.00306 |  0:02:47s\n",
      "epoch 38 | loss: 0.00123 | train_rmsle: 0.00034 | train_mae: 0.0184  | train_rmse: 0.0289  | train_mse: 0.00084 | valid_rmsle: 0.00172 | valid_mae: 0.03656 | valid_rmse: 0.06866 | valid_mse: 0.00471 |  0:02:51s\n",
      "epoch 39 | loss: 0.00128 | train_rmsle: 0.00079 | train_mae: 0.03091 | train_rmse: 0.04791 | train_mse: 0.0023  | valid_rmsle: 0.00141 | valid_mae: 0.03973 | valid_rmse: 0.05894 | valid_mse: 0.00347 |  0:02:55s\n",
      "epoch 40 | loss: 0.00158 | train_rmsle: 0.0005  | train_mae: 0.02177 | train_rmse: 0.03523 | train_mse: 0.00124 | valid_rmsle: 0.00164 | valid_mae: 0.0383  | valid_rmse: 0.06641 | valid_mse: 0.00441 |  0:03:00s\n",
      "epoch 41 | loss: 0.00171 | train_rmsle: 0.0005  | train_mae: 0.02074 | train_rmse: 0.03103 | train_mse: 0.00096 | valid_rmsle: 0.00071 | valid_mae: 0.0255  | valid_rmse: 0.03532 | valid_mse: 0.00125 |  0:03:04s\n",
      "epoch 42 | loss: 0.00165 | train_rmsle: 0.00045 | train_mae: 0.01847 | train_rmse: 0.02961 | train_mse: 0.00088 | valid_rmsle: 0.00058 | valid_mae: 0.02331 | valid_rmse: 0.03363 | valid_mse: 0.00113 |  0:03:09s\n",
      "epoch 43 | loss: 0.00159 | train_rmsle: 0.0004  | train_mae: 0.01915 | train_rmse: 0.02863 | train_mse: 0.00082 | valid_rmsle: 0.00211 | valid_mae: 0.03769 | valid_rmse: 0.07163 | valid_mse: 0.00513 |  0:03:13s\n",
      "epoch 44 | loss: 0.00156 | train_rmsle: 0.0005  | train_mae: 0.01991 | train_rmse: 0.03292 | train_mse: 0.00108 | valid_rmsle: 0.0059  | valid_mae: 0.07802 | valid_rmse: 0.1191  | valid_mse: 0.01418 |  0:03:18s\n",
      "epoch 45 | loss: 0.00181 | train_rmsle: 0.00035 | train_mae: 0.01757 | train_rmse: 0.02825 | train_mse: 0.0008  | valid_rmsle: 0.00078 | valid_mae: 0.0259  | valid_rmse: 0.03761 | valid_mse: 0.00141 |  0:03:22s\n",
      "epoch 46 | loss: 0.00171 | train_rmsle: 0.00037 | train_mae: 0.01653 | train_rmse: 0.0276  | train_mse: 0.00076 | valid_rmsle: 0.00044 | valid_mae: 0.01712 | valid_rmse: 0.02848 | valid_mse: 0.00081 |  0:03:27s\n",
      "epoch 47 | loss: 0.00159 | train_rmsle: 0.00059 | train_mae: 0.02546 | train_rmse: 0.04074 | train_mse: 0.00166 | valid_rmsle: 0.0007  | valid_mae: 0.02539 | valid_rmse: 0.03893 | valid_mse: 0.00152 |  0:03:32s\n",
      "epoch 48 | loss: 0.00158 | train_rmsle: 0.00026 | train_mae: 0.01586 | train_rmse: 0.02347 | train_mse: 0.00055 | valid_rmsle: 0.00031 | valid_mae: 0.01654 | valid_rmse: 0.0245  | valid_mse: 0.0006  |  0:03:36s\n",
      "epoch 49 | loss: 0.00148 | train_rmsle: 0.00031 | train_mae: 0.01814 | train_rmse: 0.02515 | train_mse: 0.00063 | valid_rmsle: 0.00049 | valid_mae: 0.02286 | valid_rmse: 0.03238 | valid_mse: 0.00105 |  0:03:41s\n",
      "epoch 50 | loss: 0.00211 | train_rmsle: 0.00078 | train_mae: 0.03033 | train_rmse: 0.04673 | train_mse: 0.00218 | valid_rmsle: 0.00087 | valid_mae: 0.03007 | valid_rmse: 0.04983 | valid_mse: 0.00248 |  0:03:46s\n",
      "epoch 51 | loss: 0.00184 | train_rmsle: 0.00037 | train_mae: 0.02045 | train_rmse: 0.03013 | train_mse: 0.00091 | valid_rmsle: 0.00047 | valid_mae: 0.02311 | valid_rmse: 0.03278 | valid_mse: 0.00107 |  0:03:51s\n",
      "epoch 52 | loss: 0.00154 | train_rmsle: 0.00028 | train_mae: 0.01763 | train_rmse: 0.02554 | train_mse: 0.00065 | valid_rmsle: 0.00115 | valid_mae: 0.03451 | valid_rmse: 0.05573 | valid_mse: 0.00311 |  0:03:56s\n",
      "epoch 53 | loss: 0.00155 | train_rmsle: 0.00039 | train_mae: 0.02146 | train_rmse: 0.02893 | train_mse: 0.00084 | valid_rmsle: 0.00101 | valid_mae: 0.03543 | valid_rmse: 0.04845 | valid_mse: 0.00235 |  0:04:00s\n",
      "epoch 54 | loss: 0.00152 | train_rmsle: 0.00036 | train_mae: 0.02057 | train_rmse: 0.02993 | train_mse: 0.0009  | valid_rmsle: 0.00104 | valid_mae: 0.03318 | valid_rmse: 0.05137 | valid_mse: 0.00264 |  0:04:05s\n",
      "epoch 55 | loss: 0.00136 | train_rmsle: 0.00032 | train_mae: 0.01908 | train_rmse: 0.02715 | train_mse: 0.00074 | valid_rmsle: 0.0012  | valid_mae: 0.03553 | valid_rmse: 0.05602 | valid_mse: 0.00314 |  0:04:10s\n",
      "epoch 56 | loss: 0.00156 | train_rmsle: 0.00044 | train_mae: 0.02311 | train_rmse: 0.03364 | train_mse: 0.00113 | valid_rmsle: 0.00101 | valid_mae: 0.03244 | valid_rmse: 0.05092 | valid_mse: 0.00259 |  0:04:14s\n",
      "epoch 57 | loss: 0.00138 | train_rmsle: 0.00029 | train_mae: 0.01768 | train_rmse: 0.02536 | train_mse: 0.00064 | valid_rmsle: 0.00082 | valid_mae: 0.02895 | valid_rmse: 0.04487 | valid_mse: 0.00201 |  0:04:19s\n",
      "epoch 58 | loss: 0.00141 | train_rmsle: 0.00029 | train_mae: 0.01783 | train_rmse: 0.02499 | train_mse: 0.00062 | valid_rmsle: 0.00112 | valid_mae: 0.03375 | valid_rmse: 0.05418 | valid_mse: 0.00294 |  0:04:24s\n",
      "epoch 59 | loss: 0.00134 | train_rmsle: 0.0005  | train_mae: 0.02392 | train_rmse: 0.03633 | train_mse: 0.00132 | valid_rmsle: 0.00145 | valid_mae: 0.03573 | valid_rmse: 0.06476 | valid_mse: 0.00419 |  0:04:28s\n",
      "epoch 60 | loss: 0.00138 | train_rmsle: 0.00031 | train_mae: 0.01748 | train_rmse: 0.0259  | train_mse: 0.00067 | valid_rmsle: 0.00114 | valid_mae: 0.03365 | valid_rmse: 0.05504 | valid_mse: 0.00303 |  0:04:33s\n",
      "epoch 61 | loss: 0.00141 | train_rmsle: 0.00043 | train_mae: 0.0219  | train_rmse: 0.03382 | train_mse: 0.00114 | valid_rmsle: 0.00188 | valid_mae: 0.03895 | valid_rmse: 0.07471 | valid_mse: 0.00558 |  0:04:37s\n",
      "epoch 62 | loss: 0.0013  | train_rmsle: 0.00037 | train_mae: 0.02037 | train_rmse: 0.02986 | train_mse: 0.00089 | valid_rmsle: 0.00182 | valid_mae: 0.0405  | valid_rmse: 0.07191 | valid_mse: 0.00517 |  0:04:42s\n",
      "epoch 63 | loss: 0.00135 | train_rmsle: 0.00032 | train_mae: 0.01879 | train_rmse: 0.02771 | train_mse: 0.00077 | valid_rmsle: 0.00175 | valid_mae: 0.0382  | valid_rmse: 0.07161 | valid_mse: 0.00513 |  0:04:47s\n",
      "epoch 64 | loss: 0.0013  | train_rmsle: 0.00034 | train_mae: 0.01905 | train_rmse: 0.02892 | train_mse: 0.00084 | valid_rmsle: 0.00163 | valid_mae: 0.0365  | valid_rmse: 0.06878 | valid_mse: 0.00473 |  0:04:51s\n",
      "epoch 65 | loss: 0.00137 | train_rmsle: 0.00029 | train_mae: 0.0169  | train_rmse: 0.02498 | train_mse: 0.00062 | valid_rmsle: 0.00174 | valid_mae: 0.03918 | valid_rmse: 0.07016 | valid_mse: 0.00492 |  0:04:56s\n",
      "epoch 66 | loss: 0.00133 | train_rmsle: 0.00037 | train_mae: 0.02092 | train_rmse: 0.02794 | train_mse: 0.00078 | valid_rmsle: 0.00203 | valid_mae: 0.04469 | valid_rmse: 0.07466 | valid_mse: 0.00557 |  0:05:01s\n",
      "epoch 67 | loss: 0.00135 | train_rmsle: 0.00029 | train_mae: 0.01782 | train_rmse: 0.02546 | train_mse: 0.00065 | valid_rmsle: 0.0017  | valid_mae: 0.03768 | valid_rmse: 0.07037 | valid_mse: 0.00495 |  0:05:06s\n",
      "epoch 68 | loss: 0.00149 | train_rmsle: 0.00046 | train_mae: 0.02359 | train_rmse: 0.03223 | train_mse: 0.00104 | valid_rmsle: 0.0018  | valid_mae: 0.04527 | valid_rmse: 0.06808 | valid_mse: 0.00463 |  0:05:11s\n",
      "epoch 69 | loss: 0.00138 | train_rmsle: 0.00025 | train_mae: 0.01628 | train_rmse: 0.02325 | train_mse: 0.00054 | valid_rmsle: 0.002   | valid_mae: 0.04101 | valid_rmse: 0.07588 | valid_mse: 0.00576 |  0:05:15s\n",
      "epoch 70 | loss: 0.00141 | train_rmsle: 0.00036 | train_mae: 0.02073 | train_rmse: 0.03026 | train_mse: 0.00092 | valid_rmsle: 0.00149 | valid_mae: 0.03526 | valid_rmse: 0.06584 | valid_mse: 0.00434 |  0:05:20s\n",
      "epoch 71 | loss: 0.00124 | train_rmsle: 0.00041 | train_mae: 0.02202 | train_rmse: 0.03166 | train_mse: 0.001   | valid_rmsle: 0.00107 | valid_mae: 0.03492 | valid_rmse: 0.05329 | valid_mse: 0.00284 |  0:05:24s\n",
      "epoch 72 | loss: 0.0013  | train_rmsle: 0.00039 | train_mae: 0.02159 | train_rmse: 0.03115 | train_mse: 0.00097 | valid_rmsle: 0.00073 | valid_mae: 0.02898 | valid_rmse: 0.0394  | valid_mse: 0.00155 |  0:05:28s\n",
      "epoch 73 | loss: 0.00117 | train_rmsle: 0.00029 | train_mae: 0.01762 | train_rmse: 0.0263  | train_mse: 0.00069 | valid_rmsle: 0.00061 | valid_mae: 0.02586 | valid_rmse: 0.03776 | valid_mse: 0.00143 |  0:05:33s\n",
      "epoch 74 | loss: 0.00132 | train_rmsle: 0.00063 | train_mae: 0.02821 | train_rmse: 0.04197 | train_mse: 0.00176 | valid_rmsle: 0.00036 | valid_mae: 0.01838 | valid_rmse: 0.0277  | valid_mse: 0.00077 |  0:05:37s\n",
      "epoch 75 | loss: 0.00119 | train_rmsle: 0.00031 | train_mae: 0.01867 | train_rmse: 0.0272  | train_mse: 0.00074 | valid_rmsle: 0.00052 | valid_mae: 0.02304 | valid_rmse: 0.03263 | valid_mse: 0.00106 |  0:05:42s\n",
      "epoch 76 | loss: 0.00115 | train_rmsle: 0.00036 | train_mae: 0.02017 | train_rmse: 0.03135 | train_mse: 0.00098 | valid_rmsle: 0.00043 | valid_mae: 0.01967 | valid_rmse: 0.02865 | valid_mse: 0.00082 |  0:05:46s\n",
      "epoch 77 | loss: 0.00114 | train_rmsle: 0.00033 | train_mae: 0.01933 | train_rmse: 0.02982 | train_mse: 0.00089 | valid_rmsle: 0.00043 | valid_mae: 0.0191  | valid_rmse: 0.02837 | valid_mse: 0.00081 |  0:05:50s\n",
      "epoch 78 | loss: 0.00113 | train_rmsle: 0.00033 | train_mae: 0.01928 | train_rmse: 0.02981 | train_mse: 0.00089 | valid_rmsle: 0.00045 | valid_mae: 0.01934 | valid_rmse: 0.02849 | valid_mse: 0.00081 |  0:05:54s\n",
      "epoch 79 | loss: 0.00116 | train_rmsle: 0.00029 | train_mae: 0.01768 | train_rmse: 0.026   | train_mse: 0.00068 | valid_rmsle: 0.00061 | valid_mae: 0.02337 | valid_rmse: 0.0331  | valid_mse: 0.0011  |  0:05:59s\n",
      "epoch 80 | loss: 0.00115 | train_rmsle: 0.00056 | train_mae: 0.02499 | train_rmse: 0.04024 | train_mse: 0.00162 | valid_rmsle: 0.00047 | valid_mae: 0.01939 | valid_rmse: 0.0305  | valid_mse: 0.00093 |  0:06:04s\n",
      "epoch 81 | loss: 0.00117 | train_rmsle: 0.00031 | train_mae: 0.01846 | train_rmse: 0.02863 | train_mse: 0.00082 | valid_rmsle: 0.00038 | valid_mae: 0.01751 | valid_rmse: 0.0262  | valid_mse: 0.00069 |  0:06:08s\n",
      "epoch 82 | loss: 0.00106 | train_rmsle: 0.00033 | train_mae: 0.01907 | train_rmse: 0.03003 | train_mse: 0.0009  | valid_rmsle: 0.00038 | valid_mae: 0.01723 | valid_rmse: 0.02656 | valid_mse: 0.00071 |  0:06:13s\n",
      "epoch 83 | loss: 0.00105 | train_rmsle: 0.00024 | train_mae: 0.01616 | train_rmse: 0.02462 | train_mse: 0.00061 | valid_rmsle: 0.00037 | valid_mae: 0.01762 | valid_rmse: 0.02657 | valid_mse: 0.00071 |  0:06:17s\n",
      "epoch 84 | loss: 0.00103 | train_rmsle: 0.00027 | train_mae: 0.01726 | train_rmse: 0.02719 | train_mse: 0.00074 | valid_rmsle: 0.00032 | valid_mae: 0.01664 | valid_rmse: 0.02482 | valid_mse: 0.00062 |  0:06:22s\n",
      "epoch 85 | loss: 0.00097 | train_rmsle: 0.00023 | train_mae: 0.01596 | train_rmse: 0.02366 | train_mse: 0.00056 | valid_rmsle: 0.00041 | valid_mae: 0.01917 | valid_rmse: 0.02756 | valid_mse: 0.00076 |  0:06:27s\n",
      "epoch 86 | loss: 0.00099 | train_rmsle: 0.00024 | train_mae: 0.01638 | train_rmse: 0.02355 | train_mse: 0.00055 | valid_rmsle: 0.00042 | valid_mae: 0.02025 | valid_rmse: 0.02757 | valid_mse: 0.00076 |  0:06:31s\n",
      "epoch 87 | loss: 0.00104 | train_rmsle: 0.0002  | train_mae: 0.014   | train_rmse: 0.02098 | train_mse: 0.00044 | valid_rmsle: 0.00048 | valid_mae: 0.02289 | valid_rmse: 0.03103 | valid_mse: 0.00096 |  0:06:36s\n",
      "Stop training because you reached max_epochs = 88 with best_epoch = 48 and best_valid_mse = 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    augmentations=aug, #aug\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006144237953447991\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.67166603e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.38574604e-07, 3.82012897e-01, 1.16176648e-02,\n",
       "       2.39334808e-02, 0.00000000e+00, 0.00000000e+00, 4.17375734e-09,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.42059838e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.49834382e-05, 0.00000000e+00,\n",
       "       4.57113793e-04, 1.45883143e-08, 4.99396924e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.54918424e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.72746892e-05, 2.46839358e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.72138085e-08, 7.02822592e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.40171297e-06, 5.67592326e-04, 6.74491259e-06,\n",
       "       8.90447374e-06, 1.84962220e-08, 0.00000000e+00, 2.45988729e-10,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.07040831e-06, 3.67809766e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.04863954e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.48183337e-05, 6.61311541e-04, 3.33579800e-03,\n",
       "       0.00000000e+00])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)\n",
    "from matplotlib import pyplot as plt\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.32395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-rmse:0.11461\n",
      "[20]\tvalidation_0-rmse:0.04277\n",
      "[30]\tvalidation_0-rmse:0.02010\n",
      "[40]\tvalidation_0-rmse:0.01466\n",
      "[50]\tvalidation_0-rmse:0.01361\n",
      "[60]\tvalidation_0-rmse:0.01340\n",
      "[70]\tvalidation_0-rmse:0.01335\n",
      "[80]\tvalidation_0-rmse:0.01333\n",
      "[90]\tvalidation_0-rmse:0.01331\n",
      "[100]\tvalidation_0-rmse:0.01329\n",
      "[110]\tvalidation_0-rmse:0.01329\n",
      "[120]\tvalidation_0-rmse:0.01329\n",
      "[130]\tvalidation_0-rmse:0.01331\n",
      "[138]\tvalidation_0-rmse:0.01330\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective='reg:linear', ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "clf_xgb = XGBRegressor(max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0,\n",
    "    silent=None,\n",
    "    objective='reg:linear',\n",
    "    booster='gbtree',\n",
    "    n_jobs=-1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=40,\n",
    "        verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00017644276280005152\n",
      "0.00014436806643773912\n"
     ]
    }
   ],
   "source": [
    "preds = np.array(clf_xgb.predict(X_valid))\n",
    "valid_auc = mean_squared_error(y_pred=preds, y_true=y_valid)\n",
    "print(valid_auc)\n",
    "\n",
    "preds = np.array(clf_xgb.predict(X_test))\n",
    "test_auc = mean_squared_error(y_pred=preds, y_true=y_test)\n",
    "print(test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./tabnet_model_test_1.zip\n"
     ]
    }
   ],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetRegressor()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST SCORE FOR dataset : 0.0006144237953447991\n"
     ]
    }
   ],
   "source": [
    "loaded_preds = loaded_clf.predict(X_test)\n",
    "loaded_test_mse = mean_squared_error(loaded_preds, y_test)\n",
    "\n",
    "print(f\"FINAL TEST SCORE FOR dataset : {loaded_test_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(test_score == loaded_test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

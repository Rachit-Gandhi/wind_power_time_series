{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('turbine1_df_final.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['# Date and time'] = pd.to_datetime(df['# Date and time'])\n",
    "# Perform cyclic encoding for month and hour\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['# Date and time'].dt.month / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['# Date and time'].dt.month / 12)\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['# Date and time'].dt.hour / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['# Date and time'].dt.hour / 24)\n",
    "\n",
    "# Drop the original 'Date and time' column\n",
    "df.drop('# Date and time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (78436, 66)\n",
      "Validation set shape: (26146, 66)\n",
      "Testing set shape: (26146, 66)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42, shuffle=False)\n",
    "\n",
    "# Print the shape of each split\n",
    "print('Training set shape:', train_df.shape)\n",
    "print('Validation set shape:', val_df.shape)\n",
    "print('Testing set shape:', test_df.shape)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=26146, step=1)\n"
     ]
    }
   ],
   "source": [
    "train_indices = train_df.index\n",
    "valid_indices = val_df.index\n",
    "test_indices = test_df.index\n",
    "print(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Power (kW)'\n",
    "features = [ col for col in train_df.columns if col not in target] \n",
    "\n",
    "X_train = train_df[features].values[train_indices]\n",
    "y_train = train_df[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "X_valid = val_df[features].values[valid_indices]\n",
    "y_valid = val_df[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "X_test = test_df[features].values[test_indices]\n",
    "y_test = test_df[target].values[test_indices].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 78 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "aug = RegressionSMOTE(p=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = TabNetRegressor(n_d=8, n_a=8, n_steps=8 ,gamma=1.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.20478 | train_rmsle: 0.03036 | train_mae: 0.18386 | train_rmse: 0.26408 | train_mse: 0.06974 | valid_rmsle: 0.02432 | valid_mae: 0.15791 | valid_rmse: 0.23569 | valid_mse: 0.05555 |  0:00:09s\n",
      "epoch 1  | loss: 0.08554 | train_rmsle: 0.02308 | train_mae: 0.17494 | train_rmse: 0.23031 | train_mse: 0.05304 | valid_rmsle: 0.02167 | valid_mae: 0.16731 | valid_rmse: 0.21721 | valid_mse: 0.04718 |  0:00:18s\n",
      "epoch 2  | loss: 0.01136 | train_rmsle: 0.01211 | train_mae: 0.12443 | train_rmse: 0.17439 | train_mse: 0.03041 | valid_rmsle: 0.01142 | valid_mae: 0.11899 | valid_rmse: 0.16261 | valid_mse: 0.02644 |  0:00:27s\n",
      "epoch 3  | loss: 0.00802 | train_rmsle: 0.00794 | train_mae: 0.10421 | train_rmse: 0.1367  | train_mse: 0.01869 | valid_rmsle: 0.0067  | valid_mae: 0.09422 | valid_rmse: 0.11982 | valid_mse: 0.01436 |  0:00:36s\n",
      "epoch 4  | loss: 0.00506 | train_rmsle: 0.00424 | train_mae: 0.07189 | train_rmse: 0.10037 | train_mse: 0.01007 | valid_rmsle: 0.00377 | valid_mae: 0.06658 | valid_rmse: 0.09049 | valid_mse: 0.00819 |  0:00:45s\n",
      "epoch 5  | loss: 0.00521 | train_rmsle: 0.00277 | train_mae: 0.05898 | train_rmse: 0.08461 | train_mse: 0.00716 | valid_rmsle: 0.0025  | valid_mae: 0.05446 | valid_rmse: 0.07784 | valid_mse: 0.00606 |  0:00:54s\n",
      "epoch 6  | loss: 0.00436 | train_rmsle: 0.00147 | train_mae: 0.0372  | train_rmse: 0.05356 | train_mse: 0.00287 | valid_rmsle: 0.00137 | valid_mae: 0.03522 | valid_rmse: 0.05142 | valid_mse: 0.00264 |  0:01:03s\n",
      "epoch 7  | loss: 0.00615 | train_rmsle: 0.00194 | train_mae: 0.03958 | train_rmse: 0.0643  | train_mse: 0.00413 | valid_rmsle: 0.00276 | valid_mae: 0.04911 | valid_rmse: 0.07144 | valid_mse: 0.0051  |  0:01:12s\n",
      "epoch 8  | loss: 0.0048  | train_rmsle: 0.00164 | train_mae: 0.03657 | train_rmse: 0.05904 | train_mse: 0.00349 | valid_rmsle: 0.00196 | valid_mae: 0.03902 | valid_rmse: 0.06006 | valid_mse: 0.00361 |  0:01:22s\n",
      "epoch 9  | loss: 0.00455 | train_rmsle: 0.0017  | train_mae: 0.03652 | train_rmse: 0.05702 | train_mse: 0.00325 | valid_rmsle: 0.00325 | valid_mae: 0.05815 | valid_rmse: 0.08244 | valid_mse: 0.0068  |  0:01:32s\n",
      "epoch 10 | loss: 0.0043  | train_rmsle: 0.00177 | train_mae: 0.04452 | train_rmse: 0.06545 | train_mse: 0.00428 | valid_rmsle: 0.00202 | valid_mae: 0.04491 | valid_rmse: 0.0669  | valid_mse: 0.00448 |  0:01:41s\n",
      "epoch 11 | loss: 0.004   | train_rmsle: 0.00128 | train_mae: 0.03101 | train_rmse: 0.04927 | train_mse: 0.00243 | valid_rmsle: 0.00195 | valid_mae: 0.03708 | valid_rmse: 0.05756 | valid_mse: 0.00331 |  0:01:51s\n",
      "epoch 12 | loss: 0.00394 | train_rmsle: 0.00106 | train_mae: 0.03204 | train_rmse: 0.04862 | train_mse: 0.00236 | valid_rmsle: 0.00133 | valid_mae: 0.03268 | valid_rmse: 0.04978 | valid_mse: 0.00248 |  0:02:01s\n",
      "epoch 13 | loss: 0.00413 | train_rmsle: 0.00109 | train_mae: 0.02958 | train_rmse: 0.04545 | train_mse: 0.00207 | valid_rmsle: 0.00175 | valid_mae: 0.03281 | valid_rmse: 0.05584 | valid_mse: 0.00312 |  0:02:11s\n",
      "epoch 14 | loss: 0.00377 | train_rmsle: 0.00111 | train_mae: 0.03142 | train_rmse: 0.04925 | train_mse: 0.00243 | valid_rmsle: 0.00231 | valid_mae: 0.03793 | valid_rmse: 0.06201 | valid_mse: 0.00385 |  0:02:20s\n",
      "epoch 15 | loss: 0.00388 | train_rmsle: 0.0014  | train_mae: 0.03057 | train_rmse: 0.05181 | train_mse: 0.00268 | valid_rmsle: 0.00254 | valid_mae: 0.03949 | valid_rmse: 0.06415 | valid_mse: 0.00411 |  0:02:30s\n",
      "epoch 16 | loss: 0.00366 | train_rmsle: 0.00122 | train_mae: 0.02867 | train_rmse: 0.04849 | train_mse: 0.00235 | valid_rmsle: 0.00236 | valid_mae: 0.03648 | valid_rmse: 0.06185 | valid_mse: 0.00383 |  0:02:39s\n",
      "epoch 17 | loss: 0.00361 | train_rmsle: 0.00138 | train_mae: 0.03064 | train_rmse: 0.05218 | train_mse: 0.00272 | valid_rmsle: 0.00231 | valid_mae: 0.04126 | valid_rmse: 0.06365 | valid_mse: 0.00405 |  0:02:49s\n",
      "epoch 18 | loss: 0.00339 | train_rmsle: 0.00119 | train_mae: 0.02937 | train_rmse: 0.04826 | train_mse: 0.00233 | valid_rmsle: 0.002   | valid_mae: 0.03844 | valid_rmse: 0.0608  | valid_mse: 0.0037  |  0:02:59s\n",
      "epoch 19 | loss: 0.00325 | train_rmsle: 0.00121 | train_mae: 0.03048 | train_rmse: 0.04995 | train_mse: 0.00249 | valid_rmsle: 0.0015  | valid_mae: 0.0298  | valid_rmse: 0.05097 | valid_mse: 0.0026  |  0:03:09s\n",
      "epoch 20 | loss: 0.00348 | train_rmsle: 0.00125 | train_mae: 0.02937 | train_rmse: 0.04963 | train_mse: 0.00246 | valid_rmsle: 0.00186 | valid_mae: 0.03534 | valid_rmse: 0.05743 | valid_mse: 0.0033  |  0:03:18s\n",
      "epoch 21 | loss: 0.00397 | train_rmsle: 0.00192 | train_mae: 0.03178 | train_rmse: 0.06104 | train_mse: 0.00373 | valid_rmsle: 0.00209 | valid_mae: 0.03589 | valid_rmse: 0.06215 | valid_mse: 0.00386 |  0:03:27s\n",
      "epoch 22 | loss: 0.00473 | train_rmsle: 0.00123 | train_mae: 0.03013 | train_rmse: 0.0484  | train_mse: 0.00234 | valid_rmsle: 0.00154 | valid_mae: 0.03213 | valid_rmse: 0.05169 | valid_mse: 0.00267 |  0:03:36s\n",
      "epoch 23 | loss: 0.0036  | train_rmsle: 0.00115 | train_mae: 0.02972 | train_rmse: 0.04616 | train_mse: 0.00213 | valid_rmsle: 0.00174 | valid_mae: 0.03463 | valid_rmse: 0.05355 | valid_mse: 0.00287 |  0:03:45s\n",
      "epoch 24 | loss: 0.00343 | train_rmsle: 0.00147 | train_mae: 0.03095 | train_rmse: 0.05003 | train_mse: 0.0025  | valid_rmsle: 0.00201 | valid_mae: 0.03763 | valid_rmse: 0.05742 | valid_mse: 0.0033  |  0:03:54s\n",
      "epoch 25 | loss: 0.00372 | train_rmsle: 0.00109 | train_mae: 0.02784 | train_rmse: 0.0459  | train_mse: 0.00211 | valid_rmsle: 0.0014  | valid_mae: 0.02948 | valid_rmse: 0.04934 | valid_mse: 0.00243 |  0:04:03s\n",
      "epoch 26 | loss: 0.00358 | train_rmsle: 0.00112 | train_mae: 0.02802 | train_rmse: 0.04513 | train_mse: 0.00204 | valid_rmsle: 0.0017  | valid_mae: 0.03473 | valid_rmse: 0.05223 | valid_mse: 0.00273 |  0:04:12s\n",
      "epoch 27 | loss: 0.00339 | train_rmsle: 0.00103 | train_mae: 0.02745 | train_rmse: 0.04365 | train_mse: 0.00191 | valid_rmsle: 0.00143 | valid_mae: 0.03082 | valid_rmse: 0.04821 | valid_mse: 0.00232 |  0:04:20s\n",
      "epoch 28 | loss: 0.00338 | train_rmsle: 0.00109 | train_mae: 0.03099 | train_rmse: 0.04792 | train_mse: 0.0023  | valid_rmsle: 0.00121 | valid_mae: 0.03086 | valid_rmse: 0.04765 | valid_mse: 0.00227 |  0:04:29s\n",
      "epoch 29 | loss: 0.00331 | train_rmsle: 0.00115 | train_mae: 0.03412 | train_rmse: 0.05044 | train_mse: 0.00254 | valid_rmsle: 0.00112 | valid_mae: 0.03188 | valid_rmse: 0.0476  | valid_mse: 0.00227 |  0:04:38s\n",
      "epoch 30 | loss: 0.00291 | train_rmsle: 0.00081 | train_mae: 0.02457 | train_rmse: 0.03925 | train_mse: 0.00154 | valid_rmsle: 0.00092 | valid_mae: 0.02504 | valid_rmse: 0.04014 | valid_mse: 0.00161 |  0:04:47s\n",
      "epoch 31 | loss: 0.00282 | train_rmsle: 0.00084 | train_mae: 0.02809 | train_rmse: 0.04163 | train_mse: 0.00173 | valid_rmsle: 0.001   | valid_mae: 0.02844 | valid_rmse: 0.04247 | valid_mse: 0.0018  |  0:04:56s\n",
      "epoch 32 | loss: 0.00306 | train_rmsle: 0.00091 | train_mae: 0.03489 | train_rmse: 0.05059 | train_mse: 0.00256 | valid_rmsle: 0.00094 | valid_mae: 0.03128 | valid_rmse: 0.04638 | valid_mse: 0.00215 |  0:05:05s\n",
      "epoch 33 | loss: 0.00295 | train_rmsle: 0.00125 | train_mae: 0.03578 | train_rmse: 0.0514  | train_mse: 0.00264 | valid_rmsle: 0.00154 | valid_mae: 0.03835 | valid_rmse: 0.05416 | valid_mse: 0.00293 |  0:05:14s\n",
      "epoch 34 | loss: 0.00346 | train_rmsle: 0.00102 | train_mae: 0.02717 | train_rmse: 0.04321 | train_mse: 0.00187 | valid_rmsle: 0.00138 | valid_mae: 0.0314  | valid_rmse: 0.04741 | valid_mse: 0.00225 |  0:05:22s\n",
      "epoch 35 | loss: 0.00294 | train_rmsle: 0.00098 | train_mae: 0.02871 | train_rmse: 0.04453 | train_mse: 0.00198 | valid_rmsle: 0.00112 | valid_mae: 0.02912 | valid_rmse: 0.04533 | valid_mse: 0.00205 |  0:05:31s\n",
      "epoch 36 | loss: 0.00296 | train_rmsle: 0.00097 | train_mae: 0.02676 | train_rmse: 0.04196 | train_mse: 0.00176 | valid_rmsle: 0.00145 | valid_mae: 0.03267 | valid_rmse: 0.04875 | valid_mse: 0.00238 |  0:05:39s\n",
      "epoch 37 | loss: 0.00294 | train_rmsle: 0.00084 | train_mae: 0.04361 | train_rmse: 0.08652 | train_mse: 0.00748 | valid_rmsle: 0.00102 | valid_mae: 0.03463 | valid_rmse: 0.06719 | valid_mse: 0.00451 |  0:05:48s\n",
      "epoch 38 | loss: 0.00327 | train_rmsle: 0.00098 | train_mae: 0.02642 | train_rmse: 0.04374 | train_mse: 0.00191 | valid_rmsle: 0.00135 | valid_mae: 0.02849 | valid_rmse: 0.04863 | valid_mse: 0.00236 |  0:05:56s\n",
      "epoch 39 | loss: 0.00442 | train_rmsle: 0.00257 | train_mae: 0.04732 | train_rmse: 0.06835 | train_mse: 0.00467 | valid_rmsle: 0.00312 | valid_mae: 0.05044 | valid_rmse: 0.07311 | valid_mse: 0.00535 |  0:06:05s\n",
      "epoch 40 | loss: 0.00453 | train_rmsle: 0.0015  | train_mae: 0.03536 | train_rmse: 0.05454 | train_mse: 0.00297 | valid_rmsle: 0.00152 | valid_mae: 0.03269 | valid_rmse: 0.05383 | valid_mse: 0.0029  |  0:06:14s\n",
      "epoch 41 | loss: 0.00395 | train_rmsle: 0.00144 | train_mae: 0.0319  | train_rmse: 0.05007 | train_mse: 0.00251 | valid_rmsle: 0.00226 | valid_mae: 0.04171 | valid_rmse: 0.05993 | valid_mse: 0.00359 |  0:06:23s\n",
      "epoch 42 | loss: 0.00421 | train_rmsle: 0.00178 | train_mae: 0.04143 | train_rmse: 0.05942 | train_mse: 0.00353 | valid_rmsle: 0.00193 | valid_mae: 0.03978 | valid_rmse: 0.05901 | valid_mse: 0.00348 |  0:06:31s\n",
      "epoch 43 | loss: 0.00409 | train_rmsle: 0.00145 | train_mae: 0.03411 | train_rmse: 0.04995 | train_mse: 0.0025  | valid_rmsle: 0.00179 | valid_mae: 0.03587 | valid_rmse: 0.05316 | valid_mse: 0.00283 |  0:06:40s\n",
      "epoch 44 | loss: 0.00409 | train_rmsle: 0.00132 | train_mae: 0.03377 | train_rmse: 0.04879 | train_mse: 0.00238 | valid_rmsle: 0.00147 | valid_mae: 0.03512 | valid_rmse: 0.05266 | valid_mse: 0.00277 |  0:06:49s\n",
      "epoch 45 | loss: 0.00379 | train_rmsle: 0.00131 | train_mae: 0.0302  | train_rmse: 0.04778 | train_mse: 0.00228 | valid_rmsle: 0.0014  | valid_mae: 0.02903 | valid_rmse: 0.04935 | valid_mse: 0.00243 |  0:06:58s\n",
      "epoch 46 | loss: 0.00363 | train_rmsle: 0.00144 | train_mae: 0.03684 | train_rmse: 0.05527 | train_mse: 0.00305 | valid_rmsle: 0.00144 | valid_mae: 0.03451 | valid_rmse: 0.0534  | valid_mse: 0.00285 |  0:07:06s\n",
      "epoch 47 | loss: 0.00333 | train_rmsle: 0.00126 | train_mae: 0.03494 | train_rmse: 0.0508  | train_mse: 0.00258 | valid_rmsle: 0.00147 | valid_mae: 0.03404 | valid_rmse: 0.05168 | valid_mse: 0.00267 |  0:07:15s\n",
      "epoch 48 | loss: 0.00321 | train_rmsle: 0.00121 | train_mae: 0.02992 | train_rmse: 0.04644 | train_mse: 0.00216 | valid_rmsle: 0.00157 | valid_mae: 0.03271 | valid_rmse: 0.05079 | valid_mse: 0.00258 |  0:07:25s\n",
      "epoch 49 | loss: 0.00328 | train_rmsle: 0.00127 | train_mae: 0.03275 | train_rmse: 0.04878 | train_mse: 0.00238 | valid_rmsle: 0.00198 | valid_mae: 0.0359  | valid_rmse: 0.05776 | valid_mse: 0.00334 |  0:07:34s\n",
      "epoch 50 | loss: 0.00319 | train_rmsle: 0.00101 | train_mae: 0.02736 | train_rmse: 0.04351 | train_mse: 0.00189 | valid_rmsle: 0.00131 | valid_mae: 0.02865 | valid_rmse: 0.04743 | valid_mse: 0.00225 |  0:07:42s\n",
      "epoch 51 | loss: 0.00295 | train_rmsle: 0.00105 | train_mae: 0.02819 | train_rmse: 0.0444  | train_mse: 0.00197 | valid_rmsle: 0.00136 | valid_mae: 0.02978 | valid_rmse: 0.0485  | valid_mse: 0.00235 |  0:07:51s\n",
      "epoch 52 | loss: 0.003   | train_rmsle: 0.0011  | train_mae: 0.0302  | train_rmse: 0.04667 | train_mse: 0.00218 | valid_rmsle: 0.00119 | valid_mae: 0.02935 | valid_rmse: 0.0463  | valid_mse: 0.00214 |  0:08:00s\n",
      "epoch 53 | loss: 0.00328 | train_rmsle: 0.00103 | train_mae: 0.02771 | train_rmse: 0.04402 | train_mse: 0.00194 | valid_rmsle: 0.00111 | valid_mae: 0.02591 | valid_rmse: 0.04407 | valid_mse: 0.00194 |  0:08:09s\n",
      "epoch 54 | loss: 0.00298 | train_rmsle: 0.00099 | train_mae: 0.02616 | train_rmse: 0.04277 | train_mse: 0.00183 | valid_rmsle: 0.0011  | valid_mae: 0.02596 | valid_rmse: 0.04327 | valid_mse: 0.00187 |  0:08:18s\n",
      "epoch 55 | loss: 0.00342 | train_rmsle: 0.00132 | train_mae: 0.03346 | train_rmse: 0.04957 | train_mse: 0.00246 | valid_rmsle: 0.00133 | valid_mae: 0.03103 | valid_rmse: 0.04885 | valid_mse: 0.00239 |  0:08:27s\n",
      "epoch 56 | loss: 0.0036  | train_rmsle: 0.00115 | train_mae: 0.02759 | train_rmse: 0.04614 | train_mse: 0.00213 | valid_rmsle: 0.00122 | valid_mae: 0.02738 | valid_rmse: 0.04608 | valid_mse: 0.00212 |  0:08:35s\n",
      "epoch 57 | loss: 0.00359 | train_rmsle: 0.00163 | train_mae: 0.03934 | train_rmse: 0.05746 | train_mse: 0.0033  | valid_rmsle: 0.00181 | valid_mae: 0.03853 | valid_rmse: 0.05974 | valid_mse: 0.00357 |  0:08:43s\n",
      "epoch 58 | loss: 0.00335 | train_rmsle: 0.00115 | train_mae: 0.03064 | train_rmse: 0.04827 | train_mse: 0.00233 | valid_rmsle: 0.00115 | valid_mae: 0.02735 | valid_rmse: 0.04666 | valid_mse: 0.00218 |  0:08:52s\n",
      "epoch 59 | loss: 0.00356 | train_rmsle: 0.00103 | train_mae: 0.02765 | train_rmse: 0.0446  | train_mse: 0.00199 | valid_rmsle: 0.00145 | valid_mae: 0.03206 | valid_rmse: 0.04976 | valid_mse: 0.00248 |  0:09:01s\n",
      "epoch 60 | loss: 0.00315 | train_rmsle: 0.00108 | train_mae: 0.02841 | train_rmse: 0.0449  | train_mse: 0.00202 | valid_rmsle: 0.00162 | valid_mae: 0.03478 | valid_rmse: 0.05263 | valid_mse: 0.00277 |  0:09:10s\n",
      "epoch 61 | loss: 0.00327 | train_rmsle: 0.00103 | train_mae: 0.02704 | train_rmse: 0.04374 | train_mse: 0.00191 | valid_rmsle: 0.00157 | valid_mae: 0.03534 | valid_rmse: 0.05194 | valid_mse: 0.0027  |  0:09:19s\n",
      "epoch 62 | loss: 0.00318 | train_rmsle: 0.00091 | train_mae: 0.026   | train_rmse: 0.04237 | train_mse: 0.0018  | valid_rmsle: 0.00126 | valid_mae: 0.0329  | valid_rmse: 0.0483  | valid_mse: 0.00233 |  0:09:27s\n",
      "epoch 63 | loss: 0.00283 | train_rmsle: 0.00113 | train_mae: 0.03552 | train_rmse: 0.0529  | train_mse: 0.0028  | valid_rmsle: 0.00154 | valid_mae: 0.03891 | valid_rmse: 0.0558  | valid_mse: 0.00311 |  0:09:35s\n",
      "epoch 64 | loss: 0.00269 | train_rmsle: 0.00088 | train_mae: 0.02692 | train_rmse: 0.04327 | train_mse: 0.00187 | valid_rmsle: 0.00127 | valid_mae: 0.03283 | valid_rmse: 0.04751 | valid_mse: 0.00226 |  0:09:44s\n",
      "epoch 65 | loss: 0.00306 | train_rmsle: 0.0009  | train_mae: 0.02656 | train_rmse: 0.04237 | train_mse: 0.0018  | valid_rmsle: 0.0012  | valid_mae: 0.03075 | valid_rmse: 0.04628 | valid_mse: 0.00214 |  0:09:52s\n",
      "epoch 66 | loss: 0.00293 | train_rmsle: 0.00129 | train_mae: 0.03076 | train_rmse: 0.04902 | train_mse: 0.0024  | valid_rmsle: 0.00184 | valid_mae: 0.03257 | valid_rmse: 0.05511 | valid_mse: 0.00304 |  0:10:01s\n",
      "epoch 67 | loss: 0.00292 | train_rmsle: 0.00101 | train_mae: 0.02777 | train_rmse: 0.04344 | train_mse: 0.00189 | valid_rmsle: 0.00122 | valid_mae: 0.03028 | valid_rmse: 0.04663 | valid_mse: 0.00217 |  0:10:10s\n",
      "epoch 68 | loss: 0.00303 | train_rmsle: 0.00089 | train_mae: 0.02539 | train_rmse: 0.04118 | train_mse: 0.0017  | valid_rmsle: 0.00107 | valid_mae: 0.02753 | valid_rmse: 0.04318 | valid_mse: 0.00186 |  0:10:18s\n",
      "epoch 69 | loss: 0.00275 | train_rmsle: 0.00085 | train_mae: 0.02494 | train_rmse: 0.04118 | train_mse: 0.0017  | valid_rmsle: 0.00108 | valid_mae: 0.02643 | valid_rmse: 0.04371 | valid_mse: 0.00191 |  0:10:26s\n",
      "epoch 70 | loss: 0.00316 | train_rmsle: 0.00088 | train_mae: 0.02612 | train_rmse: 0.04166 | train_mse: 0.00174 | valid_rmsle: 0.00116 | valid_mae: 0.02799 | valid_rmse: 0.04524 | valid_mse: 0.00205 |  0:10:35s\n",
      "epoch 71 | loss: 0.00276 | train_rmsle: 0.00093 | train_mae: 0.02611 | train_rmse: 0.04153 | train_mse: 0.00173 | valid_rmsle: 0.00139 | valid_mae: 0.0319  | valid_rmse: 0.04946 | valid_mse: 0.00245 |  0:10:43s\n",
      "epoch 72 | loss: 0.00286 | train_rmsle: 0.00087 | train_mae: 0.02644 | train_rmse: 0.04162 | train_mse: 0.00173 | valid_rmsle: 0.00121 | valid_mae: 0.02875 | valid_rmse: 0.04563 | valid_mse: 0.00208 |  0:10:52s\n",
      "epoch 73 | loss: 0.00277 | train_rmsle: 0.00147 | train_mae: 0.04112 | train_rmse: 0.06008 | train_mse: 0.00361 | valid_rmsle: 0.00122 | valid_mae: 0.03395 | valid_rmse: 0.0523  | valid_mse: 0.00274 |  0:11:02s\n",
      "epoch 74 | loss: 0.00468 | train_rmsle: 0.00122 | train_mae: 0.02909 | train_rmse: 0.04713 | train_mse: 0.00222 | valid_rmsle: 0.00136 | valid_mae: 0.02793 | valid_rmse: 0.04863 | valid_mse: 0.00236 |  0:11:11s\n",
      "epoch 75 | loss: 0.00339 | train_rmsle: 0.00115 | train_mae: 0.02795 | train_rmse: 0.0468  | train_mse: 0.00219 | valid_rmsle: 0.0014  | valid_mae: 0.0289  | valid_rmse: 0.05003 | valid_mse: 0.0025  |  0:11:21s\n",
      "epoch 76 | loss: 0.00323 | train_rmsle: 0.00146 | train_mae: 0.03101 | train_rmse: 0.0501  | train_mse: 0.00251 | valid_rmsle: 0.0016  | valid_mae: 0.03094 | valid_rmse: 0.05126 | valid_mse: 0.00263 |  0:11:30s\n",
      "epoch 77 | loss: 0.00389 | train_rmsle: 0.00127 | train_mae: 0.03235 | train_rmse: 0.05039 | train_mse: 0.00254 | valid_rmsle: 0.00168 | valid_mae: 0.03611 | valid_rmse: 0.05385 | valid_mse: 0.0029  |  0:11:40s\n",
      "Stop training because you reached max_epochs = 78 with best_epoch = 30 and best_valid_mse = 0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    augmentations=aug, #aug\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001514971264552074\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.11538277e-01, 5.61873123e-04, 0.00000000e+00, 2.30704271e-06,\n",
       "       3.65581559e-02, 1.51229659e-03, 1.59573464e-02, 6.03671300e-09,\n",
       "       9.48644367e-03, 4.06848345e-03, 1.95566726e-06, 0.00000000e+00,\n",
       "       3.92683522e-05, 1.18312802e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       9.04124124e-04, 6.91296694e-05, 2.57246995e-03, 3.79340176e-07,\n",
       "       0.00000000e+00, 2.66246792e-02, 1.33457175e-02, 6.78236030e-06,\n",
       "       2.85064048e-02, 7.52098159e-02, 1.57747589e-06, 1.35335202e-03,\n",
       "       3.63407463e-05, 0.00000000e+00, 6.57914394e-04, 1.02729179e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.83213783e-05, 1.80172395e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.88470624e-04, 2.77432353e-05,\n",
       "       4.42888905e-02, 0.00000000e+00, 4.79084817e-02, 1.02780849e-04,\n",
       "       9.07929600e-07, 8.18123042e-04, 0.00000000e+00, 2.34352022e-02,\n",
       "       1.07498522e-03, 1.71025742e-02, 1.40700601e-02, 0.00000000e+00,\n",
       "       3.65063998e-06, 0.00000000e+00, 2.61146865e-05, 0.00000000e+00,\n",
       "       3.82690807e-04, 4.92887491e-05, 0.00000000e+00, 1.17219235e-03,\n",
       "       0.00000000e+00, 3.92066610e-04, 0.00000000e+00, 1.68408566e-02,\n",
       "       3.63724130e-05])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)\n",
    "from matplotlib import pyplot as plt\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.32395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-rmse:0.11461\n",
      "[20]\tvalidation_0-rmse:0.04277\n",
      "[30]\tvalidation_0-rmse:0.02010\n",
      "[40]\tvalidation_0-rmse:0.01466\n",
      "[50]\tvalidation_0-rmse:0.01361\n",
      "[60]\tvalidation_0-rmse:0.01340\n",
      "[70]\tvalidation_0-rmse:0.01335\n",
      "[80]\tvalidation_0-rmse:0.01333\n",
      "[90]\tvalidation_0-rmse:0.01331\n",
      "[100]\tvalidation_0-rmse:0.01329\n",
      "[110]\tvalidation_0-rmse:0.01329\n",
      "[120]\tvalidation_0-rmse:0.01329\n",
      "[130]\tvalidation_0-rmse:0.01331\n",
      "[138]\tvalidation_0-rmse:0.01330\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=0,\n",
       "             max_depth=8, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
       "             nthread=None, num_parallel_tree=None, objective='reg:linear', ...)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "clf_xgb = XGBRegressor(max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0,\n",
    "    silent=None,\n",
    "    objective='reg:linear',\n",
    "    booster='gbtree',\n",
    "    n_jobs=-1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=40,\n",
    "        verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00017644276280005152\n",
      "0.00014436806643773912\n"
     ]
    }
   ],
   "source": [
    "preds = np.array(clf_xgb.predict(X_valid))\n",
    "valid_auc = mean_squared_error(y_pred=preds, y_true=y_valid)\n",
    "print(valid_auc)\n",
    "\n",
    "preds = np.array(clf_xgb.predict(X_test))\n",
    "test_auc = mean_squared_error(y_pred=preds, y_true=y_test)\n",
    "print(test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./tabnet_model_test_1.zip\n"
     ]
    }
   ],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetRegressor()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST SCORE FOR dataset : 0.001514971264552074\n"
     ]
    }
   ],
   "source": [
    "loaded_preds = loaded_clf.predict(X_test)\n",
    "loaded_test_mse = mean_squared_error(loaded_preds, y_test)\n",
    "\n",
    "print(f\"FINAL TEST SCORE FOR dataset : {loaded_test_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(test_score == loaded_test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

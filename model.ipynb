{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime, timedelta \n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from itertools import cycle\n",
    "import datetime as dt\n",
    "\n",
    "# matplotlib 설정\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_weights = [3.78227234e-02, 5.35090003e-05, 1.02894781e-04, 1.49786865e-04,\n",
    " 1.04764847e-04, 1.63700344e-04, 7.86159754e-01, 1.66692644e-01,\n",
    " 1.62399039e-04, 1.36344403e-04, 1.23864607e-04, 3.25831398e-03,\n",
    " 1.11413574e-04, 1.12267953e-04, 1.12513058e-04, 1.15435665e-04,\n",
    " 9.74491413e-05, 7.48724633e-05, 7.42438278e-05, 8.17979526e-05,\n",
    " 9.10188464e-05, 8.10626516e-05, 1.62408571e-04, 9.22517429e-05,\n",
    " 6.92411995e-05, 6.06398789e-05, 6.15876997e-05, 2.05707460e-04,\n",
    " 9.76096126e-05, 9.17855941e-05, 7.44235294e-05, 8.87563365e-05,\n",
    " 7.44791614e-05, 6.22049338e-05, 6.85490304e-05, 6.57211494e-05,\n",
    " 6.70680165e-05, 1.42811637e-04, 9.89059918e-05, 9.52478367e-05,\n",
    " 1.08733664e-04, 8.95528574e-05, 1.07477274e-04, 1.15086681e-04,\n",
    " 8.60139335e-05, 7.83390569e-05, 6.42610321e-05, 1.03312457e-04,\n",
    " 9.24527631e-05, 8.45081231e-05, 7.72333588e-05, 8.96328202e-05,\n",
    " 2.81332632e-05, 2.14036554e-04, 3.18860257e-05, 3.27980561e-05,\n",
    " 5.04529162e-05, 2.01942370e-04, 7.67721576e-05, 5.93836303e-05,\n",
    " 6.03012268e-05, 2.65900104e-04, 1.67839185e-04, 8.06350436e-05,\n",
    " 7.12153196e-05]\n",
    "\n",
    "tabnet_weights = [4.26892227e-06, 0.00000000e+00, 0.00000000e+00, 3.00723057e-02,\n",
    "0.00000000e+00, 1.81987064e-06, 1.37099386e-01, 3.07597264e-01,\n",
    "1.17412334e-05, 0.00000000e+00, 0.00000000e+00, 7.68810592e-02,\n",
    "6.31930090e-04, 8.53033960e-03, 1.69922775e-02, 8.09343194e-03,\n",
    "1.85524606e-08, 0.00000000e+00, 5.99931009e-03, 0.00000000e+00,\n",
    "0.00000000e+00, 0.00000000e+00, 7.60999255e-05, 1.14790590e-06,\n",
    "1.17366399e-01, 1.14198997e-02, 0.00000000e+00, 3.89959469e-06,\n",
    "0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.32325158e-05,\n",
    "0.00000000e+00, 6.57038847e-05, 1.35262607e-02, 2.21752146e-05,\n",
    "0.00000000e+00, 6.23984265e-02, 8.66896181e-03, 0.00000000e+00,\n",
    "2.79329075e-03, 1.93734536e-06, 9.73141818e-04, 0.00000000e+00,\n",
    "2.06456979e-06, 5.23236864e-02, 1.94160263e-02, 4.95664089e-03,\n",
    "8.15198301e-04, 4.23687933e-02, 4.42582323e-03, 1.96317046e-02,\n",
    "0.00000000e+00, 2.24109549e-03, 0.00000000e+00, 3.52501762e-03,\n",
    "4.90427532e-03, 0.00000000e+00, 2.95825462e-03, 0.00000000e+00,\n",
    "4.75344631e-03, 5.37095814e-03, 0.00000000e+00, 8.05441066e-04,\n",
    "2.21958440e-02]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train.pkl')\n",
    "test = pd.read_pickle('test.pkl')\n",
    "val = pd.read_pickle('val.pkl')\n",
    "\n",
    "# Create a dictionary to map feature names to tabnet_weights\n",
    "tabnet_weight_dict_train = {col: weight for col, weight in zip(train.columns, tabnet_weights)}\n",
    "tabnet_weight_dict_test = {col: weight for col, weight in zip(test.columns, tabnet_weights)}\n",
    "tabnet_weight_dict_val = {col: weight for col, weight in zip(val.columns, tabnet_weights)}\n",
    "\n",
    "# Apply tabnet_weights to train, test, and val DataFrames\n",
    "tabnet_train = train * pd.Series(tabnet_weight_dict_train)\n",
    "tabnet_test = test * pd.Series(tabnet_weight_dict_test)\n",
    "tabnet_val = val * pd.Series(tabnet_weight_dict_val)\n",
    "\n",
    "#Now to do same for xgb\n",
    "# Create a dictionary to map feature names to tabnet_weights\n",
    "xgb_weight_dict_train = {col: weight for col, weight in zip(train.columns, xgb_weights)}\n",
    "xgb_weight_dict_test = {col: weight for col, weight in zip(test.columns, xgb_weights)}\n",
    "xgb_weight_dict_val = {col: weight for col, weight in zip(val.columns, xgb_weights)}\n",
    "\n",
    "#xgb_weights to train, test, and val DataFrames\n",
    "xgb_train = train * pd.Series(xgb_weight_dict_train)\n",
    "xgb_test = test * pd.Series(xgb_weight_dict_test)\n",
    "xgb_val = val * pd.Series(xgb_weight_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocess as dpf\n",
    "\n",
    "xgb_train_norm = dpf.normalize_all(xgb_train)\n",
    "xgb_test_norm = dpf.normalize_all(xgb_test)\n",
    "xgb_val_norm = dpf.normalize_all(xgb_val)\n",
    "\n",
    "tabnet_train_norm = dpf.normalize_all(tabnet_train)\n",
    "tabnet_test_norm = dpf.normalize_all(tabnet_test)\n",
    "tabnet_val_norm = dpf.normalize_all(tabnet_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = tabnet_train_norm.index\n",
    "valid_indices = tabnet_val_norm.index\n",
    "test_indices = tabnet_test_norm.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Power (kW)'\n",
    "features = [ col for col in tabnet_train_norm.columns if col not in target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_X_train = tabnet_train_norm[features].values[train_indices]\n",
    "tabnet_y_train = tabnet_train_norm[target].values[train_indices]\n",
    "\n",
    "tabnet_X_valid = tabnet_val_norm[features].values[valid_indices]\n",
    "tabnet_y_valid = tabnet_val_norm[target].values[valid_indices]\n",
    "\n",
    "tabnet_X_test = tabnet_test_norm[features].values[test_indices]\n",
    "tabnet_y_test = tabnet_test_norm[target].values[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_tensor_creator(df):\n",
    "    # Convert DataFrame to a numpy array\n",
    "    data_array = df.values\n",
    "\n",
    "    # Convert numpy array to a PyTorch tensor\n",
    "    tensor_data = torch.tensor(data_array, dtype=torch.float)\n",
    "\n",
    "\n",
    "    # Assuming 'data' is your PyTorch tensor\n",
    "    has_nans = torch.isnan(tensor_data).any().item()\n",
    "\n",
    "    if has_nans:\n",
    "        # Assuming 'tensor_data' is your PyTorch tensor containing the data\n",
    "    # Find the indices of columns with NaN values\n",
    "        nan_columns_indices = torch.any(torch.isnan(tensor_data), dim=0).nonzero().squeeze()\n",
    "\n",
    "        # Remove the columns with NaN values\n",
    "        tensor_data_without_nan = torch.cat(\n",
    "            [tensor_data[:, i].unsqueeze(1) for i in range(tensor_data.size(1)) if i not in nan_columns_indices],\n",
    "            dim=1\n",
    "        )\n",
    "    else:\n",
    "        tensor_data_without_nan = tensor_data\n",
    "    # Assuming 'data' is your PyTorch tensor\n",
    "    has_nans = torch.isnan(tensor_data_without_nan)\n",
    "\n",
    "    # Count the number of NaN values in each column\n",
    "    num_nans_per_column = torch.sum(has_nans, dim=0)\n",
    "\n",
    "    return tensor_data_without_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_X_train = torch_tensor_creator(xgb_train_norm[features])\n",
    "xgb_y_train = torch_tensor_creator(xgb_train_norm[target])\n",
    "xgb_X_valid = torch_tensor_creator(xgb_val_norm[features])\n",
    "xgb_y_valid = torch_tensor_creator(xgb_val_norm[target])\n",
    "xgb_X_test = torch_tensor_creator(xgb_test_norm[features])\n",
    "xgb_y_test = torch_tensor_creator(xgb_test_norm[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Batch [0/168], Loss: 0.11818736046552658\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.07554781436920166\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12696537375450134\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05786138027906418\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.03675189986824989\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.020216962322592735\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.16497746109962463\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.041297391057014465\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.11360028386116028\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04273747652769089\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06127822399139404\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.16404516994953156\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023824552074074745\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06343777477741241\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09073295444250107\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.044082798063755035\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.0213814377784729\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05459141358733177\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.046779558062553406\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1279672235250473\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.053495537489652634\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03644626587629318\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.006147781852632761\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07196251302957535\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04103359580039978\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.08837593346834183\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04750082269310951\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.061859529465436935\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.09685783833265305\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.026651930063962936\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.061877284198999405\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08798622339963913\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01581072434782982\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.021139439195394516\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.050987470895051956\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04634852334856987\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.13224051892757416\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05405905470252037\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.034179940819740295\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.006745291408151388\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07613807916641235\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04107652232050896\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06765949726104736\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04570210352540016\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06203853711485863\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.0932365208864212\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.02491716295480728\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.0617319755256176\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08813098073005676\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014125055633485317\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02081356756389141\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.047245707362890244\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04502793401479721\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12438903748989105\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.0589451938867569\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03340400755405426\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005412450060248375\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07226588577032089\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.041777029633522034\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06910524517297745\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04623624309897423\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06201145797967911\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.09054471552371979\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.024468623101711273\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06197061389684677\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08803176134824753\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01407821848988533\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020399585366249084\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04697665944695473\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.0450044609606266\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12466873228549957\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05400459095835686\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03344956785440445\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.00542388204485178\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07175804674625397\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04114851728081703\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06907845288515091\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.043583326041698456\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06134272366762161\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08774423599243164\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023895908147096634\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06292755156755447\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.0884566605091095\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014047584496438503\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020277539268136024\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04800649732351303\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044962264597415924\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12435712665319443\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05451254919171333\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033444594591856\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005416164640337229\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07297081500291824\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.0410795621573925\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06758670508861542\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04416075721383095\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06132955476641655\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08839850127696991\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.0241310466080904\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06271564215421677\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08818943053483963\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014031756669282913\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02028714306652546\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04744527488946915\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.045091718435287476\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12437015771865845\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05444618687033653\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03345741331577301\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005413689650595188\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07417898625135422\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.041028305888175964\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06781069934368134\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.043648697435855865\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06128115952014923\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08745798468589783\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.024021925404667854\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06258635222911835\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08808013051748276\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014088672585785389\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02030806429684162\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04689006507396698\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.0451747290790081\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.1247471272945404\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05307307094335556\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03350365534424782\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005418276879936457\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07582615315914154\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04108123853802681\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07031411677598953\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04302682727575302\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061278268694877625\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.0865812748670578\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023837227374315262\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06257276237010956\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08803047239780426\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014092592522501945\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02035483345389366\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04660447686910629\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04506982862949371\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12646488845348358\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05123913660645485\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03332548215985298\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005411127116531134\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07926227152347565\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04111123085021973\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.07139317691326141\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.042878516018390656\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06127941235899925\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0863540843129158\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023923607543110847\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06256083399057388\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08798127621412277\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.01470282394438982\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020714327692985535\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047285351902246475\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04483791068196297\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1297270655632019\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05361752584576607\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03388854116201401\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005570057779550552\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07290846109390259\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04240403324365616\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07087254524230957\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04273374006152153\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061407703906297684\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08640623837709427\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.024002134799957275\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06246034428477287\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.0880158394575119\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014339078217744827\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02076675556600094\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04669013246893883\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04487152397632599\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12597166001796722\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05114583671092987\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03333241492509842\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005431946832686663\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07378602027893066\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04152655601501465\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.07389183342456818\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.042750611901283264\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061276670545339584\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08635511249303818\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023907018825411797\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06278222054243088\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08827657997608185\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014110753312706947\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.02032758854329586\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04848277568817139\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04496001824736595\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12443136423826218\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05178411677479744\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03342854604125023\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005411992780864239\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07499634474515915\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04105716943740845\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06883124262094498\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04279671609401703\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.0612826906144619\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08656945079565048\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02388385310769081\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06230955570936203\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08816596865653992\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014069084078073502\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020383333787322044\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.047606129199266434\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.0448388010263443\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12469611316919327\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05164879187941551\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033367037773132324\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.0054223621264100075\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.074607715010643\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04116416722536087\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.07022068649530411\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.0427759550511837\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.0612771138548851\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08653207868337631\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.0238852147012949\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06244043633341789\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08811627328395844\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01407183799892664\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02040220983326435\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04731784388422966\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04484559968113899\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12490467727184296\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051482051610946655\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03334999829530716\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005426710471510887\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07488860934972763\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04115376994013786\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06959249824285507\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042867038398981094\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061279602348804474\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.0865238830447197\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023890912532806396\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06238093227148056\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08802960813045502\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014159804210066795\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02052503265440464\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.046846263110637665\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04492970183491707\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12549515068531036\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05123641714453697\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033337779343128204\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.00543289165943861\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07525837421417236\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04118014872074127\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06904422491788864\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04292583838105202\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06128321960568428\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08652306348085403\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023911453783512115\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06232961639761925\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08798310905694962\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014362113550305367\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020688636228442192\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04660132899880409\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.045021623373031616\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12656503915786743\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05123450234532356\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03334624692797661\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.0055575002916157246\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07394644618034363\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04190750792622566\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07183606922626495\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042697615921497345\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.061276793479919434\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.086371511220932\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023956144228577614\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.0628323182463646\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08798850327730179\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014399548061192036\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02081838808953762\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04670438542962074\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04484328627586365\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.1262446641921997\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.0512944720685482\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03337918594479561\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.0055101471953094006\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07270994037389755\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04306558519601822\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.07398593425750732\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04281080886721611\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.0612766407430172\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08652419596910477\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.024001622572541237\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06334174424409866\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08825286477804184\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014200715348124504\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020731959491968155\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.048341501504182816\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04483865201473236\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12440867722034454\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.051757361739873886\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03333430364727974\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005440045613795519\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07199495285749435\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04354562982916832\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07486949115991592\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.0430484265089035\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.0612834095954895\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08634830266237259\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023832036182284355\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06263814121484756\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08833020180463791\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014020232483744621\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020411577075719833\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.048390913754701614\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04483826458454132\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12437446415424347\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05213966593146324\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03332136198878288\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005426099523901939\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.0718960091471672\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.0465654693543911\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.075124092400074\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.043554406613111496\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06130445376038551\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08645100146532059\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02385704033076763\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.062499672174453735\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08846572041511536\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.01408308558166027\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020289938896894455\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04852449521422386\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.0448416993021965\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12435277551412582\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05238596349954605\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03332791104912758\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005412939004600048\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07203692942857742\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04811149090528488\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07731986790895462\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04326838254928589\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061549779027700424\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08663368970155716\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023878246545791626\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.0627545565366745\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.0887766107916832\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.01406806893646717\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020293282344937325\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04942348971962929\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04486800357699394\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12462493777275085\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.052376240491867065\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03333764895796776\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005419346038252115\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07216180860996246\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04226454719901085\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06924297660589218\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04276018962264061\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06133110821247101\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08653019368648529\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023849740624427795\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06224161013960838\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08838138729333878\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014020358212292194\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02048817276954651\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04814678430557251\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04484832286834717\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12436705082654953\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.052391428500413895\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.033347614109516144\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005413426086306572\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07285910099744797\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04276638478040695\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07053771615028381\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04281270131468773\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06132130324840546\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08644042909145355\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02381584607064724\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06228053197264671\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08834570646286011\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014021390117704868\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020495962351560593\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.047906193882226944\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04485655575990677\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.1243540570139885\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05231292173266411\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03334379196166992\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005411582998931408\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07301049679517746\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.044713955372571945\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07287973165512085\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04303009808063507\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06132982298731804\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08641164004802704\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02381291426718235\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06238916888833046\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08842337131500244\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014041955582797527\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.02037769928574562\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04800054430961609\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04484213888645172\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12435412406921387\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.052226241677999496\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03334740176796913\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005411510821431875\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07330809533596039\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.0475744865834713\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07725124806165695\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.043423522263765335\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06150692328810692\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08652032166719437\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023813005536794662\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06265529990196228\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.0886830985546112\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014056762680411339\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020293181762099266\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04871830716729164\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04486639425158501\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12447574734687805\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.052230045199394226\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.0333595909178257\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005429179407656193\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07328420877456665\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.0436827689409256\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07098332047462463\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04298960790038109\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06133999675512314\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08638247847557068\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02381332404911518\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06230579689145088\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08829006552696228\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014018995687365532\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020473506301641464\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04769068956375122\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04485532268881798\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12435370683670044\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05215081572532654\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033379293978214264\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005414177197962999\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07431118935346603\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04625943675637245\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07384898513555527\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04314914718270302\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061296265572309494\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08634821325540543\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02380491979420185\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06240495294332504\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.0881374329328537\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014020495116710663\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02039446122944355\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04716810956597328\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.044953327625989914\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.1246715858578682\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051544006913900375\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03342387452721596\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.0054112328216433525\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07511961460113525\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.049283239990472794\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07571599632501602\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04340061545372009\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06136535108089447\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08635281026363373\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023804720491170883\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06256771087646484\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08817706257104874\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014020837843418121\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020427174866199493\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04754594340920448\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04486071318387985\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12442915886640549\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05181470513343811\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03340154141187668\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005411082878708839\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07474040985107422\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04963025450706482\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07685365527868271\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.0436975434422493\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06128358840942383\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08677500486373901\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023920638486742973\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06340549141168594\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08804827183485031\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.015613983385264874\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020970989018678665\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.046650681644678116\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04659757763147354\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1270151436328888\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05124099180102348\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033326927572488785\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005434687249362469\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.0736737996339798\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.042505837976932526\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07136137783527374\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042717739939689636\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.061461735516786575\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08637367188930511\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.0240724328905344\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06315864622592926\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08798253536224365\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014694565907120705\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020962385460734367\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04679590091109276\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.0448436439037323\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12576578557491302\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05115222930908203\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03333992138504982\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005417682230472565\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07369698584079742\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.047957029193639755\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.072842538356781\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04425817355513573\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061512675136327744\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.0866101011633873\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023915182799100876\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06286782026290894\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08847395330667496\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014018953777849674\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02024931088089943\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.05030979588627815\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04484035074710846\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12467274814844131\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.052019089460372925\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.033389847725629807\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005433649756014347\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07245729863643646\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04352737218141556\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.07022318243980408\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04335653409361839\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061435896903276443\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08641452342271805\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023983590304851532\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06202876940369606\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08799940347671509\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014147555455565453\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.021000944077968597\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.0468275360763073\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04595792293548584\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12584003806114197\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051377154886722565\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033434636890888214\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005412062630057335\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07490256428718567\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.042375508695840836\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06996934860944748\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.043545279651880264\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06148112192749977\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08635091036558151\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023812152445316315\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06280337274074554\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.0883866548538208\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014023559167981148\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020304454490542412\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.05062556639313698\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044888608157634735\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12451393902301788\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05196710303425789\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03338030353188515\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005444529466331005\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07252179831266403\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.043367546051740646\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.07051379233598709\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04339837282896042\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06151333451271057\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08643569052219391\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.02379819191992283\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06252580136060715\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08848011493682861\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014022842980921268\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02025507390499115\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.0506177693605423\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04491358622908592\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12446797639131546\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05205579847097397\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03346216306090355\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005454727448523045\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07319435477256775\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04384802281856537\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07088620215654373\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04356563463807106\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06155219301581383\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08644209802150726\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023795058950781822\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06256677955389023\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08852102607488632\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014026309363543987\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02022538334131241\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.050583869218826294\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044920165091753006\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12439349293708801\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.052031081169843674\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03348594903945923\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0054658809676766396\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07393626868724823\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04529854655265808\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.07155820727348328\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04379696771502495\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06159278377890587\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08643386512994766\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02378842979669571\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06267111003398895\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08854345232248306\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01402546651661396\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020215604454278946\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.050526779145002365\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04492722079157829\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.1243528500199318\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05186855047941208\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033343296498060226\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005473052617162466\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07312881201505661\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04891548678278923\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.07130683958530426\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04371323063969612\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06166033819317818\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08647923916578293\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023781578987836838\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06272811442613602\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08858253061771393\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014019347727298737\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020188285037875175\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.0508987195789814\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04501979798078537\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12435726076364517\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05185782164335251\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03340735286474228\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005485951900482178\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07324991375207901\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.052278611809015274\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06913302838802338\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.0434996597468853\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061626534909009933\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08672762662172318\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.02377769537270069\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06262911111116409\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08852743357419968\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014022630639374256\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02026975341141224\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04979126900434494\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.045219436287879944\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12435904145240784\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.051828160881996155\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03344358503818512\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005491548217833042\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07312174886465073\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.05108727514743805\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06866470724344254\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042757127434015274\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061699915677309036\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08646733313798904\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023843703791499138\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06278880685567856\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08822429925203323\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014042467810213566\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020323848351836205\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.049878619611263275\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04493378847837448\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12437901645898819\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05184420198202133\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03341512754559517\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005483976565301418\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07355056703090668\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.05681699886918068\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06837168335914612\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04274981841444969\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.061995066702365875\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08716468513011932\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023927941918373108\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06359973549842834\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08880873024463654\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014119619503617287\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020211242139339447\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.05113169178366661\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04492761194705963\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12435311079025269\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05177299305796623\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.033422935754060745\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005484945140779018\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07317977398633957\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.0470709390938282\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06783238798379898\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042850397527217865\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06177660822868347\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08669069409370422\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.02382638119161129\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06268058717250824\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.0884120985865593\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.01405731774866581\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020202407613396645\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.0501321516931057\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04515780881047249\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12444538623094559\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05179969221353531\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03347226604819298\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005509788170456886\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.0746573656797409\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.05189745873212814\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06786024570465088\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04274638369679451\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.061316609382629395\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08756359666585922\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.02383226528763771\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.0626552551984787\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08832410722970963\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014110041782259941\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02019585855305195\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.049630142748355865\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04517809674143791\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12487798929214478\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05171843618154526\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03354710340499878\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.00558056402951479\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07508356869220734\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.05121532827615738\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06916351616382599\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.043250296264886856\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06129293888807297\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08841866999864578\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023885266855359077\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06299441307783127\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08838560432195663\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01408176776021719\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02016834355890751\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.049159448593854904\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04526574909687042\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12597058713436127\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05234780162572861\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03407074511051178\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005814354866743088\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07271923869848251\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04636843502521515\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06933444738388062\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.0429069809615612\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06130824610590935\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08751937001943588\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023978112265467644\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.0626891702413559\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08827458322048187\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.01430507656186819\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02021002024412155\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04877143353223801\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04527820646762848\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12495480477809906\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05297254025936127\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03385129198431969\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.006085203029215336\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07237266004085541\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04584997147321701\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.07011520862579346\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04293201491236687\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06128070503473282\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08719413727521896\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023874463513493538\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06292497366666794\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08809497207403183\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.01416967436671257\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020383035764098167\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04914777725934982\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.045125436037778854\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1256016194820404\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05375536158680916\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.034234240651130676\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005674091167747974\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07192325592041016\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04764910414814949\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06832609325647354\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04274071753025055\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061499424278736115\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.09053052961826324\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023729879409074783\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06312389671802521\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08801429718732834\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014026099815964699\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02106144092977047\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.050244491547346115\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.045158788561820984\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12556089460849762\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05385732278227806\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03361182659864426\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.00541113642975688\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.0727466270327568\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04230664297938347\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06872707605361938\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042698245495557785\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06162165477871895\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08664681017398834\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023893969133496284\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.0622551254928112\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08812052756547928\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014142791740596294\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020489810034632683\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04933628439903259\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04524523764848709\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12491244822740555\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05426569655537605\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03376144915819168\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005445558112114668\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07242327183485031\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.0419926643371582\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06857352703809738\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.0427686981856823\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.061549197882413864\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08636030554771423\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023877553641796112\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.062207117676734924\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08803781867027283\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014204781502485275\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020831836387515068\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04913368076086044\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04518585652112961\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12502825260162354\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.054284434765577316\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.033632148057222366\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005417725536972284\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07279698550701141\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04188058525323868\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06866256147623062\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04279245063662529\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061654385179281235\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08635243773460388\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023878958076238632\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06214733049273491\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08803032338619232\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014185774140059948\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.021526355296373367\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04967021197080612\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04518513381481171\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12541373074054718\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.054272472858428955\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03362242132425308\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.00543577317148447\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.0726403221487999\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.041649237275123596\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06854826956987381\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04277469217777252\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061474498361349106\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08635696023702621\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023906787857413292\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.0619979165494442\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08804033696651459\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014254792593419552\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02144061028957367\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.049165740609169006\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.0452069416642189\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12588895857334137\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05436927452683449\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03347282111644745\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005411751102656126\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07315398007631302\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04131884127855301\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06843941658735275\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04282348230481148\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061519790440797806\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08637098222970963\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023928478360176086\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06194102391600609\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08805246651172638\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014262234792113304\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.022320546209812164\n",
      "Search Iteration [1/20], Validation Loss: 0.06057828464121981\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.11996515095233917\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.0733160600066185\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.15602591633796692\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06939254701137543\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.034789688885211945\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.015741700306534767\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.16011600196361542\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.06596335023641586\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.10287778079509735\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04300272464752197\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06223011389374733\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.22578172385692596\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.03119621053338051\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.0618680939078331\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.0929422378540039\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04386391490697861\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.030020715668797493\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05439954996109009\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.056841835379600525\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1244700476527214\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.06086315959692001\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.033444978296756744\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.009221005253493786\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.08128657937049866\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04182807356119156\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07232006639242172\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04361473396420479\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06726760417222977\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.10723560303449631\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02412376180291176\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.0884317085146904\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08813219517469406\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.017444821074604988\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.03134717419743538\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04685850813984871\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05278512090444565\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12775778770446777\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05118170008063316\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.034150972962379456\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005568190012127161\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07175992429256439\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04268595948815346\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.0736754834651947\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.043735191226005554\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.0675734281539917\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08694702386856079\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.02437388151884079\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.07049974799156189\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08834120631217957\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014302197843790054\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.0288963932543993\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04768970236182213\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.046243153512477875\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.1261727213859558\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.051649924367666245\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.033348094671964645\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005411319434642792\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07178241014480591\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04744662344455719\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07360956817865372\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04271044582128525\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06289281696081161\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08871029317378998\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023970626294612885\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06735596805810928\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08820432424545288\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01404272299259901\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.023733939975500107\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04828660190105438\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04608771577477455\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12730863690376282\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05206022039055824\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03345489129424095\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005411631893366575\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07198037207126617\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.041294459253549576\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07321476191282272\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.042777325958013535\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06250709295272827\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08634810894727707\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02470206841826439\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06298333406448364\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08850474655628204\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014998902566730976\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.021309439092874527\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04769410192966461\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044838692992925644\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12754328548908234\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.052825577557086945\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.0335458405315876\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0054128775373101234\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07248828560113907\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04385977238416672\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07179209589958191\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04271113499999046\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06242602691054344\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08647742122411728\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.025033369660377502\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06203256919980049\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08881617337465286\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.01556847058236599\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020764339715242386\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04713147133588791\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04515615850687027\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.1265251487493515\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05306515470147133\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.0335252471268177\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.00541516300290823\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07213171571493149\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04735546186566353\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.0694379210472107\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04270544648170471\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06216186285018921\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08666637539863586\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02489439956843853\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06172429770231247\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08873886615037918\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.015638897195458412\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020516857504844666\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04708623141050339\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04533519223332405\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12619398534297943\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05326784402132034\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.0335753969848156\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005412598140537739\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07199137657880783\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.047834157943725586\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06881517171859741\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.042703475803136826\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06183742359280586\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08669956028461456\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.024742279201745987\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.061654966324567795\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08862675726413727\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.01553373597562313\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020386068150401115\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.047130413353443146\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.045367706567049026\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12608008086681366\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05361909419298172\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03365790471434593\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005411291494965553\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07196447253227234\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.0482538640499115\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06844405829906464\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04270375519990921\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061655111610889435\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0866624042391777\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.024663876742124557\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06165507435798645\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08852031826972961\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.015358438715338707\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020319515839219093\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04717740789055824\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04534414783120155\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1259704977273941\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05391962453722954\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03372271731495857\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005413505714386702\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07191241532564163\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.048460736870765686\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.0681401714682579\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042704783380031586\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06152378395199776\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.0866260677576065\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02459275722503662\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06167297810316086\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08842427283525467\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01519767101854086\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02027924172580242\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04721274971961975\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.045304641127586365\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12588027119636536\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.054197046905756\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03377709165215492\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005416365340352058\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07186459749937057\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04850289225578308\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06792283803224564\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04270587116479874\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061434321105480194\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08658945560455322\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.024530915543437004\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06169279292225838\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08834076672792435\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.015049864538013935\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020253466442227364\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04724176973104477\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04525534808635712\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.1258074939250946\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.054441533982753754\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.033820752054452896\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005418766755610704\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07182374596595764\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.048415131866931915\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06777483224868774\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04270682483911514\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06137388199567795\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08655691891908646\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.024475622922182083\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061708588153123856\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08827086538076401\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014920774847269058\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020235514268279076\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04726676270365715\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045204047113657\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12574763596057892\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05465155467391014\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033854030072689056\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005420277826488018\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07179132848978043\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04822968319058418\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.0676790177822113\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042707640677690506\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06133360043168068\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08652963489294052\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.024425145238637924\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.061719175428152084\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08821366727352142\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014810866676270962\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02022215537726879\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.0472894050180912\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04515466466546059\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12569773197174072\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05483011156320572\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033877745270729065\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.0054208687506616116\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07176833599805832\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04797338321805\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06762145459651947\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04270833730697632\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061307378113269806\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08650758862495422\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.024378539994359016\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06172507256269455\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08816756308078766\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014718497171998024\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02021176740527153\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04731019586324692\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04510916396975517\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12565529346466064\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05498085543513298\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03389259800314903\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.0054206764325499535\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.0717555433511734\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04766934737563133\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.0675913468003273\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04270889237523079\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06129106879234314\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.0864902138710022\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.02433527074754238\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06172730028629303\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08813072741031647\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014641322195529938\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020203551277518272\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04732856526970863\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.045068420469760895\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12561798095703125\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05510670691728592\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03389914333820343\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005419881083071232\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07175346463918686\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04733642190694809\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06758036464452744\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042709313333034515\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06128179281949997\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08647690713405609\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02429516799747944\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.0617268942296505\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08810151368379593\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014577196910977364\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020197106525301933\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04734331741929054\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04503278434276581\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12558379769325256\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05520911142230034\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03389778360724449\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005418673157691956\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07176230847835541\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04699175804853439\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06758219003677368\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.0427095852792263\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06127751246094704\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08646728098392487\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.02425822988152504\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06172475963830948\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.0880785584449768\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014524338766932487\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02019221894443035\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.047352906316518784\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.045002393424510956\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12555070221424103\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.055287979543209076\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03388899564743042\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005417236126959324\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07178166508674622\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04664899408817291\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06759191304445267\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042709704488515854\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061276670545339584\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08646085113286972\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.024224594235420227\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.061721671372652054\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08806074410676956\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014481250196695328\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020188720896840096\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.047355931252241135\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.044977083802223206\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12551705539226532\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05534310266375542\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033873531967401505\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005415752064436674\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07181035727262497\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.046320825815200806\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06760566681623459\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04270967096090317\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06127801910042763\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08645742386579514\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02419445849955082\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.061718232929706573\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08804715424776077\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014446664601564407\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02018648572266102\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04735159873962402\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.044956546276807785\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12548159062862396\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05537407845258713\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03385252133011818\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005414379760622978\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07184629142284393\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04601693153381348\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06762049347162247\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.042709480971097946\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06128055229783058\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08645674586296082\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.0241679809987545\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.061714913696050644\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08803701400756836\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014419392682611942\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02018539048731327\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04733985289931297\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.0449402891099453\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12544357776641846\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.055381789803504944\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033827394247055054\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.0054132333025336266\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07188676297664642\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.045744240283966064\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06763426959514618\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04270913079380989\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06128348782658577\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08645863085985184\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.024145178496837616\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.061712056398391724\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08802972733974457\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014398260973393917\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020185338333249092\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.0473213717341423\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04492778331041336\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12540270388126373\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05536799132823944\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03379977121949196\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005412366706877947\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07192875444889069\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.045506034046411514\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06764576584100723\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042708586901426315\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06128633767366409\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08646275848150253\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.024125918745994568\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06170979142189026\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08802469819784164\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014382034540176392\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.02018623799085617\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04729749262332916\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04491838812828064\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12535929679870605\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.055335476994514465\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03377120569348335\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005411778576672077\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.0719694197177887\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.045302893966436386\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06765435636043549\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04270783066749573\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06128883361816406\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08646883070468903\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02410990558564663\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06170819699764252\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08802144229412079\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01436950359493494\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020188020542263985\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04726995527744293\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04491151496767998\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12531401216983795\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05528786778450012\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.033743079751729965\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.0054114218801259995\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07200657576322556\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04513261839747429\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06766004860401154\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042706869542598724\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061290908604860306\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08647633343935013\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.024096684530377388\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06170720234513283\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08801956474781036\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014359530061483383\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02019060216844082\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.0472404770553112\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04490668326616287\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12526778876781464\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05522879585623741\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.0337163507938385\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005411229562014341\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07203878462314606\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.044991761445999146\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06766320019960403\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.0427057184278965\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.0612926259636879\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08648484200239182\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.024085758253932\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06170668825507164\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08801867812871933\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014351055026054382\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.02019389159977436\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04721060395240784\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.0449034720659256\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12522152066230774\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.055161453783512115\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033691659569740295\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005411139223724604\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07206549495458603\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04487515240907669\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06766436249017715\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04270441457629204\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06129412725567818\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08649379014968872\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.024076536297798157\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06170651316642761\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08801848441362381\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01434329617768526\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020197760313749313\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04718145728111267\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04490158334374428\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12517622113227844\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05508861690759659\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03366929665207863\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005411103833466768\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07208676636219025\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.044778287410736084\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06766408681869507\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04270302131772041\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.0612955279648304\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08650270104408264\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.024068526923656464\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061706505715847015\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08801866322755814\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014335621148347855\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02020205743610859\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.047153882682323456\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044900763779878616\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12513262033462524\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05501252040266991\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03364931792020798\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005411092657595873\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07210314273834229\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04469653591513634\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06766290217638016\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.042701635509729385\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.0612969696521759\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08651112765073776\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.024061240255832672\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06170654296875\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.0880189836025238\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014327628538012505\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.02020660787820816\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04712822288274765\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.044900860637426376\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1250912845134735\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.054934363812208176\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03363161161541939\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005411094985902309\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07211542129516602\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04462592303752899\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06766127049922943\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042700301855802536\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06129850074648857\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08651871979236603\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.024054287001490593\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.061706483364105225\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08801927417516708\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014319140464067459\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02021123841404915\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047104611992836\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04490174725651741\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12505248188972473\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05485513433814049\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03361591324210167\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005411109887063503\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07212439924478531\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04456312954425812\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06765952706336975\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.042699120938777924\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06130019202828407\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08652529865503311\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.024047352373600006\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06170627474784851\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08801934868097305\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014310081489384174\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020215783268213272\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.047082919627428055\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044903334230184555\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.125016450881958\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05477512627840042\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03360198438167572\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005411138758063316\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07213104516267776\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.044505342841148376\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06765790283679962\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04269810765981674\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.0613020621240139\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08653074502944946\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.02404019609093666\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06170583888888359\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08801912516355515\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014300509355962276\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020220089703798294\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.047062911093235016\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04490555822849274\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12498323619365692\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05469455569982529\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03358956053853035\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005411186721175909\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07213596254587173\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.0444507896900177\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06765652447938919\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04269729554653168\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06130412220954895\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08653505146503448\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.024032674729824066\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06170516461133957\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08801855146884918\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014290530234575272\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020224029198288918\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.0470442995429039\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044908374547958374\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12495268881320953\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05461326986551285\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03357836231589317\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005411255173385143\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07213984429836273\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04439779371023178\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06765551120042801\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.042696695774793625\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061306361109018326\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08653825521469116\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.024024661630392075\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06170423701405525\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08801760524511337\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014280264265835285\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020227506756782532\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04702678322792053\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04491173103451729\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1249246597290039\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.054531119763851166\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03356817364692688\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005411343649029732\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07214313745498657\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04434501752257347\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06765488535165787\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.0426962748169899\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06130874156951904\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08654051274061203\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.024016104638576508\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06170306354761124\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08801628649234772\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014269859530031681\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02023044042289257\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.047010041773319244\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044915586709976196\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12489902228116989\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05444810912013054\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033558834344148636\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0054114507511258125\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.0721462294459343\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.044292181730270386\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06765465438365936\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.0426960363984108\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06131124496459961\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08654190599918365\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.024006998166441917\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061701662838459015\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08801461011171341\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014259428717195988\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02023278921842575\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04699384421110153\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044919926673173904\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.1248755231499672\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05436394736170769\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.0335501953959465\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.0054115722887218\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07214938849210739\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.044238295406103134\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06765478849411011\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.042695946991443634\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061313826590776443\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08654256910085678\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.02399730682373047\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06170003116130829\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08801262080669403\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014249077998101711\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02023451402783394\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04697796702384949\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044924698770046234\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12485396862030029\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05427875742316246\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03354211896657944\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005411704536527395\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07215283811092377\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.044183067977428436\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.0676552802324295\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.042695991694927216\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06131644919514656\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08654267340898514\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023987043648958206\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06169817969202995\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08801038563251495\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014238880947232246\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020235588774085045\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.046962250024080276\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.0449298731982708\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12483422458171844\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.054192617535591125\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03353455662727356\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.0054118456318974495\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07215665280818939\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.044126465916633606\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06765607744455338\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04269613325595856\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06131906062364578\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08654232323169708\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023976240307092667\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06169614940881729\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08800793439149857\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014228916727006435\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020236002281308174\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.046946536749601364\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.0449354350566864\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12481609731912613\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05410561338067055\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03352741524577141\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005411990452557802\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07216096669435501\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04406801238656044\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06765718013048172\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04269636422395706\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06132157891988754\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08654172718524933\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023964904248714447\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.0616939403116703\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08800531923770905\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014219243079423904\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02023574709892273\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04693076014518738\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04494137316942215\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12479947507381439\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05401796102523804\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.0335206463932991\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005412139464169741\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.0721658393740654\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04400784149765968\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06765861064195633\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04269666224718094\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06132391467690468\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08654088526964188\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023953063413500786\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.061691537499427795\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08800259977579117\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014209878630936146\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020234793424606323\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04691486433148384\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04494765028357506\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12478433549404144\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05393020808696747\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03351425752043724\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005412293132394552\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.0721711814403534\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04394616559147835\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06766033917665482\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04269701987504959\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06132602319121361\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08653997629880905\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.02394067868590355\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06168891116976738\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08799976855516434\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014200775884091854\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020233092829585075\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.0468989834189415\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04495422914624214\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12477075308561325\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05384312942624092\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03350823372602463\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005412445403635502\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07217679917812347\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.043882932513952255\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06766235828399658\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269743338227272\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06132793053984642\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08653891086578369\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02392779104411602\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061686061322689056\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08799690753221512\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01419190876185894\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02023058384656906\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04688337445259094\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044961027801036835\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12475867569446564\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05375741794705391\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03350255638360977\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005412588827311993\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07218259572982788\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04381897300481796\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06766454875469208\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04269791021943092\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06132958456873894\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08653773367404938\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023914573714137077\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.061683088541030884\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08799412846565247\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014183350838720798\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020227275788784027\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.0468682125210762\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04496803879737854\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1247478798031807\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05367362126708031\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03349722549319267\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005412725266069174\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07218840718269348\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.043754786252975464\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06766679137945175\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042698439210653305\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.0613308884203434\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.0865364596247673\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02390112727880478\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06168009340763092\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08799148350954056\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014175215736031532\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02022317238152027\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04685346037149429\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04497535899281502\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12473830580711365\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.053591955453157425\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03349221497774124\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005412858910858631\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07219405472278595\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04369059205055237\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06766905635595322\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04269900918006897\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06133170798420906\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08653516322374344\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02388758771121502\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061677105724811554\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08798903971910477\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.01416767854243517\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02021830342710018\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.046838995069265366\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04498303309082985\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12472992390394211\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.0535125732421875\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033487509936094284\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.0054129911586642265\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.0721992775797844\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.043626610189676285\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.0676712691783905\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04269963130354881\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061331991106271744\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08653386682271957\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023874083533883095\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061674196273088455\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08798684924840927\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014160886406898499\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02021278627216816\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04682459309697151\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044991206377744675\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12472270429134369\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05343521758913994\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03348306566476822\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.00541312713176012\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07220368832349777\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04356277734041214\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06767335534095764\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.042700305581092834\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.061331700533628464\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08653257042169571\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023860739544034004\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061671413481235504\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08798498660326004\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014154994860291481\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020206773653626442\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.0468100905418396\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04499994218349457\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12471663951873779\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05335964635014534\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03347882628440857\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005413268227130175\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07220698893070221\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.043499674648046494\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06767524033784866\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042701054364442825\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061330895870923996\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.0865311399102211\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023847637698054314\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06166878715157509\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08798342198133469\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.01415008120238781\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02020048350095749\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04679538682103157\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04500926285982132\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12471160292625427\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.053285516798496246\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03347475826740265\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005413408391177654\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07220880687236786\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04343762248754501\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.0676768496632576\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04270191118121147\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06132977455854416\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08652935922145844\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02383490838110447\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.061666373163461685\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.0879821926355362\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014146115630865097\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02019421011209488\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.046780481934547424\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.045019131153821945\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12470726668834686\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05321246385574341\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03347078710794449\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005413535516709089\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0722089558839798\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04337741807103157\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06767810881137848\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042702894657850266\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06132842227816582\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.0865270346403122\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023822691291570663\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061664219945669174\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08798126876354218\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014143060892820358\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02018827386200428\n",
      "Search Iteration [2/20], Validation Loss: 0.0568406313827092\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.15052202343940735\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.1398368924856186\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.13029475510120392\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06442428380250931\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.03451618179678917\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.018645649775862694\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.118007592856884\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.04160070791840553\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.06933192163705826\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.042720403522253036\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.062138356268405914\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.1451382040977478\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02695429138839245\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.0735912099480629\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.0879981741309166\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.03427808731794357\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.022393276914954185\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.046588070690631866\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.05686752498149872\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12757548689842224\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.051397256553173065\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03544727712869644\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005471966695040464\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.08013039082288742\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04168776422739029\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07110800594091415\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.042703963816165924\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06528275460004807\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.08784135431051254\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02600238099694252\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06919541954994202\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08812377601861954\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01848513074219227\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.0285736545920372\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.05220399796962738\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.045013099908828735\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12436159700155258\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05113627761602402\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03374240919947624\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.00543559342622757\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07178100943565369\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.041057288646698\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06769664585590363\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04651772975921631\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06364264339208603\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08783019334077835\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024496298283338547\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.0626482367515564\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08828810602426529\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014036794193089008\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.023304739966988564\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04679599031805992\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04706263542175293\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12479040771722794\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.051145706325769424\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03332887589931488\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005557049531489611\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07175592333078384\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04135270416736603\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06920893490314484\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.043340276926755905\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.061793431639671326\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08755673468112946\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02423885650932789\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06169266253709793\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08881737291812897\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01404398214071989\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020905019715428352\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.0467541441321373\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04608732834458351\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12488663196563721\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05133438855409622\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03345422446727753\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005415497813373804\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07228156179189682\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04285341873764992\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.0716099739074707\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.042790547013282776\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06135153770446777\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08652834594249725\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024056963622570038\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06171682849526405\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08819351345300674\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014338184148073196\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.021155770868062973\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04663367196917534\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.0458790548145771\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12683191895484924\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05173349753022194\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033443037420511246\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0054169511422514915\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07238686829805374\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04236523434519768\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.0704626739025116\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.0428130142390728\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.061410851776599884\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08635508269071579\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023956604301929474\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.061823464930057526\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08821585774421692\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014526749029755592\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02145630493760109\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04662276431918144\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04520689323544502\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12701332569122314\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05126979947090149\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.033387817442417145\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005428335163742304\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07287337630987167\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.042002592235803604\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06972499191761017\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.042883843183517456\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061382394284009933\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08647241443395615\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02385452203452587\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06182532012462616\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08830524981021881\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014253607951104641\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.021095121279358864\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.046617042273283005\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04509703814983368\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.1260048896074295\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05115056782960892\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03333411365747452\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005460185464471579\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.0725829005241394\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04222939535975456\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06939481943845749\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04280856251716614\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061326757073402405\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08659639954566956\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02383628860116005\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06192527338862419\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08828612416982651\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014189465902745724\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02094942331314087\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.046636082231998444\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04505198076367378\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12571562826633453\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05113599821925163\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03332236036658287\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.00551210343837738\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07240591943264008\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04252034053206444\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06973592936992645\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04273421689867973\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06130633503198624\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08656476438045502\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023810889571905136\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.062007881700992584\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08828269690275192\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.01417065691202879\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02090815268456936\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.046644262969493866\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04506158083677292\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12553054094314575\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05114586278796196\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.0333230160176754\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005588174797594547\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07246531546115875\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.042722828686237335\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.0697125494480133\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042711012065410614\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061300378292798996\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08654148876667023\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023786181584000587\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.062028538435697556\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08830463886260986\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014153564348816872\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020891012623906136\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.0466609001159668\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04507283493876457\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12532475590705872\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05116240307688713\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03332614153623581\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.0056672063656151295\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07259752601385117\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04279590770602226\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06963615119457245\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.0427037738263607\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06129904463887215\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08652805536985397\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.02376202493906021\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06202372908592224\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08833573758602142\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014129768125712872\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020867086946964264\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04667738452553749\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04507405683398247\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.1251404881477356\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.051175396889448166\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03333190083503723\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005727804731577635\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.072737917304039\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04274062067270279\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06950250267982483\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04270355775952339\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06130008026957512\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08652008324861526\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023741526529192924\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06201203912496567\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08836263418197632\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.01410760823637247\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.0208369642496109\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046688806265592575\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04506213590502739\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12500058114528656\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.051182571798563004\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033337920904159546\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.0057644774205982685\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07284828275442123\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.042638566344976425\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06937848031520844\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04270458593964577\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06130141764879227\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08650568872690201\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023725727573037148\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06200619414448738\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08837898820638657\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014091841876506805\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02080761268734932\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04669315367937088\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04504607617855072\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.1249096542596817\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051183879375457764\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033341217786073685\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.0057792020961642265\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07291553169488907\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04256231337785721\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06927584856748581\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04270321875810623\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06130204722285271\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08648069202899933\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02371462993323803\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06200949847698212\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08838322758674622\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014084206894040108\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020786389708518982\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04669340327382088\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04503319412469864\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12486104667186737\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05118294432759285\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03333989158272743\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005779193714261055\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.0729474201798439\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.0425415076315403\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.0692230761051178\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04269874468445778\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.061302345246076584\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08644351363182068\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023706678301095963\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06202426552772522\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08837848156690598\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014083749614655972\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02077702432870865\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.046694282442331314\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04502147436141968\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12484719604253769\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05118219926953316\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03333441913127899\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.0057706027291715145\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07296498119831085\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04257908836007118\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06924637407064438\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042696066200733185\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.061302829533815384\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.0864020362496376\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023700835183262825\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06205151975154877\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.0883735939860344\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.01408711913973093\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020774539560079575\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04670172557234764\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.044994838535785675\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12484949827194214\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.051186248660087585\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.033327553421258926\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.0057610562071204185\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.0729939416050911\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04267605021595955\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06941892206668854\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042709190398454666\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061302583664655685\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0863695740699768\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023696307092905045\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06209113821387291\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08837670087814331\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014087754301726818\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020763352513313293\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04672836512327194\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04493684694170952\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12483039498329163\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05120953172445297\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033322252333164215\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005755179561674595\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07302716374397278\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04281880334019661\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06981024891138077\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04276139289140701\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061298660933971405\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08635702729225159\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02369251288473606\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.062128275632858276\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08838072419166565\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014077219180762768\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020708873867988586\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04680166766047478\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.044869314879179\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12473703175783157\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05128827318549156\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03332223370671272\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.0057438514195382595\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07296081632375717\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.042871586978435516\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07016438990831375\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04284099489450455\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06128895655274391\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.0863669365644455\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023690450936555862\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06211194396018982\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08837667107582092\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014054450206458569\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020598838105797768\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04693646728992462\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04484153911471367\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12459646910429001\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.051439858973026276\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03333220258355141\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005695240572094917\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07260247319936752\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.042624182999134064\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06987573951482773\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04287203401327133\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061280544847249985\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08640019595623016\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.02369164302945137\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06202961876988411\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08837267011404037\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014039827510714531\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020504547283053398\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.047028426080942154\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04483877867460251\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12452387064695358\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.0515609048306942\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03335963934659958\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005617416929453611\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07208778709173203\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04236741364002228\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06929051131010056\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.0428776852786541\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061277519911527634\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08641111105680466\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023696335032582283\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.061962395906448364\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08835554122924805\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014040513895452023\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020455842837691307\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04699133336544037\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04483884945511818\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12452653050422668\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051554255187511444\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.0333852656185627\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005569991189986467\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07183483988046646\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.042540691792964935\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06915624439716339\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04294890537858009\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08639167994260788\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023701461032032967\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.061941515654325485\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08833576738834381\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014048305340111256\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020435335114598274\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.046917084604501724\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04483842849731445\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12455619126558304\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05149846524000168\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03339805081486702\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.00555429607629776\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07177119702100754\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04304349049925804\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.0693126767873764\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04308074712753296\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06127806380391121\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08637484163045883\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023704268038272858\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06192934140563011\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08832908421754837\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01405420433729887\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020418325439095497\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04687850922346115\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04483781009912491\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12455637753009796\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051486749202013016\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03340855985879898\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005550006404519081\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07175637036561966\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04359264299273491\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06943948566913605\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04322672262787819\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06128197908401489\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08636797219514847\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023704374209046364\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06189851835370064\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08832944929599762\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014057576656341553\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020393311977386475\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04688167944550514\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04483873024582863\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12451499700546265\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05152473226189613\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03342872112989426\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005536594893783331\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07175422459840775\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04410804063081741\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06951290369033813\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04339506849646568\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06128831207752228\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08636541664600372\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023703744634985924\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06185782700777054\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08832184970378876\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014060856774449348\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020358692854642868\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04690142720937729\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.044842272996902466\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12446402758359909\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05158280208706856\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03346296027302742\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005510353017598391\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07178713381290436\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04483092576265335\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.0695943832397461\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.043635740876197815\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061298102140426636\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08636558800935745\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02370493859052658\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06181015074253082\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08830156922340393\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014065997675061226\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02031688578426838\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04693027585744858\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04484861344099045\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12441757321357727\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051648300141096115\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03350815549492836\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005481090862303972\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07188717275857925\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.046311091631650925\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06976573914289474\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04404286667704582\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061320286244153976\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08638028800487518\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02370871603488922\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061748720705509186\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08827833086252213\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014068684540688992\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020263398066163063\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.047012344002723694\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044857416301965714\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12437114119529724\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05174987390637398\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03356725722551346\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005451320204883814\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07208919525146484\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.049637243151664734\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.0700010433793068\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04464475065469742\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06140908971428871\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08649709075689316\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02371649071574211\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.061688847839832306\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08827745914459229\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.01406347006559372\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020202556625008583\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04719524085521698\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04485750570893288\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12435267865657806\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05194004625082016\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03369075804948807\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005419271532446146\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07253982871770859\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.05360070988535881\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06958326697349548\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.044661104679107666\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06153251603245735\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08666525781154633\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023716360330581665\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06168004497885704\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08825153857469559\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014151793904602528\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020191587507724762\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047117315232753754\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04484204202890396\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12439907342195511\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05211639776825905\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03393842279911041\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005411837715655565\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07306277751922607\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.05131535604596138\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06851889938116074\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04393988102674484\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061333898454904556\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08637906610965729\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023704389110207558\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.0617000088095665\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08811771869659424\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014364116825163364\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020195389166474342\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.046893224120140076\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04492220655083656\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12435272336006165\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05221989005804062\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.034061919897794724\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005420718342065811\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07323386520147324\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.0595322884619236\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.0677410140633583\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.0431213453412056\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06129756569862366\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08649398386478424\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023762738332152367\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06177647039294243\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.0881112590432167\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014535412192344666\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02020084857940674\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.046927180141210556\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04489868879318237\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12443488836288452\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05272319167852402\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03441954031586647\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005460585001856089\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07438186556100845\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.05096400901675224\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06758666783571243\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042912691831588745\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06129046529531479\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08640539646148682\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023828264325857162\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06219225749373436\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.0882386639714241\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014840273186564445\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.02017025835812092\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04756565019488335\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04491066560149193\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12447813898324966\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05277333781123161\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03441312164068222\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005487299989908934\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07393447309732437\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.05719442293047905\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06825793534517288\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04271489381790161\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0614330880343914\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08635401725769043\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.024042747914791107\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06241492182016373\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08828399330377579\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014715321362018585\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020209453999996185\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04758070409297943\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04484596475958824\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12435270845890045\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05326921120285988\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03452291712164879\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.0054886178113520145\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.0737079605460167\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.058054547756910324\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06973738968372345\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.0434245690703392\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.0616096667945385\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08652109652757645\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.024078870192170143\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06278931349515915\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08817631751298904\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.01424168236553669\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020370976999402046\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.0475153811275959\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044839873909950256\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12457485496997833\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.053603559732437134\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03456248715519905\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0054688965901732445\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07274363934993744\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.05258860066533089\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.07030574232339859\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.043362509459257126\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.061381544917821884\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08668903261423111\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02390391193330288\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.0626101866364479\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08806478977203369\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014095427468419075\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020649811252951622\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.047800540924072266\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044854115694761276\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12468239665031433\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05374429374933243\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03445570543408394\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.00542990118265152\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07205643504858017\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04870526120066643\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.07012889534235\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04308434948325157\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06128242239356041\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08668709546327591\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023809082806110382\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06232433393597603\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08801054954528809\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014060771092772484\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.0209334846585989\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04788751155138016\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04485983029007912\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12472863495349884\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05376075953245163\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03426345810294151\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005412166006863117\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07176018506288528\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.045671138912439346\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06968940049409866\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04285022243857384\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06129120662808418\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08652715384960175\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023773767054080963\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.062148816883563995\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08798857778310776\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014054520055651665\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.021165119484066963\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047995246946811676\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04486272484064102\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12468183040618896\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05364604666829109\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.034083615988492966\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005416799336671829\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07183310389518738\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04378693550825119\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06921611726284027\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04274330660700798\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06132960692048073\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08643387258052826\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023767877370119095\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06202400475740433\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08798553049564362\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014069022610783577\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.0213445033878088\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.047900550067424774\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044866982847452164\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12476290762424469\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.053626686334609985\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.0339309424161911\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005433152429759502\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07205704599618912\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.042838554829359055\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06883682310581207\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042706966400146484\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06134855002164841\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08638213574886322\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02377462200820446\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06193333491683006\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08798820525407791\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014087804593145847\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02144893817603588\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04782626032829285\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04486744850873947\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12485338747501373\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.053502634167671204\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03381340578198433\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005455785896629095\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07245640456676483\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.042061325162649155\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06876477599143982\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04269682243466377\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06134941056370735\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08634746819734573\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023781049996614456\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.061865150928497314\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08800078183412552\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014071688987314701\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02130793407559395\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.047742556780576706\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04488866403698921\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12495117634534836\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05347463861107826\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033672209829092026\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005476050544530153\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07277446985244751\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.0415792353451252\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06823335587978363\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04270261153578758\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06134989857673645\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08634717017412186\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.0237771887332201\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.0617358423769474\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08800233155488968\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014083891175687313\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02097977139055729\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04736597090959549\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044871363788843155\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.1249493807554245\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05353342741727829\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.0335688591003418\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.0055089071393013\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.0732194185256958\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04139283299446106\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06889297813177109\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269596189260483\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061328865587711334\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08643919974565506\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023798754438757896\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061761289834976196\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08806651830673218\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014070935547351837\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020837660878896713\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04757242277264595\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04494008794426918\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12498842179775238\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.053544748574495316\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03354056552052498\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.0054782419465482235\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07304991036653519\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04142887517809868\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06817357987165451\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042698316276073456\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06131463125348091\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08637090027332306\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023770757019519806\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06168834865093231\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08802440017461777\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014051294885575771\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020694177597761154\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04728963226079941\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.044890280812978745\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1248856633901596\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05358259752392769\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033562738448381424\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0054513923823833466\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07307479530572891\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.041426196694374084\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.0682402029633522\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042697034776210785\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06130311265587807\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08637978136539459\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023786067962646484\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06167159602046013\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08804816752672195\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014056443236768246\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02058134414255619\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04720582440495491\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.044880129396915436\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12489617615938187\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.053670287132263184\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03346402570605278\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.0054938821122050285\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07322637736797333\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04140347242355347\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06793790310621262\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042696744203567505\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061285633593797684\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08640415221452713\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023825155571103096\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061671581119298935\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08810852468013763\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014053854160010815\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02057812549173832\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.047435659915208817\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044907618314027786\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1248164176940918\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05392614006996155\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03344219550490379\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005497336853295565\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07350784540176392\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04141801968216896\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06853806972503662\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04269647225737572\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06129230186343193\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08636847138404846\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023764915764331818\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061651650816202164\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08811653405427933\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014020085334777832\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020572558045387268\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.047831520438194275\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044936902821063995\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12534601986408234\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05347088351845741\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033701833337545395\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005411084741353989\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07197311520576477\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04425494372844696\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06837709248065948\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04279192537069321\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06127740442752838\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08635660260915756\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02379448525607586\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.0616932138800621\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08801911771297455\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014074413105845451\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020273739472031593\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04713116213679314\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04485280439257622\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12443652749061584\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05280311033129692\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03334406018257141\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005517513025552034\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07357289642095566\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.041112303733825684\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06832766532897949\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042701605707407\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06134241446852684\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08645427972078323\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023738378658890724\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06165827810764313\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08806958049535751\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014030618593096733\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020422425121068954\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.047435831278562546\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.044891357421875\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.1245289072394371\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05327487364411354\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033362243324518204\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005521073006093502\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07345030456781387\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04120411351323128\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06859828531742096\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04269600287079811\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06132020056247711\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08650241047143936\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02373725175857544\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.061656516045331955\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.0880918800830841\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014024986885488033\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020486894994974136\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.047523658722639084\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04489646106958389\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12455786019563675\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05318927392363548\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03334929049015045\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005514590069651604\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07343871146440506\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.0412323959171772\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06862716376781464\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04269707202911377\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.0613064281642437\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08652108162641525\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023728011175990105\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06165275350213051\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08811313658952713\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014018900692462921\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020497025921940804\n",
      "Search Iteration [3/20], Validation Loss: 0.055929658164016224\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.11600203812122345\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.08798196166753769\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12466942518949509\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.054915331304073334\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.0488579086959362\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.00541158951818943\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.0747707411646843\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.05060667172074318\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07963964343070984\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04657666012644768\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06673872470855713\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.13111135363578796\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023725364357233047\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.07540974766016006\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09662918001413345\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04250999167561531\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.030010778456926346\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05611470714211464\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.048878394067287445\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12523242831230164\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05199882760643959\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.04020870849490166\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.006455724127590656\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07336144894361496\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04417510703206062\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.08687479048967361\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.051251959055662155\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06769479811191559\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1025371327996254\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02404184825718403\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06457628309726715\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.09218980371952057\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01526582706719637\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02903068996965885\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04660682752728462\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.046270713210105896\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.1253058761358261\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05323487147688866\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033329859375953674\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.0054585253819823265\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07247181981801987\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.050364334136247635\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06804563850164413\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05035882443189621\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06500811874866486\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.1025734394788742\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.02371196821331978\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06487343460321426\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.0940532460808754\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.018089868128299713\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.022226734086871147\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04698985442519188\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04527483135461807\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12435334175825119\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05390234291553497\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03350600227713585\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.0054308949038386345\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07448731362819672\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04756540432572365\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06836846470832825\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.044013407081365585\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06153514236211777\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.09968040883541107\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02373500168323517\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.061861008405685425\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.09109636396169662\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01463306788355112\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.0203349981456995\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04716368392109871\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04510778188705444\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12502314150333405\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05312305688858032\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03397563472390175\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005411140620708466\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07711490243673325\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.041016288101673126\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.08123473823070526\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.043284591287374496\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06164836511015892\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.09096738696098328\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023821057751774788\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06173767149448395\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08864670246839523\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014115742407739162\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02059626579284668\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.048428140580654144\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044971466064453125\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12487485259771347\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05222034454345703\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03409126028418541\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005416662432253361\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07830148190259933\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04359028488397598\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.0869341641664505\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04504818096756935\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06201418489217758\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08905491977930069\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023830296471714973\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06166239082813263\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08842112869024277\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014165154658257961\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020272966474294662\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04914851486682892\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.044934727251529694\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.1243569552898407\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05141843482851982\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03384600207209587\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005416533909738064\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07650879770517349\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04981246590614319\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.08498086780309677\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.045219313353300095\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061908554285764694\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08817661553621292\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023932820186018944\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06172332540154457\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08840266615152359\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014249403961002827\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02016562782227993\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.049962300807237625\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04586292803287506\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12452256679534912\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05120871216058731\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03357556089758873\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005423160269856453\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07374387234449387\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.05924248695373535\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07642088085412979\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.044752225279808044\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061479177325963974\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08709663152694702\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.024086324498057365\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06242179125547409\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08871608227491379\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014247708953917027\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020214829593896866\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.05171168968081474\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04829241707921028\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.1253572553396225\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05141252279281616\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03397710248827934\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005411287769675255\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07312765717506409\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.056168083101511\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06953956931829453\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04333946481347084\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06130171939730644\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0863557830452919\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.024509476497769356\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06483378261327744\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08921072632074356\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014489447697997093\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02024657092988491\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.050017014145851135\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04686640202999115\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1263454407453537\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.053230054676532745\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03444404527544975\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.00544786499813199\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07244496047496796\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.055398326367139816\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.0675947517156601\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04278520867228508\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06153567135334015\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08653682470321655\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.024543792009353638\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06502260267734528\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.0890333354473114\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014499412849545479\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020418226718902588\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.049450021237134933\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.045855168253183365\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12658560276031494\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.053990304470062256\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03465938940644264\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005432370118796825\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07196639478206635\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.05384523421525955\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06799905002117157\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.042702291160821915\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06181307137012482\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08662128448486328\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.024541666731238365\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06436873227357864\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08872779458761215\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014361639507114887\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020402001217007637\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04947243258357048\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.045672912150621414\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12613201141357422\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.0535159669816494\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.034265171736478806\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.00543129863217473\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07178676128387451\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.05106605589389801\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06860782206058502\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.042756181210279465\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06189431995153427\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08651687204837799\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.024601178243756294\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.0635768324136734\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08853349834680557\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014377391897141933\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.02024945057928562\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.0490250363945961\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045569807291030884\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12540721893310547\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.0527479313313961\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03382924199104309\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005578481592237949\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07176188379526138\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.049024198204278946\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.068911612033844\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04278162494301796\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06189929321408272\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08645134419202805\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.024530133232474327\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.0631207674741745\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08838869631290436\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014330360107123852\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02022974193096161\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.048814572393894196\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04550948739051819\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.1251196563243866\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.0524437353014946\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03363444283604622\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.00565565237775445\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07189153134822845\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04706456512212753\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06923243403434753\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04275226220488548\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06176108866930008\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08637594431638718\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02449514903128147\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06280215829610825\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08834390342235565\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014416536316275597\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020211828872561455\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04834534227848053\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04536578059196472\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12513677775859833\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.052444249391555786\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033645134419202805\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005614646710455418\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07201283425092697\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.046071309596300125\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06915568560361862\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04274758696556091\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06169312447309494\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08640355616807938\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.02447025291621685\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06280657649040222\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08835683017969131\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014436193741858006\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020232560113072395\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04820649325847626\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.045306771993637085\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12524165213108063\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.0525648258626461\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033666543662548065\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.00557449646294117\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07209065556526184\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.045349955558776855\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06907013803720474\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04274384304881096\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06164729967713356\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08642327040433884\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.024451056495308876\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06279066950082779\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08837223798036575\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014448831789195538\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020250562578439713\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04810594767332077\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04527029022574425\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12533462047576904\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05266657471656799\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03368968516588211\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005540607031434774\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07213543355464935\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.044876571744680405\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06895777583122253\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04273993521928787\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06161581724882126\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08644112944602966\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.024434290826320648\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06277453899383545\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08838589489459991\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014449645765125751\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020267337560653687\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.048051364719867706\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.0452539436519146\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12540896236896515\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05274895951151848\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03370862826704979\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.00551451975479722\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07216285169124603\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04451905936002731\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06885547190904617\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04273618757724762\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.0615939162671566\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08645521849393845\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02441665343940258\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06274963915348053\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08839521557092667\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014443893916904926\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.02027672342956066\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04801871255040169\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.045246005058288574\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12544560432434082\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05279887095093727\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03372175246477127\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.00549539178609848\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07218347489833832\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04422874003648758\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.0687573254108429\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04273373261094093\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061578888446092606\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08647019416093826\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02439821884036064\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06272183358669281\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08840116858482361\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.01443416252732277\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02027917094528675\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04799771308898926\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.045239582657814026\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12544624507427216\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.0528191514313221\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033730898052453995\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005480980034917593\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07219763845205307\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04397664591670036\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06866174191236496\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.042732514441013336\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061567384749650955\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08648526668548584\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.024377821013331413\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06269332021474838\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08840323239564896\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014418681152164936\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02028018981218338\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04798959568142891\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04523555934429169\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12542429566383362\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05281881242990494\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03373561426997185\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.00547027587890625\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07220688462257385\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.043742600828409195\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06858170032501221\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.042732350528240204\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06155761703848839\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08649787306785583\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.024355562403798103\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06266141682863235\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08840019255876541\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014401120133697987\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020281706005334854\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04797643423080444\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.0452287532389164\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12539036571979523\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05280734598636627\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03373787924647331\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005462504457682371\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.072210393846035\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.0435166135430336\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.0685199573636055\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04273297265172005\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06154840067028999\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.0865081176161766\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.024333661422133446\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06262869387865067\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08839304000139236\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014384313486516476\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020283717662096024\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.047953877598047256\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04521871730685234\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.1253463625907898\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05279671400785446\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03374110907316208\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005456199403852224\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07220785319805145\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04329875856637955\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06846866756677628\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04273400455713272\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06153935566544533\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08651873469352722\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02431475929915905\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06260073930025101\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08838442713022232\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01437136810272932\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020286276936531067\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04792553186416626\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.045207202434539795\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12528546154499054\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.0527898333966732\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.033748872578144073\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005448893643915653\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07219849526882172\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04309017211198807\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06842736154794693\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04273577779531479\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06152847036719322\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08652597665786743\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.02429630421102047\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06257618963718414\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08837383985519409\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.01436381135135889\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02029343508183956\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04788024351000786\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04518979415297508\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12521463632583618\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05278646945953369\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03375457227230072\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005445461254566908\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07218419015407562\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04291367530822754\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06839003413915634\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04273725673556328\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.061520371586084366\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08654002100229263\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.024284783750772476\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.0625535398721695\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08836442232131958\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014363031834363937\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020305968821048737\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.0478191114962101\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.045166634023189545\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12510739266872406\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05280179902911186\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03375985473394394\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005444847978651524\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07216361910104752\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04278595745563507\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06836006045341492\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04273638874292374\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06150801107287407\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.0865590050816536\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02427796460688114\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.0625348761677742\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08835542947053909\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01436776202172041\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020327983424067497\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.047742463648319244\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.045135747641325\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12492721527814865\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.052841562777757645\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.033757779747247696\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.0054481239058077335\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07214611023664474\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04269171506166458\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06833112239837646\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.042734719812870026\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061499591916799545\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.0865778997540474\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.024273881688714027\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.0625034049153328\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08834352344274521\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014376518316566944\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02038857340812683\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04765257611870766\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04509412869811058\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12466594576835632\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05286658555269241\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03373035416007042\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005454024765640497\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07213964313268661\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04265064746141434\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06829790771007538\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04272995889186859\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.061484985053539276\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08660151064395905\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.024272607639431953\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06246047466993332\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.0883328765630722\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014385090209543705\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020624438300728798\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04764378443360329\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.045050449669361115\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12472071498632431\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05264807865023613\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033712614327669144\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005448855459690094\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07215328514575958\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04257859289646149\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06817195564508438\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04273131862282753\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.061490390449762344\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08658914268016815\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.024258935824036598\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06237814575433731\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08832424134016037\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.01438532117754221\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020895278081297874\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047631021589040756\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04503442719578743\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12478002160787582\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.052558738738298416\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03371873497962952\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.0054504177533090115\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07212238758802414\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04270784556865692\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06815493106842041\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04271542653441429\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061417996883392334\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08661706745624542\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.024255260825157166\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06235736981034279\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.0883258804678917\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014380860142409801\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02108716033399105\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.047550592571496964\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04503370448946953\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12482231855392456\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05261581763625145\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03369608521461487\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005452665966004133\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07208913564682007\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04272664710879326\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06814367324113846\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.042715586721897125\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06144163757562637\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08666117489337921\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.024268638342618942\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.062292736023664474\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.0883169025182724\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014394792728126049\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02137758955359459\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04756993055343628\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04505821689963341\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12511396408081055\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.052574533969163895\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03369195759296417\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.00545268040150404\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.0720650851726532\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04292384535074234\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06826356053352356\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04270980879664421\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06139177829027176\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08665291965007782\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.024262964725494385\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.062247134745121\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08830460906028748\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014374542981386185\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.021418964490294456\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.047583531588315964\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04507166147232056\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1253288835287094\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.052613165229558945\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03365156427025795\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005453425459563732\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07210396230220795\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.042864080518484116\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06833561509847641\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04270991310477257\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0614263080060482\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08667507022619247\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.02426767162978649\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.062158193439245224\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08828381448984146\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014400438405573368\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02138163521885872\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.0475141666829586\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04505697637796402\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12534911930561066\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05257372185587883\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033628225326538086\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005451791919767857\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07214716821908951\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04294321686029434\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06846821308135986\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04270599037408829\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06141052022576332\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08665763586759567\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.024258477613329887\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06209731101989746\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0882662683725357\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014407726004719734\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02128678560256958\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04753280431032181\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.0450483039021492\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12537817656993866\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.052586935460567474\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03358418121933937\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005454236641526222\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07226843386888504\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04286704584956169\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06851673126220703\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.042708322405815125\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06150640919804573\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08665841817855835\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.024253183975815773\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061997171491384506\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08825323730707169\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014469774439930916\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.021060341969132423\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04746603965759277\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04502047225832939\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12475802004337311\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.0524023100733757\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03357497602701187\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005449169315397739\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07224009186029434\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.043532975018024445\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06860779225826263\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04270089790225029\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061397161334753036\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08661512285470963\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.02425435557961464\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06203048676252365\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.088277667760849\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014383473433554173\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02152256667613983\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04773446545004845\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.045059677213430405\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.1252652108669281\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05242423713207245\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03357381001114845\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005444463342428207\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07233742624521255\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.04300358146429062\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06851789355278015\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04269615560770035\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06151167303323746\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08660143613815308\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.024215616285800934\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06190662458539009\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08822996914386749\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014511089771986008\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020958220586180687\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04731471836566925\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04498147591948509\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12472502142190933\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05222179740667343\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033622510731220245\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005428950767964125\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07216668874025345\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04468829929828644\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06864192336797714\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042696066200733185\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.0613144114613533\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08652309328317642\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.024202488362789154\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.062011074274778366\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08829925954341888\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014296203851699829\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02137901447713375\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04794751852750778\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.045089490711688995\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12471719086170197\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05247155949473381\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.033511485904455185\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005421000067144632\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07219713181257248\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04557335376739502\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.0690060630440712\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042810820043087006\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06161705031991005\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08680593222379684\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.024293536320328712\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06207098439335823\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08824741095304489\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014315551146864891\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.022471746429800987\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04775694012641907\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.044995587319135666\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12569460272789001\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.052055176347494125\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03356495127081871\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005492452997714281\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.0725768581032753\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.042566776275634766\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06890524923801422\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042794469743967056\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06154195964336395\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.0870160311460495\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.024296864867210388\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.062182046473026276\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08833999931812286\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014555821195244789\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02054706960916519\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04692462459206581\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04491223394870758\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12576079368591309\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.052414845675230026\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03342416509985924\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005468779243528843\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.0727928951382637\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04213101044297218\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.068588487803936\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.0428604930639267\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.061913423240184784\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08660031110048294\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.024183239787817\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06186501309275627\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08824419975280762\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.01439808402210474\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02089039981365204\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04716319218277931\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044960979372262955\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12513262033462524\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05186359956860542\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033404309302568436\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.0054703522473573685\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07239159941673279\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04332304373383522\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06935495138168335\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269595444202423\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.0614401251077652\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08667965233325958\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.024186884984374046\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061880387365818024\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08826383948326111\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01456610206514597\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.021059442311525345\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.046872206032276154\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04490111023187637\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12600789964199066\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05240485817193985\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03339207544922829\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005495165009051561\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07298843562602997\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04223567619919777\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06867729127407074\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04288892447948456\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06197439879179001\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08664748817682266\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.024131769314408302\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06181655824184418\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08824838697910309\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014397120103240013\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020672734826803207\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04715613275766373\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04495098069310188\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1251380890607834\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05166780576109886\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03338443860411644\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005434221122413874\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07216683030128479\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04339226707816124\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06956684589385986\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04269992560148239\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06149368733167648\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08669733256101608\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.024163171648979187\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06184178963303566\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08823693543672562\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014507293701171875\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02101168781518936\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.0468980111181736\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04490308463573456\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12522149085998535\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.0519719161093235\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03340128809213638\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.00544089125469327\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07283121347427368\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04259043186903\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06961163133382797\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042741984128952026\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06152654066681862\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08669774979352951\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.024096466600894928\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061922717839479446\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08836125582456589\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014579089358448982\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020681211724877357\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04687771946191788\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044910091906785965\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1256323903799057\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05221174284815788\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033344000577926636\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005498887971043587\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07324613630771637\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04293189197778702\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06867611408233643\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04301097244024277\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061906859278678894\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08653876930475235\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.024022959172725677\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06182939559221268\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.088185153901577\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.0142325758934021\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02044910378754139\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04714219272136688\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04493868350982666\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.1248031035065651\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.051506590098142624\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03332170099020004\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.00550673296675086\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07261017709970474\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04176744446158409\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06924019008874893\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04269621521234512\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06155730411410332\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08658767491579056\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.024054991081357002\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061678797006607056\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08818772435188293\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014658689498901367\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.021105626598000526\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.046684227883815765\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04489525780081749\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1246243342757225\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05149426311254501\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03343069925904274\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005411096848547459\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07220581918954849\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.042154401540756226\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06783106923103333\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04271572083234787\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061379965394735336\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08695066720247269\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02422874979674816\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06234251707792282\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08839704841375351\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.01444570068269968\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.021505456417798996\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.047128256410360336\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04495081305503845\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12599265575408936\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.052459437400102615\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033328671008348465\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005539019126445055\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07310865819454193\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04160574823617935\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06878509372472763\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04296813905239105\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06184890493750572\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08677402883768082\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02407016046345234\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06187712401151657\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08821240812540054\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014349761418998241\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020461445674300194\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04693920537829399\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04490206390619278\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.1252325475215912\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05180548131465912\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03332240879535675\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005592331290245056\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07358847558498383\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.0419936403632164\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06869152933359146\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042738400399684906\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06156309321522713\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08660479635000229\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02405998297035694\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06172981485724449\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08818172663450241\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014420563355088234\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020235687494277954\n",
      "Search Iteration [4/20], Validation Loss: 0.055909902932630345\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.0810910165309906\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.10445483028888702\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12507881224155426\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06002156063914299\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.048850223422050476\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.005721746943891048\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.07892788201570511\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.04528162255883217\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07394880801439285\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04525626450777054\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06519778817892075\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.12379725277423859\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.024303920567035675\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06692305207252502\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.1014937311410904\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04524891451001167\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.024758480489253998\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.058460820466279984\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.0461207777261734\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12449762225151062\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05263301730155945\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.040404073894023895\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.009052331559360027\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.08367110788822174\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04194680228829384\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.0918019488453865\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.048718519508838654\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06562136858701706\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.10568032413721085\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.025047095492482185\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06422893702983856\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08813556283712387\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.014096565544605255\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02864479273557663\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04668990150094032\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05048135295510292\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12435557693243027\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.051146864891052246\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033395640552043915\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005419067572802305\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07203062623739243\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.043786752969026566\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.0676153376698494\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.047929298132658005\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06328219920396805\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.09081771969795227\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024837689474225044\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06197115778923035\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08842432498931885\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014064482413232327\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.020693017169833183\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04674255847930908\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04510984942317009\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12450583279132843\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.0518093965947628\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03338029980659485\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005495376884937286\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07179346680641174\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04102735593914986\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.0709301233291626\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04351603239774704\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.061312947422266006\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08796842396259308\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02427048049867153\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06258422881364822\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08801770210266113\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014133631251752377\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02056911401450634\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.046589311212301254\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04670150578022003\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12480108439922333\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.0531306155025959\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03337828069925308\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005456022918224335\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07271447032690048\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04101065918803215\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07118711620569229\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04312232509255409\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061313699930906296\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08660989254713058\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023854989558458328\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06221722811460495\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08798462897539139\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014043784700334072\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02057749032974243\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.0470285601913929\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.045440420508384705\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12826091051101685\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.051730137318372726\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.034584760665893555\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0060761296190321445\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07368475198745728\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04111087694764137\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07411184161901474\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04290476068854332\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.061693400144577026\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08639983087778091\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02378142811357975\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06188254803419113\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08798390626907349\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014027495868504047\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.0207411739975214\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04664870351552963\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04527333378791809\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12564842402935028\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05113741010427475\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03333286941051483\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005441790912300348\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07179347425699234\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04116825759410858\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06910531222820282\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04310253635048866\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06149639934301376\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08739273995161057\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023954665288329124\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.0623154453933239\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08800234645605087\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014040723443031311\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020410874858498573\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04692787304520607\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.045172449201345444\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12473491579294205\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05185816064476967\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.0333239883184433\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005535999312996864\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07181978970766068\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.041253745555877686\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07088933140039444\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04274431988596916\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06128917261958122\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.0865698754787445\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023778190836310387\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06243427097797394\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.0880235806107521\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014111478812992573\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020549282431602478\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.046757813543081284\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.0451853945851326\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12558434903621674\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.051148418337106705\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033332012593746185\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005474286153912544\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07215680181980133\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04104553908109665\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.0682651549577713\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04329312965273857\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061434704810380936\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08719634264707565\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023936554789543152\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06224308907985687\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.0879795253276825\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014042399823665619\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02059915103018284\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04670771211385727\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04541410878300667\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12567347288131714\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.0511358417570591\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.033324774354696274\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005473901052027941\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07232637703418732\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.041011471301317215\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06866029649972916\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.043080806732177734\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061398204416036606\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08697504550218582\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023906167596578598\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06224621459841728\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08798437565565109\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01404185127466917\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020622147247195244\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04663655906915665\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04536258801817894\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12649200856685638\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05139462649822235\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033464886248111725\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005623860750347376\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07178942114114761\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.041193898767232895\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.07110536098480225\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.042737025767564774\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061382047832012177\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08638645708560944\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023893414065241814\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06228392571210861\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08799964189529419\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014043332077562809\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.02079150453209877\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04658696427941322\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.044958047568798065\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12697505950927734\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05170838534832001\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.033802639693021774\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005815288983285427\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07235829532146454\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.042144373059272766\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.07233600318431854\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04276109114289284\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06132565438747406\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08634864538908005\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023917680606245995\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06258146464824677\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08811131864786148\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014024804346263409\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020724110305309296\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.048269033432006836\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.0448421910405159\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1243535578250885\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05158013850450516\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.0333746112883091\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005457209888845682\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07203401625156403\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04149120673537254\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.07310447841882706\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.0428309366106987\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.061288099735975266\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08658885955810547\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023835204541683197\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06251318007707596\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08831153810024261\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01422771718353033\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02034328505396843\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.0490034781396389\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04484742507338524\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.1244029626250267\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05185510218143463\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033326879143714905\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.0054213181138038635\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07187586277723312\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04118558019399643\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06944931298494339\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04269661381840706\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06128549575805664\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08684135228395462\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02385750226676464\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.062249984592199326\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08826210349798203\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014182700775563717\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02037997730076313\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.048068687319755554\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.044839609414339066\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12439554929733276\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05159417539834976\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03332384303212166\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005433959886431694\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07175673544406891\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.041256967931985855\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.07038980722427368\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04269596189260483\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06128578633069992\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08669763058423996\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023863067850470543\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.062373243272304535\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08819833397865295\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014132937416434288\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02040613628923893\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04782845079898834\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.044856730848550797\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12455037236213684\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05136537924408913\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03332190215587616\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005438097752630711\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07191219180822372\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04119737073779106\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06985683739185333\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042719773948192596\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.0612768679857254\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08669380843639374\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02388388104736805\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06238046661019325\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08808967471122742\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014058101922273636\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020463699474930763\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04742681607604027\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04492237791419029\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12489227205514908\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05120319500565529\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03332138806581497\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005441316403448582\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07219637930393219\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.041163813322782516\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06893781572580338\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04282429814338684\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06128484383225441\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08681546151638031\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.0239393450319767\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.0623062402009964\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08800717443227768\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014019827358424664\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020562324672937393\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.047005824744701385\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.045061562210321426\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12546825408935547\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.051136478781700134\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03332207724452019\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005447333212941885\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07232481241226196\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04130122438073158\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06857404112815857\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04283516854047775\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06129994988441467\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08680295199155807\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02401035651564598\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06220491975545883\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.0879799872636795\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.01409524492919445\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.02071182243525982\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.046693895012140274\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04511350765824318\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12639273703098297\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.051526349037885666\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03345351666212082\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005700891371816397\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07182987034320831\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04244288429617882\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07035704702138901\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04271865263581276\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06128740310668945\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08635443449020386\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.024053214117884636\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06259578466415405\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08798842877149582\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014063294976949692\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020869508385658264\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04695044830441475\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04487347975373268\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12546494603157043\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.051248058676719666\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03338516503572464\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005508751608431339\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.0718044564127922\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.044483646750450134\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07219681888818741\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.043246008455753326\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06152496114373207\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08634749799966812\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.0239599347114563\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06252121925354004\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08807189017534256\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014030266553163528\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020469509065151215\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04807440936565399\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.044838372617959976\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12442505359649658\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05125053599476814\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03343348577618599\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.0055143567733466625\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07185176014900208\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.056584086269140244\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.07920058071613312\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04545954242348671\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06163623183965683\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08753097057342529\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.02407263219356537\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06225406751036644\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08871671557426453\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014267132617533207\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020204642787575722\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.05033900588750839\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04489694908261299\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12512607872486115\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05181911215186119\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03332454338669777\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.00541222607716918\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07180829346179962\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04476562887430191\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07082504779100418\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.043303150683641434\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061464469879865646\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08694136142730713\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02397673763334751\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06202036887407303\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08856634795665741\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014113272540271282\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020256415009498596\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.05010534077882767\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.044839780777692795\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12458683550357819\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05188066139817238\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033436182886362076\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005441315937787294\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07214626669883728\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04304113611578941\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07021956890821457\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.043230704963207245\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.061395078897476196\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08652026951313019\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023940548300743103\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06216481328010559\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08843183517456055\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01404706109315157\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020295239984989166\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04918275028467178\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04485204443335533\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12437772750854492\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.0517205148935318\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03346249461174011\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005440307781100273\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07298580557107925\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04468180984258652\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.0723700150847435\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04380427300930023\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06132839620113373\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08642697334289551\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023892315104603767\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.0623028539121151\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.0885668694972992\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014081918634474277\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02021736092865467\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.049439698457717896\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04486283287405968\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12440383434295654\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.051694177091121674\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03347541019320488\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005445145070552826\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.0732378140091896\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04994272440671921\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07644137740135193\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.044669631868600845\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.061609942466020584\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.0869523286819458\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02392302080988884\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06227680295705795\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08876826614141464\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014121022075414658\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020165612921118736\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.05002663657069206\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04488147795200348\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12444525957107544\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.051677532494068146\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033499881625175476\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005462359171360731\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07325311005115509\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.05150904133915901\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07458821684122086\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.044636115431785583\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06159456819295883\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08681575208902359\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023860380053520203\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06218264624476433\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.0886315181851387\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014051620848476887\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02020092122256756\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04905485361814499\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04554271325469017\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.1243535578250885\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05164262279868126\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03332417830824852\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005431960336863995\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07398449629545212\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04180043190717697\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07254432886838913\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.042994916439056396\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06147674843668938\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08636380732059479\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023884331807494164\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.062205664813518524\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08834253996610641\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.01401880569756031\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020503677427768707\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.049131840467453\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044924262911081314\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12436144798994064\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05163796991109848\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03349658101797104\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005476268939673901\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07437588274478912\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.043861500918865204\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07340018451213837\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.043615132570266724\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06157499551773071\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08653539419174194\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023881563916802406\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06238032132387161\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08853223919868469\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014022018760442734\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020262548699975014\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.05012958124279976\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04492906108498573\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12435662001371384\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05158445984125137\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033544473350048065\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005480841267853975\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.0745999738574028\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04773765802383423\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07269253581762314\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04410351440310478\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06159722059965134\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08654821664094925\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023840969428420067\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.062306370586156845\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08844856172800064\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014020119793713093\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02020740881562233\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.05005626007914543\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04491143301129341\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12441737949848175\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05147130414843559\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03356747329235077\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005463635083287954\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.0750177651643753\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.05670761317014694\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06989376246929169\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04343554750084877\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.0614706426858902\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08686649799346924\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02387961745262146\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06222299113869667\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08827193081378937\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014048228971660137\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02023218758404255\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04959477111697197\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04491627216339111\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12477269768714905\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05138257145881653\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.033540990203619\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005442484747618437\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07508686929941177\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.05420380458235741\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06767237931489944\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04279542714357376\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.0613190233707428\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08673124015331268\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023920493200421333\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06237585470080376\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.0882558599114418\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014073507860302925\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020182425156235695\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04991303011775017\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04490261524915695\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12478271871805191\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05143069848418236\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033554770052433014\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005461918655782938\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07455968111753464\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.05435926094651222\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06759561598300934\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042828816920518875\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.061281174421310425\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08717846870422363\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02403973415493965\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.062355149537324905\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08818583190441132\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014066756702959538\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020184921100735664\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.048957571387290955\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04493102431297302\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12504316866397858\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.051440346986055374\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.033592820167541504\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005480325315147638\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07400799542665482\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.05000458285212517\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06840621680021286\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.042946211993694305\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06127932667732239\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08693090081214905\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.024066440761089325\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06216726452112198\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08819305151700974\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014099097810685635\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020167086273431778\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.0483611524105072\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.044924668967723846\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1252247840166092\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05173918977379799\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.034239962697029114\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005980248562991619\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07392498850822449\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04718542471528053\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07011932879686356\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04291202872991562\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.061279673129320145\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08646851778030396\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.02413005568087101\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06264395266771317\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08826182782649994\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014139020815491676\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020569467917084694\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.0495259165763855\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04486369341611862\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12479564547538757\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05234414339065552\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03430890291929245\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0056454953737556934\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07505656033754349\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.052390001714229584\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06804123520851135\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.042915571480989456\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08889134973287582\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.024037940427660942\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.0628102496266365\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08816548436880112\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01411878876388073\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020684778690338135\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04934990778565407\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044865865260362625\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12598010897636414\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05369918420910835\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.034195803105831146\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005441902205348015\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07185856252908707\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.047764651477336884\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06780010461807251\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.043126288801431656\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06127985566854477\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08839157968759537\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.024132203310728073\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06219366937875748\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08813732862472534\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.01415299903601408\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.021008744835853577\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.049364157021045685\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04490054026246071\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12534265220165253\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.053580887615680695\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03401685506105423\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.0054138884879648685\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07181033492088318\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.04399939998984337\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06862737983465195\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04269597679376602\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06136235594749451\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08670282363891602\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.02395332232117653\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06189578399062157\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.0880073830485344\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.01413656771183014\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.021729182451963425\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.049699753522872925\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04493193328380585\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12512394785881042\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.053445469588041306\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033642783761024475\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005445968825370073\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.0724179595708847\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.041969362646341324\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06845561414957047\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.0427284836769104\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061466284096241\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08637137711048126\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023922862485051155\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.061975304037332535\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08800632506608963\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014143472537398338\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.0210865568369627\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04923287406563759\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044970110058784485\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12523165345191956\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05338601395487785\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03350946307182312\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005432557314634323\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07257959246635437\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.041423726826906204\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06852744519710541\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04273708909749985\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.061390820890665054\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08640951663255692\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02396605908870697\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.061991166323423386\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08810605853796005\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014200353063642979\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.021533101797103882\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.048750631511211395\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04496035352349281\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12573404610157013\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05364430695772171\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03350234031677246\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005434860475361347\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07267878949642181\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04186343774199486\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06856806576251984\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042705267667770386\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.061343058943748474\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.0863494947552681\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023910338059067726\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06173482537269592\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08801310509443283\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014210228808224201\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.021809764206409454\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04805224388837814\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044938039034605026\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12578867375850677\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05344003438949585\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033456332981586456\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005446354392915964\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07273893803358078\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.041406795382499695\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06859275698661804\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.0427144393324852\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06133018434047699\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08642616868019104\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.0239276010543108\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.061783112585544586\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08805222064256668\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014229982160031796\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02126348949968815\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04814637452363968\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04495864734053612\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12604306638240814\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.053559109568595886\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033439524471759796\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005445701070129871\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07277065515518188\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.041618362069129944\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06869714707136154\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269927367568016\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06130557879805565\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08639216423034668\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02389737404882908\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061710424721241\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08802951872348785\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014230825938284397\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.021223722025752068\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04790729284286499\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044938135892152786\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.1260181963443756\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05348984897136688\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033434946089982986\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005442120600491762\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07269279658794403\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04147786274552345\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.0687623843550682\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042699072510004044\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.061297398060560226\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08646772801876068\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023907411843538284\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06174180284142494\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08806182444095612\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014224779792129993\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.021017592400312424\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04808960109949112\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04496680200099945\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1259118914604187\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05355410650372505\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033429522067308426\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.00544350128620863\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07267101854085922\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04173796623945236\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06885015219449997\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.0426960252225399\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061288073658943176\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08642519265413284\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02387906238436699\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.061691734939813614\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08804119378328323\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014211251400411129\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.021172095090150833\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04794777184724808\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.044950857758522034\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1259291023015976\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05349336564540863\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03342488408088684\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.0054428232833743095\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07261751592159271\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04161074757575989\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06885062903165817\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04269622638821602\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.0612838938832283\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08648049086332321\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023879991844296455\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06170071288943291\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08806931972503662\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.01420352142304182\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020942553877830505\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04801613837480545\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04496641829609871\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1258397102355957\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05351676046848297\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03343087062239647\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005439182743430138\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07255811244249344\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04184845834970474\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06892336159944534\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042701318860054016\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06127843260765076\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08645319193601608\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023860706016421318\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06167395040392876\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08805819600820541\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014191251248121262\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.021052377298474312\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04790910705924034\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04495398700237274\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12583115696907043\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05346987769007683\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033431995660066605\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.0054368916898965836\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.0724979043006897\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04181428253650665\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.0689225047826767\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04270423576235771\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06127699837088585\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08648087829351425\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02385479398071766\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06167273223400116\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08807606995105743\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014179843477904797\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.02088899537920952\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.047938644886016846\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04496176168322563\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12574101984500885\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05347331613302231\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03343706205487251\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005434059537947178\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07243695855140686\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.042039088904857635\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06899261474609375\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042713988572359085\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06127697601914406\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08646633476018906\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02384241856634617\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.061661239713430405\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08807305246591568\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014168579131364822\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020969999954104424\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04787972941994667\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.044954072684049606\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12571191787719727\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05343612655997276\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.0334404893219471\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005431114695966244\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.0723864734172821\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04197835922241211\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.069008968770504\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.042717643082141876\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06127847731113434\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08649377524852753\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02383570186793804\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.0616595484316349\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08808719366788864\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.01415605191141367\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020832378417253494\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04793651029467583\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044965244829654694\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12557505071163177\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05341000854969025\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033446963876485825\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005427626892924309\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07232733815908432\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04223981127142906\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.0690850019454956\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042730145156383514\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061284590512514114\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08648159354925156\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02382776327431202\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061653848737478256\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08808653056621552\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014145736582577229\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02094976231455803\n",
      "Search Iteration [5/20], Validation Loss: 0.06296116624196822\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.0832270011305809\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.05354199558496475\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12971872091293335\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.059109002351760864\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.05386922508478165\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.04481947794556618\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.1705077439546585\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.25457119941711426\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08851753920316696\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.0897984504699707\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.07742854207754135\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.2095676213502884\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02659391611814499\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06301672756671906\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09920792281627655\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.045140355825424194\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.04795024171471596\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.061955615878105164\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.06313709914684296\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12537148594856262\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.07166500389575958\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.04594874009490013\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.02052345871925354\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.1193321943283081\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.09001973271369934\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.10999473184347153\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04414936155080795\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06194973364472389\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1715935915708542\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02865190990269184\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06269628554582596\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08969902992248535\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.031861562281847\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02028932049870491\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.047567419707775116\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04835454747080803\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12740463018417358\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05160679668188095\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033493928611278534\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.008631481789052486\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07409761846065521\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.05647863447666168\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.08028508722782135\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04291775822639465\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06503289192914963\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.0865091010928154\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.02419722080230713\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.07000138610601425\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08813014626502991\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014966198243200779\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.023808259516954422\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04897237941622734\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04486164450645447\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12890969216823578\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.0511382520198822\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03341686353087425\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005433312617242336\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07474074512720108\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.0544329397380352\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.08170776814222336\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04278251901268959\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06347338110208511\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08869156241416931\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02385413832962513\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.0651620402932167\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.0879812091588974\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014756323769688606\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.021790413185954094\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04783949628472328\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04518359154462814\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1275072544813156\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051144298166036606\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.0333438478410244\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005467971321195364\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07791303098201752\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.05963296815752983\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.08505884557962418\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.0427415668964386\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06305700540542603\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08653393387794495\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02369162067770958\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06302278488874435\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08798068016767502\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014801528304815292\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.021032113581895828\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04745648056268692\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04534074664115906\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.127483531832695\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05114595592021942\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03338030353188515\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005518809426575899\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07942446321249008\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.05319810286164284\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.08137217164039612\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04271330311894417\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06233590841293335\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08639386296272278\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02371353469789028\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06218438223004341\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08800261467695236\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.015054503455758095\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02063891291618347\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04716269671916962\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04527047649025917\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12735618650913239\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05119030922651291\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03339029848575592\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005493701435625553\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.0804777517914772\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.050439707934856415\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07881004363298416\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04272022843360901\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06181034445762634\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08666429668664932\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023758606985211372\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06187521666288376\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.0880548506975174\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.015546641312539577\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02044384926557541\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04693574830889702\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04504595324397087\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12746822834014893\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.0512724407017231\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.0334630012512207\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005476510617882013\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.08071821182966232\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04759194701910019\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07609672099351883\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04271196946501732\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06157878786325455\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08682948350906372\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023795446380972862\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.061780039221048355\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08805977553129196\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.015524029731750488\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020374014973640442\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04687599465250969\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04504287987947464\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12719745934009552\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05130946263670921\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.0334557481110096\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005458431784063578\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.08041100203990936\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.045743029564619064\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.0744209811091423\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.0427122488617897\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06147024780511856\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08676610887050629\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023788779973983765\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06173718348145485\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.0880386158823967\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.015312242321670055\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020353343337774277\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.046850040555000305\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04510020092129707\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12680889666080475\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05132497474551201\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.033410970121622086\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.0054484764114022255\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07979251444339752\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04437245801091194\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07312791049480438\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042715173214673996\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06140397861599922\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08662799745798111\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023763351142406464\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06170893460512161\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08801170438528061\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.015081264078617096\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020341649651527405\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04683545604348183\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04510781168937683\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.1265150010585785\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05135799199342728\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03339269384741783\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005453042685985565\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07905098795890808\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04327789321541786\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.07188692688941956\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04271416366100311\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061357803642749786\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08650606125593185\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023737449198961258\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06169069558382034\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08799148350954056\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014894355088472366\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020332785323262215\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04680129885673523\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04506923258304596\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12631003558635712\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.0514175146818161\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.033390164375305176\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.00546693243086338\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07815833389759064\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.0423385351896286\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.07076917588710785\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.042708151042461395\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.0613301582634449\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.086411252617836\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023714173585176468\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06168270483613014\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.0879802480340004\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014720169827342033\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020329145714640617\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046760302037000656\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04501725733280182\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12615014612674713\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05149662867188454\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03338922932744026\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.0054847849532961845\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07717923074960709\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.041635479778051376\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06983543187379837\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042701032012701035\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06131333112716675\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.086358942091465\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02369682863354683\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06168053671717644\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08798324316740036\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014567192643880844\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020327089354395866\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046719275414943695\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04496105760335922\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12602514028549194\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051597535610198975\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03338692709803581\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005504863802343607\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07617796957492828\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04119826480746269\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06909111142158508\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042696304619312286\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06130329519510269\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08634733408689499\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023687398061156273\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.061681319028139114\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08800076693296432\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014437598176300526\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02032419852912426\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04668579250574112\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.044909294694662094\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12592577934265137\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05172201618552208\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03338195011019707\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005524522624909878\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07523728162050247\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04102015495300293\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06852726638317108\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04269786924123764\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06129744276404381\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08635855466127396\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023685168474912643\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06168220564723015\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08802594244480133\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014334436506032944\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020319731906056404\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04666239768266678\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04486967995762825\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12584081292152405\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05186847597360611\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03337317705154419\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005539495963603258\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07447176426649094\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04104334115982056\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06812536716461182\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042707718908786774\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.0612935833632946\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08636897057294846\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023686988279223442\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06168007105588913\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08804531395435333\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014262441545724869\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02031516842544079\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.046645887196063995\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04484609514474869\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12576016783714294\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05203154683113098\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03336084261536598\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005545572377741337\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.0739610567688942\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04115269333124161\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06786137819290161\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042722370475530624\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06129033491015434\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0863659605383873\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023689212277531624\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06167368218302727\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08804860711097717\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.01421494409441948\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02031172811985016\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04663596674799919\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04483795911073685\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12567833065986633\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.052205465734004974\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03334686905145645\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005541397724300623\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07363813370466232\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04126277565956116\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06770492345094681\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042736902832984924\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06128789857029915\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.0863560363650322\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023690123111009598\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.0616653710603714\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08803791552782059\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014175081625580788\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.0203078705817461\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04663877561688423\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04484018310904503\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.125596284866333\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.052385952323675156\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03333382308483124\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005529586225748062\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07338252663612366\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.041364286094903946\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06762229651212692\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04274988919496536\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061286672949790955\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08634878695011139\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02368984930217266\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06165805459022522\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08802124857902527\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014137737452983856\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020301880314946175\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04665995389223099\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.044846970587968826\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12552841007709503\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05258071795105934\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03332455828785896\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005514991469681263\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07316428422927856\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.041455719619989395\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06758718192577362\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04275950416922569\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06128614395856857\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08634719997644424\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023688795045018196\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06165328249335289\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08800479024648666\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014106099493801594\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020293693989515305\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04670586809515953\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04485611245036125\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12549163401126862\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05280356854200363\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033321358263492584\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005500381346791983\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07299269735813141\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04153227433562279\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06757993996143341\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04276437684893608\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061285607516765594\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08635063469409943\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023687446489930153\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06165146082639694\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08799213171005249\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014081712812185287\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020284684374928474\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04678252711892128\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04486628249287605\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12548717856407166\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05305064097046852\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.033325210213661194\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005486327689141035\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07287038862705231\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.0415937565267086\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06758790463209152\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04276534914970398\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06128467991948128\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08635649085044861\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02368628978729248\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06165193393826485\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08798437565565109\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014063992537558079\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020276689901947975\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04688768461346626\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.044874902814626694\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12550199031829834\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.053298383951187134\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033334847539663315\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005473456811159849\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07279141992330551\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.041639115661382675\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06760376691818237\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04276428371667862\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.061283424496650696\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08636178821325302\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023685572668910027\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06165345758199692\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08798065036535263\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014051438309252262\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020270777866244316\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04700876772403717\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044879503548145294\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12552085518836975\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.053521301597356796\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03334729000926018\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005462566390633583\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07274433225393295\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04166768491268158\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06762319058179855\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.0427628792822361\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06128207594156265\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08636471629142761\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.02368524670600891\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.061655037105083466\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08797954022884369\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014042606577277184\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020266830921173096\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.047130052000284195\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04487904533743858\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12553364038467407\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05370425060391426\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.033359602093696594\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005453992635011673\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07271690666675568\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.041681595146656036\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06764349341392517\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04276222735643387\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.061280883848667145\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.0863652378320694\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.0236851517111063\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06165621802210808\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08797989785671234\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014036430045962334\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.0202640350908041\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.047240182757377625\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04487399011850357\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.1255360245704651\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05384402349591255\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03336997330188751\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.0054476442746818066\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.072700634598732\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.041684381663799286\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06766311079263687\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.042762745171785355\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06127993389964104\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08636417984962463\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023685161024332047\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06165700405836105\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08798106014728546\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014032173901796341\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02026154287159443\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04733354598283768\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04486582800745964\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12552709877490997\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05394385755062103\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03337760642170906\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005443233996629715\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07269095629453659\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.041679173707962036\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06768124550580978\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04276447743177414\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06127920374274254\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08636245876550674\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02368520013988018\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06165749579668045\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08798270672559738\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014029305428266525\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020258724689483643\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04740888625383377\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044856514781713486\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.1255076825618744\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.0540095716714859\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03338240459561348\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005440428387373686\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07268557697534561\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04166838154196739\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06769764423370361\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04276734218001366\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06127864494919777\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08636068552732468\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023685241118073463\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06165784224867821\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08798466622829437\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014027424156665802\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020255232229828835\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04746723920106888\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04484790563583374\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12547935545444489\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05404695123434067\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03338460624217987\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0054389298893511295\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07268326729536057\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.041653964668512344\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06771220266819\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042771171778440475\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06127823889255524\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08635915815830231\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.02368527464568615\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06165814772248268\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08798688650131226\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.01402624137699604\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020250916481018066\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047510694712400436\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.044841468334198\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12544378638267517\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.054060906171798706\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.033384595066308975\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005438494961708784\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07268335670232773\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.041637204587459564\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06772496551275253\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04277580603957176\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061277903616428375\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08635804057121277\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023685285821557045\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06165844574570656\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08798930048942566\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.0140255531296134\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020245790481567383\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.047541458159685135\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04483814537525177\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12540249526500702\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05405548959970474\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03338276967406273\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.00543895224109292\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07268543541431427\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.041619159281253815\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06773590296506882\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.042781103402376175\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06127765029668808\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08635734766721725\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023685289546847343\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06165875121951103\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08799190074205399\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.01402521412819624\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02023993246257305\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.047561805695295334\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04483839124441147\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.1253572404384613\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.054034311324357986\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033379554748535156\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.00544016482308507\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07268917560577393\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.041600558906793594\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06774508208036423\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04278689995408058\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06127745658159256\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08635705709457397\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023685283958911896\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.061659082770347595\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08799462765455246\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014025134034454823\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020233480259776115\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04757355526089668\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04484228044748306\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1253092885017395\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05400009825825691\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03337528929114342\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.0054420409724116325\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07269437611103058\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.041582029312849045\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06775251030921936\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.042793069034814835\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061277296394109726\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08635713905096054\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.02368527092039585\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06165944039821625\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08799745887517929\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014025239273905754\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020226601511240005\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04757829010486603\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.044849615544080734\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1252598613500595\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05395527556538582\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033370304852724075\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005444504786282778\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07270082086324692\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04156406223773956\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.0677582323551178\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04279947280883789\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06127715855836868\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08635757863521576\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023685254156589508\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06165981665253639\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0880003571510315\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.01402547862380743\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02021947130560875\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04757728427648544\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04486003518104553\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.1252099573612213\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05390192195773125\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033364880830049515\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.00544748967513442\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07270832359790802\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04154709726572037\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06776237487792969\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04280601069331169\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06127705052495003\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08635832369327545\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023685241118073463\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061660200357437134\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08800327032804489\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014025809243321419\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020212264731526375\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04757154360413551\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044873058795928955\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.1251603364944458\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.053841713815927505\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03335924074053764\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005450936034321785\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07271675765514374\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04153136909008026\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06776504218578339\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04281257465481758\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06127694621682167\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08635936677455902\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.02368522807955742\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06166059151291847\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.0880061686038971\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014026197604835033\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02020515501499176\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.047561753541231155\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04488816484808922\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12511169910430908\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05377619341015816\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033353593200445175\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005454782862216234\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07272598892450333\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.0415169931948185\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06776638329029083\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04281909391283989\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061276860535144806\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08636070042848587\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023685218766331673\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06166099011898041\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08800902217626572\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.01402660645544529\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020198313519358635\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047548625618219376\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04490480571985245\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12506462633609772\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05370669811964035\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03334808722138405\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005458975676447153\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07273595780134201\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04150404408574104\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06776655465364456\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042825497686862946\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06127678602933884\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08636226505041122\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023685213178396225\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.061661381274461746\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08801178634166718\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014027012512087822\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020191892981529236\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04753255471587181\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04492248594760895\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12501953542232513\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05363420397043228\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03334284573793411\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005463465116918087\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07274661213159561\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04149249568581581\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06776569038629532\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042831748723983765\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06127673760056496\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08636406809091568\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023685209453105927\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06166175380349159\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08801442384719849\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014027382247149944\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020186010748147964\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04751408100128174\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04494071379303932\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.124976746737957\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05355977267026901\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03333798795938492\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005468206014484167\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07275780290365219\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.041482459753751755\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06776399165391922\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042837824672460556\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.061276692897081375\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08636604994535446\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023685211315751076\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06166210025548935\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08801690489053726\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014027709141373634\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020180782303214073\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04749351739883423\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044959161430597305\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12493645399808884\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.053483881056308746\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03333360329270363\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005473152734339237\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07276953756809235\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.041474051773548126\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06776169687509537\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04284374415874481\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08636821061372757\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023685216903686523\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06166242063045502\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.0880192443728447\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014027981087565422\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02017628401517868\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04747122898697853\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044977545738220215\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12489870190620422\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05340705066919327\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.0333297923207283\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005478250794112682\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07278146594762802\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.041467584669589996\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06775900721549988\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04284949228167534\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.0612766407430172\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08637052029371262\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02368522621691227\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06166272610425949\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.088021419942379\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014028193429112434\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020172560587525368\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04744728282094002\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.0449957475066185\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12486343830823898\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05332935228943825\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03332662954926491\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005483435001224279\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07279355078935623\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04146350547671318\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06775619089603424\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04285508766770363\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.0863729938864708\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02368524670600891\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06166300177574158\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08802345395088196\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014028357341885567\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020169643685221672\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.047421760857105255\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04501371085643768\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12483057379722595\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05325097218155861\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03332418203353882\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005488621070981026\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07280544191598892\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04146216809749603\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06775344908237457\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04286052659153938\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061276622116565704\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08637561649084091\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02368527464568615\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06166325509548187\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08802534639835358\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014028473757207394\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020167535170912743\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04739448055624962\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04503146559000015\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12480005621910095\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05317186936736107\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03332248330116272\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005493703298270702\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.0728171318769455\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04146416857838631\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06775101274251938\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04286576807498932\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08637841045856476\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023685313761234283\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06166350096464157\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08802712708711624\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014028562232851982\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020166216418147087\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04736525937914848\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.045049037784338\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12477181106805801\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05309193953871727\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033321548253297806\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.0054985457099974155\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07282837480306625\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04147003963589668\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.0677490159869194\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04287077859044075\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061276648193597794\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08638142794370651\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02368536777794361\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061663731932640076\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08802884817123413\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014028630219399929\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020165646448731422\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04733378067612648\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.045066528022289276\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12474582344293594\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05301111564040184\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033321380615234375\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.0055029792711138725\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07283902168273926\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04148057475686073\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06774763017892838\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04287548363208771\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06127667799592018\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08638471364974976\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02368544042110443\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06166398525238037\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08803056180477142\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014028710313141346\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020165763795375824\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.047299664467573166\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04508405551314354\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12472209334373474\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.052929189056158066\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03332194685935974\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005506786517798901\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07284870743751526\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04149690270423889\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06774692237377167\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04287976771593094\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06127673014998436\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08638838678598404\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023685531690716743\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06166425347328186\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08803234994411469\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014028826728463173\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02016647532582283\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.047262560576200485\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04510176554322243\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12470056861639023\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05284589156508446\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03332321718335152\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.00550969410687685\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07285667210817337\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04151986539363861\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06774692237377167\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04288345202803612\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06127683073282242\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08639245480298996\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.0236856397241354\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.061664581298828125\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08803429454565048\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.01402899157255888\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02016766555607319\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04722236841917038\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04511965066194534\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12468133866786957\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05276190862059593\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033325083553791046\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005511370487511158\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07286176830530167\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04155035689473152\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06774760782718658\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042886488139629364\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06127697601914406\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08639689534902573\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02368575893342495\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061664879322052\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08803623914718628\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014029202051460743\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02016918919980526\n",
      "Search Iteration [6/20], Validation Loss: 0.06969920200380413\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.11482830345630646\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.06787723302841187\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.13907337188720703\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05628140643239021\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.05360151082277298\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.04027632251381874\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.1728922426700592\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.2275223582983017\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.11049331724643707\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.08211613446474075\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06846121698617935\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.2198878824710846\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02502119541168213\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06204800307750702\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09747098386287689\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04449561610817909\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.04558589681982994\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.06325096637010574\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.06294318288564682\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1253449022769928\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.07246344536542892\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.042809467762708664\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.013956140726804733\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.13064369559288025\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.07543627172708511\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.11302974075078964\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04435719922184944\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06271037459373474\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1676807850599289\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02773904986679554\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06298153102397919\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.089646115899086\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.02997848391532898\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.020474249497056007\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.049316734075546265\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05141782760620117\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12677277624607086\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05404327064752579\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03332146257162094\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.006286474410444498\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07190663367509842\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04156004637479782\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.07222452014684677\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.042799029499292374\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06583745032548904\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08749762922525406\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.023851387202739716\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.0707252025604248\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08802249282598495\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014383113943040371\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.023838665336370468\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04740854725241661\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04559291899204254\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12799473106861115\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05116766318678856\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03333001956343651\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005421652924269438\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07223763316869736\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04189971461892128\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06818746030330658\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04303918778896332\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06391417980194092\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08643436431884766\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023877840489149094\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06404236704111099\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08810219913721085\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014142699539661407\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02215340919792652\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04775587096810341\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04496359825134277\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1275266855955124\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051907651126384735\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.0333547368645668\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.006138058379292488\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.0721987783908844\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04264160990715027\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06773604452610016\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04305640235543251\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.0625920370221138\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08666299283504486\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023742204532027245\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06266099214553833\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08811536431312561\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014187974855303764\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02102540247142315\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04763348773121834\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044849228113889694\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12691986560821533\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.052401285618543625\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03343156725168228\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.00626444723457098\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.0723518654704094\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.042415473610162735\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.0676562488079071\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04304680973291397\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06219298392534256\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08647389709949493\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023761499673128128\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.062090564519166946\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08817961812019348\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014264486730098724\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.0205098744481802\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04759729653596878\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.0448378287255764\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.1267446130514145\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.052694953978061676\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03343765810132027\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.00620909221470356\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07251685112714767\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.042593780905008316\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06761004030704498\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04308865964412689\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061992891132831573\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08635459095239639\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023812564089894295\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.0618092343211174\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08825389295816422\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014348622411489487\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020280448719859123\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04758845642209053\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04484141990542412\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12662416696548462\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05286233872175217\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03341952711343765\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.006098014768213034\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07265199720859528\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04286963865160942\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06758647412061691\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04311969876289368\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061853110790252686\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08636488020420074\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.0238634143024683\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06168635934591293\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08831209689378738\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014409317634999752\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020193323493003845\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04760000854730606\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04484957829117775\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12649878859519958\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05297813564538956\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033404819667339325\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005983274895697832\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07275819033384323\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.043074123561382294\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06757982075214386\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.043122418224811554\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061744604259729385\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0864316001534462\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023898420855402946\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06165197864174843\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08834695816040039\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014431800693273544\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020168358460068703\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047631315886974335\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04485798999667168\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1263769119977951\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.053085532039403915\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03339928761124611\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005883579142391682\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07283766567707062\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.043176911771297455\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06758438050746918\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04310315102338791\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06165872886776924\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08650375157594681\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023915821686387062\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.0616615004837513\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.0883631631731987\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014421124942600727\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020166000351309776\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04767659306526184\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04486439377069473\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12626604735851288\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05319596081972122\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033401042222976685\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005802114028483629\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07289426773786545\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.043207816779613495\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06759621202945709\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.043073102831840515\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06159159541130066\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08656284958124161\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023920638486742973\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06168906390666962\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08836796879768372\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014390503987669945\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020169559866189957\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04772854968905449\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04486820101737976\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12616755068302155\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05330582335591316\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.033407218754291534\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.0057366215623915195\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07293244451284409\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04320243000984192\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06761255115270615\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.043040256947278976\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06153995916247368\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08660659193992615\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023918282240629196\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061721041798591614\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08836688846349716\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014351308345794678\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020173074677586555\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04778152331709862\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04486972838640213\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12607964873313904\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.053408458828926086\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03341561555862427\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005683992989361286\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07295633852481842\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04318336397409439\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06763128936290741\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04300863668322563\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.061500679701566696\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08663751184940338\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02391236647963524\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.061750758439302444\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.0883631706237793\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014310479164123535\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02017495408654213\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.047831952571868896\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04486963525414467\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12600001692771912\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05349893495440483\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03342486917972565\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005641569383442402\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07296891510486603\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.043161604553461075\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06765089929103851\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04297984391450882\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061470918357372284\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08665860444307327\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023904921486973763\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06177546828985214\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08835852146148682\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.0142715685069561\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020175207406282425\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04787757620215416\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.0448685921728611\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12592662870883942\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05357467383146286\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03343416377902031\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005607237573713064\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07297229766845703\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.043141476809978485\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06767034530639648\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04295426234602928\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06144825369119644\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08667226880788803\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023896971717476845\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.0617944709956646\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08835367858409882\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014236096292734146\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02017432078719139\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04791716858744621\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.0448671318590641\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12585791945457458\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.053635064512491226\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033443037420511246\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005579380784183741\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.0729682669043541\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04312405735254288\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06768901646137238\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04293184354901314\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.061430834233760834\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08668030053377151\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023888977244496346\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06180815398693085\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08834879845380783\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014204542152583599\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020172832533717155\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.047950126230716705\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.044865675270557404\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.1257929652929306\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05368053540587425\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03345121443271637\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005556728225201368\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07295846939086914\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.0431094728410244\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06770668923854828\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04291238635778427\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061417222023010254\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08668404072523117\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.02388113923370838\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.061817314475774765\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08834385126829147\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.01417689397931099\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020171165466308594\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.0479762889444828\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.044864472001791\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12573127448558807\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05371219664812088\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03345850482583046\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005538300611078739\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07294434309005737\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04309748485684395\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06772340089082718\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04289567098021507\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06140636280179024\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08668442815542221\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023873504251241684\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06182283163070679\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08833862841129303\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014152860268950462\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.02016960084438324\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04799570143222809\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04486368969082832\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.1256723701953888\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05373138189315796\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033464763313531876\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005523337982594967\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07292714715003967\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04308754578232765\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.0677393451333046\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04288148507475853\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061397552490234375\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08668217808008194\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02386605553328991\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06182555854320526\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.088332898914814\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014132099226117134\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020168283954262733\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04800857603549957\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.044863421469926834\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12561607360839844\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.053739409893751144\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033469900488853455\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005511217284947634\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07290785014629364\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.0430794395506382\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06775475293397903\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04286965727806091\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.0613902285695076\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08667788654565811\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023858748376369476\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.061826176941394806\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08832645416259766\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.01411421224474907\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.0201672725379467\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04801514372229576\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.044863734394311905\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12556208670139313\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.053737640380859375\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03347386419773102\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.0055014570243656635\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07288738340139389\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.043072547763586044\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06776994466781616\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.0428600013256073\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061384011059999466\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08667198568582535\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023851536214351654\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06182526424527168\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08831916749477386\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.01409884449094534\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020166553556919098\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04801569879055023\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04486466571688652\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12551027536392212\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05372714251279831\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03347664326429367\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.00549363112077117\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07286631315946579\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04306696355342865\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06778512895107269\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04285232722759247\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061378639191389084\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08666488528251648\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023844387382268906\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06182325258851051\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08831100910902023\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014085683971643448\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020166082307696342\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04801055043935776\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04486624523997307\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12546049058437347\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.053709082305431366\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.0334782749414444\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005487415008246899\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07284515351057053\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.043062105774879456\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06780048459768295\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04284641146659851\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.061373911798000336\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08665689080953598\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.0238372590392828\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06182049214839935\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08830192685127258\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014074415899813175\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020165806636214256\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04800001531839371\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044868502765893936\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.1254124641418457\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.053684335201978683\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03347881883382797\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005482515320181847\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07282406091690063\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04305790364742279\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06781622022390366\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04284211993217468\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061369702219963074\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08664824068546295\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023830141872167587\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.0618172287940979\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08829199522733688\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.01406479999423027\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020165670663118362\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04798443987965584\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04487144947052002\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12536609172821045\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05365379527211189\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03347837179899216\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005478698760271072\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07280322164297104\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.043054237961769104\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06783242523670197\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04283927008509636\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.061365894973278046\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.0866391658782959\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023823032155632973\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.061813659965991974\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08828128129243851\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014056602492928505\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020165618509054184\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.0479641817510128\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.044875141233205795\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12532129883766174\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05361824110150337\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.0334770567715168\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005475772079080343\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07278265058994293\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.0430508516728878\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06784915924072266\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04283767193555832\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061362408101558685\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08662986010313034\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023815931752324104\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06180992349982262\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08826988190412521\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01404962595552206\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020165616646409035\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04793962091207504\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.044879570603370667\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12527798116207123\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05357841029763222\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.033475011587142944\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.0054735648445785046\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07276233285665512\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04304755479097366\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.0678664892911911\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04283715784549713\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06135919690132141\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08662036806344986\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023808853700757027\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06180613115429878\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08825792372226715\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014043707400560379\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02016563154757023\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.047911137342453\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044884733855724335\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12523604929447174\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.053534992039203644\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03347237780690193\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005471951328217983\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07274224609136581\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04304433986544609\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06788439303636551\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04283759370446205\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.061356186866760254\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08661086112260818\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02380182221531868\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.061802323907613754\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08824552595615387\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014038702473044395\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020165646448731422\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.047879159450531006\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.0448906235396862\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1251954734325409\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05348862707614899\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033469267189502716\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005470814183354378\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07272236794233322\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.043041083961725235\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06790287047624588\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042838819324970245\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06135336309671402\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08660141378641129\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023794865235686302\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.0617985874414444\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08823281526565552\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014034492895007133\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02016564831137657\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04784400016069412\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04489721357822418\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.1251561939716339\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05343987047672272\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03346581757068634\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005470071919262409\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.0727025717496872\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04303743690252304\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06792191416025162\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04284073784947395\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061350710690021515\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08659207820892334\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02378799393773079\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.061794932931661606\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08821991086006165\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014030969701707363\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020165642723441124\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04780607670545578\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044904451817274094\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.125118225812912\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.053389232605695724\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03346214443445206\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005469644442200661\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.0726829320192337\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04303352162241936\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06794142723083496\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04284317046403885\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061348170042037964\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08658287674188614\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023781239986419678\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06179137900471687\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08820690959692001\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014028044417500496\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02016562782227993\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04776576906442642\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04491226002573967\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12508153915405273\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05333723500370979\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03345833346247673\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005469477269798517\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07266341149806976\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.043028902262449265\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06796145439147949\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042846065014600754\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06134577840566635\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08657388389110565\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023774627596139908\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06178794801235199\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08819394558668137\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014025640673935413\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020165614783763885\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.047723498195409775\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044920578598976135\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12504611909389496\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05328432470560074\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03345445543527603\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005469520576298237\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07264406979084015\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.043023306876420975\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06798183917999268\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04284924641251564\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0613434724509716\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08656516671180725\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.02376818098127842\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.061784643679857254\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08818107843399048\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014023695141077042\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020165618509054184\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04767965152859688\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.044929273426532745\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12501199543476105\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.053230926394462585\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033450573682785034\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.0054697273299098015\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07262495905160904\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04301668331027031\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06800253689289093\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.042852628976106644\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06134128198027611\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08655665814876556\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023761911317706108\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06178145855665207\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0881684347987175\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014022145420312881\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020165661349892616\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04763459414243698\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04493824392557144\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.124979168176651\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.053177472203969955\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03344673663377762\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005470062140375376\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07260619103908539\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.043008673936128616\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06802348047494888\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.0428561195731163\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.061339206993579865\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08654842525720596\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023755842819809914\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06177837774157524\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.0881560668349266\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014020946808159351\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020165758207440376\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04758872091770172\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04494735971093178\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12494763731956482\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.053124286234378815\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033442962914705276\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005470492877066135\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07258789986371994\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04299893230199814\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06804453581571579\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04285959526896477\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061337243765592575\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08654051274061203\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023749995976686478\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.061775390058755875\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08814405649900436\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014020050875842571\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02016594633460045\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04754246398806572\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04495646432042122\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12491736561059952\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05307169258594513\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033439263701438904\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005470988340675831\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07257016748189926\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.042987387627363205\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06806560605764389\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04286295548081398\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061335399746894836\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08653289824724197\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023744380101561546\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.061772480607032776\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08813246339559555\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014019422233104706\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020166246220469475\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047496192157268524\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04496542364358902\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12488845735788345\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.053020209074020386\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033435676246881485\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005471520125865936\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07255314290523529\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04297385737299919\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06808656454086304\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04286610707640648\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06133368983864784\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08652567118406296\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02373901940882206\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06176963821053505\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08812135457992554\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014019027352333069\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02016669511795044\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04745020717382431\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04497412219643593\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12486084550619125\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05296989157795906\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03343217447400093\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005472060292959213\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07253692299127579\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.042958155274391174\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06810729205608368\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042868971824645996\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06133212894201279\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08651883155107498\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023733919486403465\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.061766836792230606\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.0881107747554779\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014018833637237549\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02016732096672058\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.047404851764440536\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.044982392340898514\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1248345896601677\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05292117968201637\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.033428773283958435\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005472583696246147\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07252158969640732\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.042940426617860794\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06812770664691925\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042871471494436264\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06133074313402176\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08651240915060043\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023729095235466957\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06176402419805527\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08810078352689743\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014018816873431206\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020168157294392586\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.0473603680729866\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04499013349413872\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.1248096153140068\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.052874207496643066\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.0334254689514637\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005473067052662373\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07250716537237167\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.042920783162117004\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06814766675233841\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.042873531579971313\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06132955476641655\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08650647848844528\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023724565282464027\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06176121160387993\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08809138834476471\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014018951915204525\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020169230177998543\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04731696471571922\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04499725624918938\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12478596717119217\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05282917991280556\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03342225030064583\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005473488476127386\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07249367982149124\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04289928451180458\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06816709786653519\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04287513345479965\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06132860481739044\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08650103956460953\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023720331490039825\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06175834685564041\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08808263391256332\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014019220136106014\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02017056569457054\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.0472748726606369\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04500366374850273\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12476354837417603\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.052786264568567276\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033419132232666016\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005473824683576822\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07248110324144363\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04287639260292053\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.0681859627366066\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042876213788986206\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06132790073752403\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08649620413780212\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023716403171420097\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06175541505217552\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08807454258203506\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014019607566297054\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020172173157334328\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04723421856760979\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.045009300112724304\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12474242597818375\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05274553224444389\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03341609239578247\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0054740579798817635\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07246942818164825\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.042852338403463364\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06820423156023026\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04287678003311157\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061327479779720306\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08649194240570068\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023712774738669395\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06175239756703377\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08806712180376053\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014020096510648727\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020174061879515648\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04719512537121773\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04501410946249962\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12472248077392578\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.052707135677337646\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.033413149416446686\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005474173929542303\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07245847582817078\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04282767325639725\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06822193413972855\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042876843363046646\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06132737174630165\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08648831397294998\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023709455505013466\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06174929440021515\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08806036412715912\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014020677655935287\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020176220685243607\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04715767130255699\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.045018091797828674\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12470371276140213\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.052671078592538834\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03341028839349747\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005474153906106949\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07244821637868881\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04280276596546173\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06823907047510147\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04287639260292053\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061327602714300156\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08648532629013062\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023706432431936264\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061746105551719666\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08805426955223083\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.01402134820818901\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020178627222776413\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.047121915966272354\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04502120614051819\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12468600273132324\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.052637360990047455\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03340751677751541\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005473995581269264\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07243846356868744\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.042777929455041885\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06825575232505798\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.042875465005636215\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06132819876074791\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08648301661014557\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02370370179414749\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06174281984567642\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08804882317781448\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.01402209885418415\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020181259140372276\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04708791896700859\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.045023489743471146\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12466936558485031\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05260610952973366\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03340482711791992\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005473686847835779\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07242917269468307\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04275369271636009\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06827208399772644\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04287409037351608\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06132917106151581\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08648134768009186\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023701254278421402\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06173944100737572\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08804399520158768\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014022927731275558\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020184073597192764\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04705570265650749\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.045024942606687546\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12465371936559677\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05257720872759819\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.0334022156894207\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005473227705806494\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07242012023925781\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04273040220141411\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06828812509775162\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.042872294783592224\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061330556869506836\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08648031949996948\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023699071258306503\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06173600256443024\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08803977072238922\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014023830182850361\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020187025889754295\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04702529311180115\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04502559453248978\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12463902682065964\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.0525507926940918\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03339969366788864\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005472618155181408\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07241122424602509\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.042708318680524826\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06830406934022903\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04287012666463852\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.0613323412835598\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08647993206977844\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023697135969996452\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06173255667090416\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08803611248731613\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014024805277585983\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02019006572663784\n",
      "Search Iteration [7/20], Validation Loss: 0.05143632762642069\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.1043616533279419\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.12705416977405548\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12831012904644012\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.0649615228176117\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.033809226006269455\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.016934199258685112\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.09348125755786896\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.04205004498362541\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07274619489908218\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04305637627840042\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06394647061824799\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.1153390109539032\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.0244645643979311\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06888452172279358\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09345310926437378\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.027769457548856735\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.02565976046025753\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.048972245305776596\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.045197729021310806\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12435270845890045\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.053796760737895966\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03734414651989937\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005501650273799896\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.0718197152018547\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04519089683890343\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.0816132128238678\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.044831011444330215\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06450285017490387\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.08770453929901123\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02409522607922554\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06335236132144928\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08804097771644592\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.014239257201552391\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.023158490657806396\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04685859754681587\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04601722210645676\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.1247718557715416\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.0513874851167202\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03348321467638016\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005558912176638842\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07176349312067032\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04319177567958832\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06779444962739944\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04550516605377197\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06281249970197678\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08862826228141785\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024609144777059555\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.061661217361688614\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08805001527070999\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014677231200039387\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02120974287390709\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04695761948823929\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04596854746341705\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12482717633247375\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.051530852913856506\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.033685117959976196\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005692007951438427\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07197780162096024\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04211496189236641\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.0677928552031517\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04491805285215378\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.0621776357293129\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08849398791790009\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.0246299896389246\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06178414821624756\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.0880691260099411\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014824326150119305\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020840946584939957\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.046845681965351105\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04599405825138092\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12460283935070038\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05198189243674278\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03374265879392624\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005536967888474464\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07208960503339767\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04169434681534767\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06776050478219986\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.044640153646469116\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061741847544908524\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08854930847883224\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02466425485908985\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06203193962574005\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.088046595454216\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.015064017847180367\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020771069452166557\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04671792313456535\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.046564001590013504\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12463580816984177\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.052090901881456375\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03379343822598457\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0055598425678908825\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07228456437587738\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04144277051091194\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.0676092728972435\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04424184188246727\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06158450245857239\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.0879722535610199\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02444618195295334\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06209324300289154\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08802326023578644\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.01490273792296648\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020612210035324097\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04665275290608406\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04616878181695938\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12459085881710052\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05235439911484718\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.0336514487862587\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005445207469165325\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.0720798447728157\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04125550761818886\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06761357933282852\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04394206777215004\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.0614616833627224\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08761457353830338\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02428497187793255\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06220985949039459\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08800342679023743\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014796731062233448\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020578155294060707\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04661339521408081\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.046292975544929504\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.1246890053153038\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05223548784852028\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03362950310111046\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005442971829324961\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07219839841127396\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.041186340153217316\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06769208610057831\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.043749794363975525\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06143542379140854\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08728524297475815\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02414257451891899\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.062135037034749985\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08798530697822571\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014544224366545677\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02055542729794979\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04658878594636917\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04610028862953186\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12510403990745544\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05134175345301628\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033494263887405396\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005417739041149616\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07229804247617722\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.041084691882133484\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06888921558856964\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.043315257877111435\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06147387623786926\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08663780987262726\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023924289271235466\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06194385886192322\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08797968924045563\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014189478009939194\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02050800994038582\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.046630024909973145\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.045297686010599136\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12665577232837677\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.0517430417239666\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03356068581342697\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005701904185116291\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07258296757936478\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04148844629526138\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07176056504249573\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04270082712173462\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061633091419935226\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08646988868713379\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023831427097320557\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.061734654009342194\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08803807944059372\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01401881966739893\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02076263166964054\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04662242904305458\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04491810500621796\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12662091851234436\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.051447074860334396\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.0335499569773674\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005626065656542778\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07492984086275101\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04110594838857651\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06811647862195969\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04270442575216293\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061533715575933456\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.086372509598732\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023778695613145828\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061685241758823395\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08826372772455215\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014062811620533466\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.02053217589855194\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.046824466437101364\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.044837869703769684\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12493323534727097\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.0511629581451416\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03340182825922966\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005554579198360443\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07473837584257126\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04106326401233673\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06800620257854462\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.042738158255815506\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06149119511246681\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08647290617227554\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023763034492731094\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061832625418901443\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08833170682191849\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014104526489973068\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.02043909579515457\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04686885327100754\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04484410211443901\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12481281906366348\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.051139287650585175\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.0333453007042408\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005597691051661968\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.0739322379231453\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04113001748919487\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06838686019182205\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042708467692136765\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06147494912147522\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08643213659524918\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023752959445118904\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06197212263941765\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.0882781371474266\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01412030216306448\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020447799935936928\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04679566249251366\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04483850672841072\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12488773465156555\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051148876547813416\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03333418443799019\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005648164544254541\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07365823537111282\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04125642776489258\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06878457218408585\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04269605129957199\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06148281693458557\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.086377814412117\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023743687197566032\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.062035296112298965\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08822475373744965\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.01413370668888092\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02047230489552021\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04673722758889198\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.044840794056653976\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12495327740907669\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.051139529794454575\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03333112969994545\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005674871150404215\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07367711514234543\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.041410233825445175\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06898824125528336\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042714860290288925\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06150047853589058\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08635473996400833\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023738780990242958\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06206439062952995\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08820933103561401\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014148245565593243\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020484942942857742\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.046726565808057785\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04483781382441521\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12489490211009979\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05114344507455826\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.0333298034965992\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005698725581169128\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07388218492269516\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041569191962480545\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06908288598060608\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04276096075773239\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06150608882308006\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08634959161281586\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023734567686915398\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06207936257123947\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08822572231292725\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.01417131070047617\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020479002967476845\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.046760909259319305\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04484403505921364\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12475299835205078\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05118072032928467\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03332743048667908\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005720706190913916\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.0741078183054924\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04171396419405937\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06920388340950012\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042824093252420425\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06149482727050781\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08634919673204422\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023729387670755386\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06208553910255432\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08826000988483429\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014198968186974525\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020458398386836052\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04683062806725502\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04486559331417084\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12460538744926453\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05127350240945816\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03332382068037987\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005719746463000774\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07420344650745392\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.041812390089035034\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06931938976049423\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042891860008239746\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061471402645111084\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08635099977254868\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023725135251879692\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.062072768807411194\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08829838037490845\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014218048192560673\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020427344366908073\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04691913723945618\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.044898517429828644\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12449123710393906\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.051391031593084335\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03332136943936348\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005678117275238037\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07402274012565613\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04182159900665283\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06923308223485947\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04293878376483917\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061444226652383804\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08635599911212921\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023724272847175598\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.062032461166381836\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08832277357578278\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014214160852134228\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02039485052227974\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.046984631568193436\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.044929757714271545\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12442747503519058\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05146075412631035\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03332336246967316\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005618374329060316\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07358179241418839\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04179259389638901\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06894508004188538\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04296193644404411\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.0614231675863266\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08636078238487244\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023728005588054657\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06197594478726387\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08832236379384995\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014185694046318531\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02037142775952816\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04699009284377098\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04494600370526314\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12440397590398788\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.051453884690999985\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03332733362913132\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005575194023549557\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07311643660068512\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04188993200659752\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0688556432723999\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.043022725731134415\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06141383945941925\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08635522425174713\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.0237337127327919\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06193322688341141\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08830380439758301\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.01414764765650034\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020352061837911606\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04696037620306015\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04495210573077202\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12439265102148056\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051401834934949875\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03332960978150368\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005549485795199871\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.0727856308221817\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.0422329306602478\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06912072002887726\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04318341985344887\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061417967081069946\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08634743094444275\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023739343509078026\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06189911812543869\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08828332275152206\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014110389165580273\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.02032683603465557\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.0469474233686924\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04496331885457039\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12437417358160019\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.051359206438064575\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033330246806144714\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005531840957701206\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07260248064994812\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04292626678943634\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06955304741859436\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04349488392472267\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06142827495932579\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.0863482877612114\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023746658116579056\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06182778626680374\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.0882788598537445\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014080566354095936\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020290207117795944\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04698895663022995\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04498795047402382\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12435536086559296\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051379743963479996\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.033332858234643936\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005515249911695719\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07248636335134506\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04421896114945412\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06976550072431564\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.0439828485250473\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061394352465867996\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08634806424379349\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023762084543704987\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06171240285038948\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08830814808607101\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014070233330130577\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020242484286427498\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04707691818475723\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04503726214170456\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12435589730739594\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05150618031620979\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03334570676088333\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005489950533956289\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.0723208636045456\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.046592827886343\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06991001218557358\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.044577501714229584\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06127677857875824\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.0865916758775711\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023857761174440384\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.061671558767557144\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08854144811630249\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014145229011774063\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020181549713015556\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.047388285398483276\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.045321494340896606\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12459032237529755\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05181025341153145\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.0334269143640995\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005416025407612324\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07185029238462448\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04323220252990723\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06803083419799805\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.043610744178295135\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06127891317009926\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08669054508209229\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02394290640950203\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06166048347949982\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08847010880708694\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01403990387916565\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02020278573036194\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04714076593518257\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.045168276876211166\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12438545376062393\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.0519799068570137\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03351224958896637\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005412609316408634\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07175776362419128\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.042271241545677185\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06796681135892868\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04331859201192856\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06129610911011696\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08639722317457199\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023836283013224602\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06169689819216728\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08827641606330872\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014024673029780388\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020205829292535782\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.0468309260904789\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044999755918979645\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12438405305147171\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05137242004275322\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03341177850961685\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.0054299188777804375\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07176322489976883\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04650668799877167\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.0711076483130455\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.044581927359104156\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06129113957285881\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08635861426591873\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02387048862874508\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06168723851442337\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08822844922542572\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014018808491528034\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020185651257634163\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.046845220029354095\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.0449761264026165\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12437647581100464\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05135593190789223\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033387091010808945\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0054617091082036495\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07178696990013123\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.05215706303715706\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07165093719959259\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.045442044734954834\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06146430969238281\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08738052099943161\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.024069247767329216\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.0618370845913887\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08871618658304214\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014107141643762589\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020168770104646683\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04783385246992111\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04521504044532776\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12480053305625916\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05167226120829582\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03355233371257782\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005411838181316853\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.0718257799744606\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04203474521636963\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.067613385617733\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04336003586649895\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061281051486730576\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08652054518461227\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023945331573486328\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.061657313257455826\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08818965405225754\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014067701064050198\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020191235467791557\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04686657711863518\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044938504695892334\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.1244075745344162\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.0516466461122036\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.033588018268346786\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005412610247731209\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07213450223207474\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04377695545554161\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06872206926345825\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04421033337712288\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06129984185099602\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08634944260120392\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.02381599321961403\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.061693351715803146\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08824014663696289\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014018912799656391\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.0201673936098814\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04705565795302391\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04500249773263931\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12435957789421082\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05174877494573593\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03362690284848213\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005411320831626654\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07210497558116913\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.0471317283809185\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06945900619029999\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04486117139458656\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06131346896290779\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.0865553766489029\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02392798848450184\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.061685554683208466\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08835094422101974\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014019434340298176\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020166294649243355\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04708148539066315\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04508106783032417\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1243908703327179\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05185004696249962\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03366181254386902\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005413970444351435\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.0721907764673233\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04535853490233421\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06844238191843033\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.0444856658577919\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061284735798835754\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08648017048835754\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.0239022895693779\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06166457384824753\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08825597912073135\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014036926440894604\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02016643062233925\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04692886397242546\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.045011576265096664\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1243528500199318\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05175960808992386\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033624228090047836\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005411090794950724\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07222379744052887\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.0453626774251461\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06848900765180588\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04437796771526337\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06127726659178734\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08645323663949966\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023875195533037186\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06165867671370506\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0881810337305069\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014052745886147022\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020168744027614594\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04686443507671356\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04497883841395378\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12435637414455414\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05160912498831749\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03354905918240547\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005415650550276041\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07213633507490158\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04655815288424492\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06853371858596802\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.044728752225637436\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.061277564615011215\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08654312789440155\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023917444050312042\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.0616537481546402\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08821181207895279\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014051835983991623\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02017221227288246\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.046904731541872025\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04499116167426109\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12435387820005417\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05161586403846741\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033505797386169434\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005422738380730152\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07208388298749924\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04574252665042877\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.0681794062256813\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04436291754245758\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.0612783245742321\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08652203530073166\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023842204362154007\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06166146323084831\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08822550624608994\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014028530567884445\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020174292847514153\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04697257652878761\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04503684863448143\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12437176704406738\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05175250396132469\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03353997319936752\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005413360893726349\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0722263902425766\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.0455663725733757\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06811921298503876\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04410502314567566\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061294686049222946\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08650871366262436\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023833464831113815\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.061664681881666183\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08822506666183472\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.01403952669352293\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020166244357824326\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04687897861003876\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04498884454369545\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12435300648212433\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05175262689590454\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033588770776987076\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005412625148892403\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07239192724227905\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.044179920107126236\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06774867326021194\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.043898917734622955\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06127777323126793\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08647007495164871\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023814167827367783\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.0616534985601902\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08809015154838562\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.01411212794482708\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020209703594446182\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.046771857887506485\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04490995407104492\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12443897873163223\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05155428126454353\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03351400047540665\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.0054238224402070045\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07231371849775314\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04530799761414528\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06790990382432938\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04437178373336792\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.061292603611946106\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08649291843175888\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023855851963162422\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06166480481624603\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08808457106351852\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014153601601719856\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020216045901179314\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04672978073358536\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04485904797911644\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12459742277860641\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05145628750324249\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03345506265759468\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005453748628497124\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07214632630348206\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04638839513063431\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.0679972693324089\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04438185319304466\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.0612766370177269\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08652201294898987\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023808369413018227\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06165604665875435\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08814683556556702\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014044612646102905\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020203858613967896\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.046875983476638794\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04497914761304855\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12437553703784943\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05127577483654022\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033324871212244034\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005532663781195879\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07181556522846222\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.043391574174165726\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06947806477546692\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04356011375784874\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06127673014998436\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.0863567516207695\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.02369096502661705\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06183396652340889\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08815839141607285\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014023706316947937\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020244700834155083\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.0468885563313961\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04483779892325401\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12436879426240921\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05168166756629944\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03351644054055214\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005411738995462656\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07232636958360672\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04693193361163139\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.0684865415096283\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.044293902814388275\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06132936477661133\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08657260984182358\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023841118440032005\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.0617230050265789\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08831106126308441\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014020070433616638\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020203251391649246\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.046812329441308975\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04488588124513626\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.124483622610569\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.0517103336751461\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033512525260448456\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005413509905338287\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07217942923307419\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04238533228635788\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06758773326873779\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04304930567741394\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06129319220781326\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08643314242362976\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023737572133541107\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06165510416030884\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08803931623697281\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014124264940619469\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02022969350218773\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04687352851033211\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.044838838279247284\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12436062842607498\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05165310949087143\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033525168895721436\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0054120891727507114\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07245767116546631\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04392107576131821\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06766427308320999\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04378163814544678\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061302799731492996\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08639797568321228\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023752380162477493\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06165793910622597\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.0880429595708847\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014103017747402191\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.0202834140509367\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.046883877366781235\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04485836252570152\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1243537962436676\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.051739130169153214\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03354323282837868\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.00541701540350914\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07255171239376068\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.045002955943346024\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06782041490077972\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04398918151855469\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061276692897081375\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08642307668924332\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023760424926877022\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06165435537695885\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08804719895124435\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014118802733719349\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02037031389772892\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.046896979212760925\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044873934239149094\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12435300648212433\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05177682638168335\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033576708287000656\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005432446487247944\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07269560545682907\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04537804052233696\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.0678558200597763\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04400090500712395\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06128372624516487\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08666108548641205\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023790575563907623\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06165431812405586\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08807430416345596\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014091559685766697\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020231181755661964\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04712264612317085\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044855017215013504\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12441419064998627\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05187326297163963\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03364308923482895\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005461002700030804\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07305288314819336\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04521786421537399\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06779932230710983\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04429931193590164\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06130236014723778\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08635590225458145\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023789163678884506\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061687782406806946\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.0879950150847435\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014429931528866291\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020223546773195267\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.046596184372901917\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.044895388185977936\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1252916306257248\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.051337990909814835\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03349991887807846\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005411644000560045\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07260596752166748\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04655102640390396\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06791388988494873\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.043635495007038116\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06127697601914406\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08635609596967697\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02372635342180729\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.061673253774642944\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08804111927747726\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.01424538716673851\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02026027999818325\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04675408452749252\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04486504942178726\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12449837476015091\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05129678174853325\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033405352383852005\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005412313621491194\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07193639129400253\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04879404231905937\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06762797385454178\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04380318894982338\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061278920620679855\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08661997318267822\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023758485913276672\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06165918707847595\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08813395351171494\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014147144742310047\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020254140719771385\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04728144779801369\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044852592051029205\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12498895078897476\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05167928338050842\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.0334656685590744\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.0054396167397499084\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07209782302379608\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04975345730781555\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06759965419769287\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.0430939756333828\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06128280609846115\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08644772320985794\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023776745423674583\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06168127432465553\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08807314187288284\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014378468506038189\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020220952108502388\n",
      "Search Iteration [8/20], Validation Loss: 0.057851709603247314\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.09052196145057678\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.12171433866024017\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.13248310983181\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06684940308332443\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.033845819532871246\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.019386349245905876\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.11110728234052658\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.044754523783922195\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.06824204325675964\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04276621714234352\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06176190823316574\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.13163509964942932\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.024478670209646225\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06421700119972229\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09395908564329147\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.03166772797703743\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.022520463913679123\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.04847750812768936\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.045189108699560165\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12456241250038147\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.055203404277563095\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.036919016391038895\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005924960598349571\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07256405800580978\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04130612313747406\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.0730128362774849\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.0458831824362278\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06227560713887215\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.09010040014982224\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.025109997019171715\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06182759255170822\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08802835643291473\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.014604046009480953\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.022551720961928368\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.05144991725683212\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04486418142914772\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12471694499254227\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05114055797457695\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03348264843225479\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005415752995759249\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.0717635378241539\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04105731472373009\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06781040132045746\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.0446273609995842\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06190060079097748\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08786088973283768\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024084029719233513\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.061703331768512726\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.0879809707403183\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014022601768374443\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.021256664767861366\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04667641595005989\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04688192903995514\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.1268014907836914\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05113518610596657\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.0333714485168457\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005478456150740385\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07278458774089813\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.041461363434791565\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07062192261219025\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.042696986347436905\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06141812726855278\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08634836226701736\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023859737440943718\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06174216791987419\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08797988295555115\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014026566408574581\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02144797518849373\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04665184020996094\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04497862979769707\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1279037743806839\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05140213295817375\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03409731760621071\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005432887468487024\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07342784106731415\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04183207452297211\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07135244458913803\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04272190481424332\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061445534229278564\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08646218478679657\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023886924609541893\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06177244335412979\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08813365548849106\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01416046917438507\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02099199965596199\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04751167073845863\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04542005807161331\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.1252240389585495\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.051951128989458084\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03332405909895897\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005419716238975525\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07183211296796799\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.041222892701625824\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06856751441955566\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04292307049036026\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06140298396348953\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08677087724208832\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02390267513692379\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.061924051493406296\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08809453248977661\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014089777134358883\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020834198221564293\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04699309170246124\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04613747447729111\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12561747431755066\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.0521388053894043\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.033321429044008255\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005411072634160519\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07188601791858673\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.041558701545000076\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06919971853494644\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04279370233416557\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061316147446632385\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.0867067277431488\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023877901956439018\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06198634207248688\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08806270360946655\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.01410623174160719\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020763900130987167\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.0468066968023777\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04627883434295654\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12602762877941132\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05163766071200371\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03332790359854698\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.00541300093755126\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.0718076080083847\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04171186313033104\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06906141340732574\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04274966940283775\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06130877882242203\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08666051924228668\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02389119751751423\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06195971369743347\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.0880422294139862\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014077911153435707\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02079320326447487\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.046731725335121155\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04613122716546059\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12644045054912567\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05123557150363922\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03336813673377037\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005421766079962254\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07185055315494537\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04197718948125839\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06913289427757263\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.042705029249191284\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06131283938884735\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08655969053506851\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023925432935357094\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.0619034506380558\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08802878111600876\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014063147827982903\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020856456831097603\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.046712640672922134\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.045844051986932755\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12670515477657318\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05113520845770836\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03346645087003708\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005438006948679686\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07216180860996246\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04235580936074257\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06919749081134796\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042698074132204056\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061323381960392\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08650325238704681\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023974403738975525\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06186261028051376\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08805128931999207\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01407752837985754\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.0208558589220047\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04681522771716118\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04560980200767517\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.126128152012825\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05118539184331894\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033464107662439346\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.00548344012349844\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.0730811133980751\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04256274923682213\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06919503957033157\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04270338639616966\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06130306422710419\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08657857030630112\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.02395574375987053\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06188768148422241\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08812941610813141\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014177313074469566\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020706571638584137\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04703288525342941\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.045486629009246826\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12544018030166626\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05165942385792732\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03345481678843498\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005576555151492357\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07632890343666077\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04251250997185707\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.0693695992231369\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04269753023982048\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.061278585344552994\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.0869433581829071\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02390330471098423\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06197398528456688\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08838620036840439\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014498422853648663\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020513176918029785\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.047742266207933426\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045093048363924026\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1251053810119629\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.051444653421640396\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033408619463443756\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005461701191961765\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07443398237228394\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04192756488919258\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06857139617204666\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042697157710790634\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06127849221229553\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08691224455833435\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023915214464068413\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06201133504509926\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.088349349796772\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01428645197302103\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.0205769632011652\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04764221981167793\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04513842612504959\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12506592273712158\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05166945233941078\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03336575627326965\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005458338651806116\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07415338605642319\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04190399870276451\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.0686044916510582\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042704496532678604\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061276715248823166\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.0869913324713707\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023919114843010902\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06205592676997185\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08838040381669998\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014254900626838207\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020564688369631767\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.047621436417102814\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.0451308898627758\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.1250685304403305\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05165407434105873\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03335168585181236\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005448716692626476\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07348421961069107\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04178278148174286\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06838830560445786\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04272180795669556\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06127668544650078\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08704804629087448\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023941373452544212\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.0620875209569931\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08836996555328369\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014179560355842113\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02057909592986107\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04756663367152214\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.045161087065935135\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.1250641644001007\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05174926295876503\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033336807042360306\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.00544352363795042\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07303746044635773\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04172072932124138\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06829552352428436\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04273739457130432\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08706623315811157\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02395150437951088\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.062108080834150314\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.0883619412779808\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.01413409411907196\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020582500845193863\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.047521524131298065\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.045173365622758865\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.1250854879617691\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.051743946969509125\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03332967683672905\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.00543947471305728\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07257843017578125\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04165779799222946\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06817574799060822\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04275697469711304\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08706814795732498\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023968879133462906\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.062116317451000214\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08833467960357666\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014086625538766384\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02059394121170044\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04743589460849762\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04520757868885994\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12513312697410583\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.051756780594587326\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033324483782052994\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005438576452434063\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.072240449488163\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04163464158773422\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06811254471540451\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04276765137910843\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06127673014998436\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08702829480171204\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023977061733603477\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.062111321836709976\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08830059319734573\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014054459519684315\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020603682845830917\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.0473213866353035\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04523743316531181\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12524008750915527\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.0516684427857399\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03332260623574257\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005440045613795519\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07197786867618561\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.041644688695669174\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06805501878261566\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04277224466204643\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061277199536561966\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08697310835123062\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023990413174033165\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.062095556408166885\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08825480192899704\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.01403066050261259\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.0206207986921072\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04716089740395546\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04527607187628746\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12543414533138275\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05149920657277107\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03332255035638809\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.0054466212168335915\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07183019816875458\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.0417402982711792\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06805558502674103\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.042752739042043686\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061278149485588074\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08686672896146774\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023998098447918892\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06206396594643593\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08819947391748428\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014020301401615143\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02064426988363266\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04695915803313255\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04528006538748741\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12579569220542908\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05122610554099083\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03333196043968201\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005467870272696018\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07178143411874771\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.042016662657260895\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0681496113538742\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.042707446962594986\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06127997115254402\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08667634427547455\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023997686803340912\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.062005966901779175\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08813763409852982\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014018833637237549\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020681845024228096\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.0467558316886425\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04517623409628868\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12637582421302795\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05117208510637283\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03340258449316025\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.0055049811489880085\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07180910557508469\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.042444806545972824\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06816456466913223\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04270218312740326\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06128256767988205\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08648011833429337\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023993825539946556\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06191007047891617\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08812393248081207\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014019089750945568\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020739935338497162\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04669718071818352\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.044948432594537735\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12676119804382324\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.051432590931653976\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033545512706041336\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005498047452419996\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07224755734205246\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04285874217748642\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06816931068897247\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04272276908159256\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.0612788051366806\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08651665598154068\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.024012254551053047\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06182820722460747\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08826816082000732\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014021222479641438\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.02067745290696621\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04713955521583557\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044839803129434586\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.1255536675453186\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05114344134926796\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03340885415673256\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.0055127572268247604\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07247506082057953\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.042260922491550446\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.0678398385643959\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04272836446762085\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08653877675533295\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023886900395154953\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.061846788972616196\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.0883946567773819\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014061602763831615\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02047920599579811\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04767338186502457\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.044844772666692734\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.124991774559021\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05129328742623329\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03335496783256531\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005459375213831663\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07253168523311615\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04212457686662674\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06786788254976273\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.042749252170324326\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06128131225705147\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08655261993408203\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.0238468237221241\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.061925459653139114\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08843076229095459\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014064738526940346\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.02042064070701599\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04767603054642677\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04485369846224785\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12497621029615402\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.051276255398988724\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03333209082484245\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005440077278763056\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.072086401283741\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.042099643498659134\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06800687313079834\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04271962121129036\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06127713620662689\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08649756759405136\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02386455610394478\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06198392063379288\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08830952644348145\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01402406208217144\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020473070442676544\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04709137603640556\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04483949765563011\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12562869489192963\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05113700032234192\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.033350247889757156\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.00550385657697916\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07183205336332321\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04293890669941902\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06838703900575638\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.042787183076143265\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061276648193597794\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08639268577098846\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02385139651596546\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06204455718398094\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08821560442447662\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014018828980624676\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.0204577948898077\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04675763472914696\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.044838402420282364\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12637372314929962\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05122067779302597\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03339005634188652\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005509273149073124\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07181871682405472\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.043923236429691315\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06822469830513\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04289233312010765\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.061276890337467194\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.0863700583577156\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02383933588862419\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06188194081187248\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08829350024461746\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014019486494362354\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020378418266773224\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04688354581594467\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.044895272701978683\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12571017444133759\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05113530531525612\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03334550932049751\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005461280234158039\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07198521494865417\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04413312301039696\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06817561388015747\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04288274422287941\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06130009517073631\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.0865071639418602\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023820122703909874\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.061895981431007385\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08867108076810837\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014057627879083157\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020288927480578423\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04929238185286522\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04492338374257088\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12435302138328552\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05224546417593956\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03333418443799019\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005421795416623354\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07205578684806824\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.0414428785443306\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06766021251678467\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04274113103747368\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061297833919525146\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08657883107662201\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.024130532518029213\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06180781498551369\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08809342980384827\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.01419787760823965\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020464392378926277\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.046779707074165344\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044851161539554596\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.1257721483707428\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05116923153400421\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.0333237387239933\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005418932531028986\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.0717853531241417\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.043344710022211075\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06885458528995514\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.043163448572158813\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06129539757966995\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08636951446533203\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023777786642313004\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06221410632133484\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08862751722335815\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014024319127202034\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02023998461663723\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.048408184200525284\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04494646564126015\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.124417744576931\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05244606360793114\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03345528617501259\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005423597525805235\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07195296883583069\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.0418180450797081\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.0678693950176239\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04288284480571747\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06128929182887077\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.0863630622625351\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023903850466012955\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06192522123456001\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08820759505033493\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.01406167820096016\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020309224724769592\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.047095268964767456\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04484894499182701\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12502028048038483\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05145318806171417\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03339871019124985\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005411818623542786\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07244447618722916\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.044312261044979095\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.0695498064160347\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04355926066637039\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06127847731113434\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08635806292295456\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023756125941872597\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.062271714210510254\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08853784948587418\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014028376899659634\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02021878771483898\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04793614521622658\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04495325684547424\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12450794875621796\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05222873389720917\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03351415693759918\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.0054139685817062855\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.0728735402226448\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04561808705329895\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06966614723205566\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04395342618227005\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06128040701150894\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08634738624095917\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023752523586153984\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.062147073447704315\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08855342864990234\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014018967747688293\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02016671746969223\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04851345345377922\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04501989856362343\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.1243598535656929\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05240499973297119\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033652372658252716\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005471651442348957\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07321561872959137\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04514605551958084\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06905671954154968\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04397007077932358\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.061281394213438034\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08635054528713226\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.0238039530813694\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06215161457657814\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.088421531021595\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014044051058590412\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02017303556203842\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04786236584186554\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04496264085173607\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12442992627620697\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05224322900176048\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033764999359846115\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.0054754046723246574\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07419988512992859\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.0499308779835701\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06992654502391815\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04479774832725525\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06127925217151642\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08634892851114273\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.0237878505140543\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06235416978597641\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08846327662467957\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014019793830811977\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020171931013464928\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.048476092517375946\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044914159923791885\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12438603490591049\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05245887488126755\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033907681703567505\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005503145046532154\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07442481070756912\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.05733456462621689\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06792270392179489\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.0430620051920414\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06142677366733551\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.086722731590271\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023888301104307175\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06285396218299866\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08833540976047516\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014455065131187439\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02019103802740574\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04764322191476822\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.0449402891099453\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12478654831647873\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.052137769758701324\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03387009724974632\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005486332345753908\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07515808194875717\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.05168803408741951\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06778128445148468\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.043373603373765945\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06128060072660446\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08674365282058716\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02381693571805954\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06257249414920807\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08820516616106033\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014478297904133797\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02019164338707924\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04772502928972244\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.045057933777570724\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12488768994808197\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05258653312921524\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03396763652563095\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005514767486602068\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.0756581574678421\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.05264856666326523\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.0703265517950058\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04315625876188278\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06154141575098038\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08694447576999664\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.024230120703577995\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06341379135847092\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08832277357578278\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.01452285423874855\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020190756767988205\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.049162525683641434\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04485659673810005\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1251607984304428\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.053574077785015106\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03397943452000618\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005605286918580532\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07359810173511505\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.05335981026291847\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.0714179053902626\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04383358359336853\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06151825934648514\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08844354748725891\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.02423853985965252\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06329283118247986\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08864694833755493\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014559915289282799\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020212901756167412\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04827544838190079\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044867951422929764\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.125692218542099\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05473462864756584\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03414564207196236\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005720523651689291\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07226859778165817\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.050478093326091766\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.07081908732652664\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04335634410381317\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06143295764923096\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08916928619146347\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.024054143577814102\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06327556818723679\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08842089772224426\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014468620531260967\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020363420248031616\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.048432208597660065\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044926565140485764\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12524570524692535\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.0549449548125267\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03402421250939369\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.0055287498980760574\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07191799581050873\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04569251090288162\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.0689401775598526\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04309925436973572\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08723467588424683\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02381289191544056\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06236699968576431\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.0879908874630928\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014189690351486206\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02066740393638611\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.0479724146425724\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.0448778010904789\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.1255343109369278\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.055171605199575424\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033957548439502716\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.00542979221791029\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07210648059844971\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.043853554874658585\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06859010457992554\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04274015873670578\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06135956570506096\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.0865580216050148\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023799516260623932\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.062415190041065216\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08797972649335861\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014067837037146091\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02100265398621559\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.049139197915792465\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.045072976499795914\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12542353570461273\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.055336013436317444\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03363043814897537\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005412955302745104\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07279001176357269\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04229793697595596\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.0680932104587555\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042813535779714584\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06145411357283592\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08634769171476364\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023849930614233017\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06203129142522812\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08798649907112122\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014112013392150402\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02071661874651909\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.048006098717451096\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04496683180332184\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1254604607820511\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.054912909865379333\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03358136862516403\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005413695704191923\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07287445664405823\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04202652722597122\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06815018504858017\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04280318319797516\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06139669567346573\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.0863930732011795\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023891255259513855\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.062213752418756485\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.0879911258816719\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014081358909606934\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020796190947294235\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04844408482313156\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.045004554092884064\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12552396953105927\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05494271218776703\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03345703333616257\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005411311984062195\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07313820719718933\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04155087471008301\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06825826317071915\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04278428852558136\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061434973031282425\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08654569834470749\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023926544934511185\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06216075271368027\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08804438263177872\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014182673767209053\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020847899839282036\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04855702817440033\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04491695016622543\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.1253610998392105\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05463838577270508\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03338148817420006\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.00541146332398057\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07294163852930069\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.042102813720703125\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06874518096446991\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04270515590906143\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06129908189177513\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08647991716861725\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.024055059999227524\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06241511180996895\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08821377903223038\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014264528639614582\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.021392280235886574\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.049667682498693466\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04500712454319\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12504497170448303\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05485612899065018\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03333252668380737\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005411437246948481\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.0738278478384018\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04125846177339554\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06763603538274765\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042935241013765335\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06135513260960579\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.086499884724617\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023881027474999428\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06178781017661095\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08800695836544037\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014067091979086399\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02084875851869583\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04777920991182327\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04498739168047905\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12551575899124146\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05462716147303581\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03343041241168976\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005411417223513126\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07305871695280075\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.041444629430770874\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06781181693077087\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04275338724255562\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06127675995230675\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08676814287900925\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02389054372906685\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06188123673200607\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08804366737604141\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014044429175555706\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02066185139119625\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.048286426812410355\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04499959200620651\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12525992095470428\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05445599928498268\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03339207544922829\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005415209569036961\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07299075275659561\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04152252525091171\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06803188472986221\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.0427120178937912\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06127670034766197\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08679960668087006\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02387203648686409\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06184859201312065\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08807586878538132\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.01405149046331644\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020678121596574783\n",
      "Search Iteration [9/20], Validation Loss: 0.05928487858142365\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.07688295841217041\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.046656638383865356\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12486017495393753\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06920862942934036\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.06395186483860016\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.04615260288119316\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.1686595231294632\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.2529206871986389\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08181489259004593\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.09820415824651718\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.08334063738584518\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.17915377020835876\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02816484495997429\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06198398768901825\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09956682473421097\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.03751862421631813\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.036084648221731186\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.06019574776291847\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.0655466765165329\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12472705543041229\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.0691707581281662\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.04824129864573479\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.017768066376447678\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.11756731569766998\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.09893405437469482\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.11462898552417755\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.05462407320737839\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06196370720863342\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.15661685168743134\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02610703557729721\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06710971891880035\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08914054930210114\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.026873718947172165\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02072746865451336\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04791747406125069\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05166969075798988\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12912042438983917\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.0533934161067009\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03361181914806366\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.00648576021194458\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.0719788447022438\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.046457137912511826\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.07525160163640976\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.0426974892616272\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06616853177547455\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.087561696767807\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.023759054020047188\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.07524900883436203\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.0881262719631195\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014547315426170826\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.0254990141838789\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04676329717040062\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04549924284219742\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.1279177963733673\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05114579573273659\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03342483192682266\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005434817634522915\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07309474796056747\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.041431084275245667\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07020507752895355\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04271727055311203\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06357797235250473\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08749105036258698\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023693550378084183\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06714589148759842\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.0879821628332138\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01417827233672142\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.023296449333429337\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.047087956219911575\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.044917043298482895\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12651775777339935\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05117517709732056\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03355540335178375\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.00604851171374321\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07386567443609238\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04263192042708397\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07063134014606476\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04272736236453056\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06306173652410507\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08717700839042664\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02371114119887352\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.0645417869091034\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08798554539680481\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014147702604532242\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.021859195083379745\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.047073353081941605\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044843826442956924\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12584209442138672\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.0512504056096077\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03358244150876999\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0063720825128257275\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07427811622619629\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04298651963472366\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07032540440559387\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04273667559027672\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06266733258962631\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08679812401533127\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023694032803177834\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06329591572284698\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08799933642148972\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014137206599116325\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.021023500710725784\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04700503870844841\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.044838644564151764\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12548719346523285\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.051282405853271484\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03361549973487854\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.006372604053467512\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07454682886600494\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04272704944014549\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06979005038738251\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04274329915642738\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06234010308980942\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08657103031873703\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02368561550974846\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06255806982517242\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08801253885030746\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014146503992378712\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020542269572615623\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04691656306385994\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04484573006629944\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12526053190231323\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05130444094538689\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03363804519176483\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.006299345288425684\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07479797303676605\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04244640842080116\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06932985037565231\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.042745739221572876\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06208813562989235\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08644042909145355\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023686600849032402\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.062104158103466034\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08802611380815506\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014169950969517231\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02029554359614849\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04682513326406479\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.044852279126644135\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.1251065582036972\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05133692920207977\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.0336461067199707\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.006228843238204718\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07502741366624832\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.0422302782535553\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.068960040807724\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04274628683924675\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061896566301584244\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0863756388425827\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.02369159832596779\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.061844147741794586\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.088040292263031\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014201966114342213\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02019314467906952\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04674414545297623\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04485560208559036\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1250017136335373\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.0513833649456501\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03364194929599762\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.00617431104183197\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.0752086341381073\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04206004738807678\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06866686791181564\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042746517807245255\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06175239011645317\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.0863514393568039\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023696303367614746\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06171518936753273\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08805332332849503\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014233767054975033\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020166274160146713\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04668252915143967\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04485638439655304\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12492763996124268\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05143940448760986\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03362889215350151\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.006131201982498169\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07531893998384476\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04191165789961815\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06843787431716919\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04274717718362808\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06164458766579628\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.0863470807671547\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023699047043919563\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061663854867219925\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08806347101926804\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014257858507335186\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020170414820313454\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04664136841893196\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04485589638352394\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12487044185400009\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.051498573273420334\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03360993042588234\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.006093669217079878\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07535038143396378\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04177318140864372\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06826061755418777\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04274853691458702\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06156357750296593\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08634922653436661\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023699920624494553\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06165149062871933\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08807019144296646\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014271480962634087\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.02018248662352562\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04661628231406212\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04485499858856201\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12482248246669769\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05155627429485321\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033587489277124405\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.006058431696146727\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07531044632196426\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04164254292845726\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06812278181314468\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042750634253025055\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06150173768401146\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08635171502828598\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023699557408690453\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06165551766753197\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08807405084371567\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01427557971328497\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020193176344037056\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04660189896821976\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04485410824418068\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12478044629096985\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051610469818115234\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03356334939599037\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.006024169735610485\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07521528750658035\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04152187705039978\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.0680137425661087\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04275335744023323\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06145353987812996\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08635274320840836\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02369854226708412\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06166491657495499\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08807598054409027\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014272547326982021\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020200012251734734\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04659402370452881\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04485341161489487\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12474318593740463\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05166082829236984\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033538784831762314\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005990589968860149\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07508282363414764\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04141383245587349\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06792566925287247\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042756617069244385\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06141532212495804\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08635243028402328\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023697271943092346\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.061675138771533966\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08807673305273056\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014264904893934727\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020203154534101486\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04658989980816841\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04485296085476875\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12471018731594086\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05170759931206703\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033514656126499176\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005957805551588535\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07492811977863312\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041320040822029114\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06785327196121216\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04276030883193016\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06138472259044647\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08635140210390091\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02369597554206848\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06168462708592415\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.0880768746137619\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014254685491323471\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020203491672873497\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.046587858349084854\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.044852763414382935\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12468115985393524\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05175111070275307\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03349154442548752\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005926087964326143\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07476256787776947\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04124099761247635\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06779330223798752\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042764339596033096\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061360202729701996\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08635016530752182\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023694781586527824\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.061692994087934494\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08807674795389175\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014243371784687042\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020201899111270905\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04658692330121994\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.0448528416454792\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.1246558353304863\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05179142206907272\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03346984088420868\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.00589568680152297\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07459428906440735\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04117623716592789\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06774362921714783\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04276859387755394\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06134061515331268\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08634907752275467\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023693755269050598\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.061700329184532166\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08807653933763504\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.01423198264092207\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020199090242385864\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.0465865395963192\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.044853173196315765\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12463387846946716\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.051828429102897644\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033449817448854446\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.0058668009005486965\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07442846149206161\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04112479090690613\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06770281493663788\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04277292266488075\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.0613250732421875\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08634822815656662\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023692913353443146\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06170681118965149\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08807635307312012\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014221145771443844\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02019561268389225\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.046586401760578156\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04485377296805382\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12461494654417038\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05186176300048828\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03343166038393974\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005839535500854254\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07426837086677551\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04108520597219467\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06766971200704575\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04277718439698219\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061312854290008545\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08634764701128006\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.02369225025177002\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06171262636780739\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08807618916034698\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.01421124953776598\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020191840827465057\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.046586375683546066\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04485466703772545\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12459870427846909\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05189112573862076\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03341543301939964\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.0058139655739068985\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07411624491214752\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04105602204799652\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0676434263586998\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04278119280934334\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061303310096263885\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.086347296833992\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023691756650805473\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.0617179200053215\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08807607740163803\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014202475547790527\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02018805593252182\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.046586401760578156\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04485587775707245\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12458482384681702\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05191611871123314\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.033401135355234146\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.0057900892570614815\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07397329807281494\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04103558510541916\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06762305647134781\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042784739285707474\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061295926570892334\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08634711802005768\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023691410198807716\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.061722803860902786\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08807592839002609\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014194877818226814\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020184434950351715\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04658650606870651\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04485743120312691\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.1245729848742485\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05193650722503662\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033388685435056686\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005767898168414831\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07384032011032104\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.041022296994924545\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06760779023170471\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.042787663638591766\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06129024922847748\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.0863470509648323\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02369118481874466\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06172732636332512\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08807569742202759\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014188417233526707\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020181097090244293\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.046586714684963226\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04485934227705002\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12456287443637848\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051952119916677475\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03337796404957771\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005747359246015549\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07371755689382553\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04101461172103882\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06759677827358246\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042789820581674576\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061285946518182755\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.0863470658659935\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023691050708293915\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06173150613903999\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08807530254125595\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014183021150529385\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02017812244594097\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04658709093928337\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04486164078116417\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12455424666404724\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.051962871104478836\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.033368807286024094\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005728418007493019\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07360514998435974\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.041011083871126175\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06758921593427658\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04279109835624695\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06128271296620369\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08634711802005768\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02369098737835884\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.0617353580892086\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08807466179132462\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014178586192429066\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020175544545054436\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04658766835927963\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04486433416604996\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12454681843519211\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05196883901953697\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03336106985807419\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.0057110111229121685\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07350306957960129\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04101046547293663\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06758435070514679\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04279148206114769\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06128036230802536\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08634717762470245\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023690974339842796\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.061738867312669754\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08807373046875\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.01417501550167799\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02017337456345558\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04658849909901619\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.044867437332868576\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.1245403066277504\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051970165222883224\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03335457667708397\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005695076659321785\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07341090589761734\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04101167246699333\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06758152693510056\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.0427909716963768\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061278700828552246\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08634726703166962\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023690981790423393\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06174203008413315\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08807250112295151\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.01417220663279295\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02017160877585411\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.046589601784944534\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04487093910574913\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12453454732894897\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.051967162638902664\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.033349182456731796\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005680548492819071\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07332847267389297\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04101383313536644\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06758017092943192\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04278962314128876\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.0612775981426239\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08634734153747559\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023691007867455482\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06174483522772789\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08807097375392914\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014170093461871147\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020170211791992188\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04659099504351616\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.044874805957078934\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12452927231788635\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05196010321378708\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03334474191069603\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005667340941727161\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07325528562068939\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04101627692580223\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06757981330156326\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042787522077560425\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06127694621682167\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08634740859270096\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023691028356552124\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.061747271567583084\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08806917816400528\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014168601483106613\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02016913890838623\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04659268260002136\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.044879015535116196\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.1245243102312088\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.051949433982372284\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03334111347794533\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005655372515320778\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.0731908455491066\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.0410185232758522\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06758009642362595\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.042784787714481354\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08634743094444275\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02369103953242302\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06174931675195694\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08806714415550232\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.01416767854243517\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020168347284197807\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04659465700387955\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04488350450992584\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.124519482254982\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051935672760009766\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03333817049860954\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005644557997584343\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07313458621501923\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04102025181055069\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06758074462413788\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.042781561613082886\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08634744584560394\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023691032081842422\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06175098568201065\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08806494623422623\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.01416730135679245\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02016778662800789\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04659689590334892\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04488817974925041\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12451458722352982\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05191927030682564\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033335812389850616\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005634809844195843\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07308594137430191\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04102129116654396\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06758157163858414\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04277794808149338\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06127690523862839\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08634741604328156\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023690996691584587\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06175224855542183\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08806265145540237\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014167454093694687\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020167404785752296\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.046599358320236206\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04489296302199364\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1245095431804657\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05190078169107437\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03333393484354019\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.00562603073194623\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07304426282644272\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04102160036563873\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06758242100477219\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04277409240603447\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06127732992172241\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08634736388921738\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023690946400165558\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06175310164690018\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08806031942367554\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014168137684464455\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020167170092463493\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04660199582576752\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04489774629473686\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12450423091650009\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05188073590397835\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.0333324559032917\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005618121009320021\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07300890237092972\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04102122783660889\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06758324056863785\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.042770106345415115\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06127791851758957\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08634728193283081\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.02369087003171444\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06175355985760689\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08805805444717407\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014169365167617798\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02016705460846424\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.046604711562395096\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044902410358190536\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12449854612350464\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05185958743095398\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03333129733800888\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0056109800934791565\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07297910749912262\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.041020262986421585\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06758398562669754\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04276607930660248\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06127863749861717\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08634719252586365\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02369077503681183\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061753615736961365\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08805586397647858\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01417115330696106\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020167043432593346\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.046607427299022675\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.0449068658053875\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12449247390031815\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.051837753504514694\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03333041071891785\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.0056044915691018105\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07295402884483337\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04101888835430145\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06758461147546768\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04276210069656372\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06127944961190224\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08634711802005768\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023690663278102875\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06175330653786659\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08805383741855621\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014173504896461964\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020167117938399315\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.046610016375780106\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04491100832819939\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12448598444461823\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.051815614104270935\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03332973271608353\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005598544143140316\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0729328915476799\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.041017282754182816\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06758513301610947\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04275823384523392\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06128035485744476\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.0863470584154129\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023690542206168175\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.061752624809741974\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08805198222398758\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014176410622894764\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020167283713817596\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04661237448453903\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04491473361849785\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12447916716337204\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.051793474704027176\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03332922235131264\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005593028850853443\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07291484624147415\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.041015610098838806\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.0675855427980423\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042754530906677246\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061281342059373856\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.0863470733165741\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02369040995836258\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06175161525607109\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08805035054683685\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014179833233356476\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020167529582977295\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04661441221833229\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044917993247509\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12447208911180496\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05177163705229759\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.0333288349211216\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.0055878353305161\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07289901375770569\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.041014041751623154\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06758586317300797\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04275102913379669\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06128237023949623\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08634714037179947\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023690275847911835\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.061750318855047226\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08804893493652344\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014183691702783108\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020167866721749306\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.046616073697805405\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04492071643471718\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12446482479572296\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.051750294864177704\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03332853317260742\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005582875572144985\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07288466393947601\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04101269692182541\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06758607923984528\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04274773970246315\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06128344684839249\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.0863473191857338\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023690149188041687\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06174876540899277\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08804773539304733\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014187870547175407\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02016829513013363\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.046617332845926285\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.0449228473007679\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.1244574710726738\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05172961205244064\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03332829475402832\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.0055780671536922455\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07287120819091797\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04101165756583214\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06758623570203781\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.042744677513837814\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.061284519731998444\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08634763956069946\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023690028116106987\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.0617469884455204\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08804675191640854\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014192244969308376\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020168812945485115\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04661817476153374\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04492434859275818\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12445013225078583\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.051709793508052826\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033328089863061905\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005573350004851818\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07285799086093903\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04101094603538513\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06758632510900497\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.042741842567920685\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06128557771444321\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08634809404611588\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02368992194533348\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06174502894282341\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08804596215486526\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014196634292602539\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020169418305158615\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04661862924695015\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04492519050836563\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12444288283586502\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05169091746211052\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033327892422676086\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005568683613091707\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.0728447288274765\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.041010547429323196\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06758638471364975\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04273924604058266\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.061286598443984985\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08634873479604721\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023689832538366318\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06174290552735329\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08804537355899811\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014200889505445957\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02017010748386383\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.046618737280368805\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.044925350695848465\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12443574517965317\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.051673077046871185\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03332770988345146\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005564028397202492\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07283095270395279\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04101041331887245\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06758641451597214\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04273686930537224\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06128754839301109\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08634954690933228\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023689763620495796\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06174064427614212\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08804495632648468\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014204834587872028\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02017085812985897\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04661855101585388\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04492483660578728\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12442876398563385\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.051656294614076614\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03332751244306564\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005559363402426243\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07281652837991714\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04101047292351723\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06758642941713333\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042734719812870026\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06128838285803795\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08635059744119644\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02368972823023796\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06173822656273842\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08804469555616379\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014208296313881874\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02017166279256344\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04661811143159866\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044923651963472366\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12442197650671005\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.051640573889017105\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033327311277389526\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005554670933634043\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07280115783214569\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04101063683629036\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06758645176887512\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042732805013656616\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06128907948732376\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08635186403989792\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023689720779657364\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06173568218946457\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08804459124803543\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014211149886250496\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020172495394945145\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04661748558282852\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04492185264825821\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12441539764404297\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05162591114640236\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03332710266113281\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005549937952309847\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.0727846622467041\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.041010838001966476\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.0675864890217781\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04273109883069992\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.061289623379707336\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08635339885950089\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023689748719334602\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06173299252986908\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08804464340209961\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014213253743946552\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.0201733335852623\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04661671072244644\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.044919464737176895\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12440904229879379\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.0516122542321682\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.0333268865942955\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005545154679566622\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07276689261198044\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04101100191473961\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06758657097816467\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042729608714580536\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06128999963402748\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08635521680116653\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023689813911914825\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06173016503453255\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08804480731487274\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014214507304131985\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020174149423837662\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.046615827828645706\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04491657391190529\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12440291792154312\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05159957334399223\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033326659351587296\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005540317855775356\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07274772971868515\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04101109132170677\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06758667528629303\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04272833094000816\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06129016727209091\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08635728806257248\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023689918220043182\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06172719597816467\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08804508298635483\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.01421482302248478\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020174920558929443\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.046614859253168106\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044913243502378464\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12439707666635513\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05158782750368118\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03332643210887909\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005535421427339315\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0727270171046257\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.041011083871126175\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06758683174848557\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042727239429950714\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061290159821510315\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08635968714952469\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023690063506364822\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06172407791018486\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08804547786712646\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014214137569069862\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020175624638795853\n",
      "Search Iteration [10/20], Validation Loss: 0.05508580892770128\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.08947382867336273\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.11454673856496811\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.13003116846084595\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05114523321390152\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.049475766718387604\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.00550732621923089\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.08045858144760132\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.050282783806324005\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.06915072351694107\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04488760605454445\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06276144087314606\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.15942563116550446\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02496381103992462\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.07203700393438339\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.08823997527360916\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04132219776511192\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.0231159757822752\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.053013674914836884\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.04857783764600754\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12456737458705902\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05282256379723549\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.04169691354036331\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.010180262848734856\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.0950954332947731\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.041663698852062225\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.09140461683273315\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04557602480053902\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06304717063903809\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1277354657649994\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02381073497235775\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06282228231430054\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.0963449776172638\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.033956605941057205\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02743997983634472\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.057423174381256104\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04532135650515556\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.1243528202176094\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05152116343379021\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.036518968641757965\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005591627676039934\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07257851958274841\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04325028881430626\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06762377172708511\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05015811696648598\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06237223744392395\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.09858798235654831\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024907557293772697\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06300396472215652\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.0879935696721077\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014977840706706047\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02235923334956169\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04659567400813103\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.046423524618148804\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12488065659999847\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.052535902708768845\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03338111191987991\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005875921808183193\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.0754818245768547\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04115872085094452\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06777560710906982\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.045252714306116104\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06167276203632355\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08920760452747345\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023807158693671227\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.0617062970995903\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08816052973270416\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014023019932210445\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02098759450018406\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.047133881598711014\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04570393264293671\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12435788661241531\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051392100751399994\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03440072014927864\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005514657124876976\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.0753035768866539\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04125049710273743\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06777280569076538\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04576363041996956\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06128678098320961\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.09009558707475662\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024270234629511833\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06196650117635727\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08798284083604813\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01423652283847332\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020645910874009132\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04662603139877319\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04545051231980324\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12443965673446655\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05371283367276192\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033325400203466415\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005498242564499378\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07321605086326599\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04220319166779518\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06765582412481308\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.046596210449934006\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06151128187775612\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.09041285514831543\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02400081790983677\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06217192858457565\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08800098299980164\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014072728343307972\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020427487790584564\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04728502035140991\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04517943784594536\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12435364723205566\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05308789387345314\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.033455610275268555\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005446915049105883\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07318156212568283\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04145636409521103\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06786368042230606\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.045566145330667496\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061312489211559296\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.09026631712913513\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.024109508842229843\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.062211982905864716\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08799617737531662\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.01404070109128952\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020425809547305107\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04741697013378143\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.0453333780169487\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.1244095042347908\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05350213125348091\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03335890918970108\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.0054189348593354225\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.0720004290342331\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04154732823371887\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06818602234125137\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04539290443062782\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061280738562345505\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.09011361747980118\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.024140534922480583\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06209089234471321\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08798809349536896\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014025960117578506\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020391201600432396\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.047493189573287964\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04524487629532814\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12437114119529724\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05311591178178787\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033323243260383606\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005411126650869846\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07180309295654297\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04162546247243881\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.0678025633096695\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.045205481350421906\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06127680838108063\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08916742354631424\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.02402346022427082\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06212681904435158\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.0879930853843689\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.01403387077152729\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.0203655157238245\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047519195824861526\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.045244283974170685\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.1243712455034256\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05286399647593498\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03332136943936348\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005412860307842493\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07221993058919907\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04144839569926262\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06759446859359741\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04461091384291649\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06129002943634987\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08828938752412796\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023973405361175537\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06207745522260666\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08799310028553009\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014021486975252628\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.0203715730458498\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04740405082702637\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04532581567764282\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12435327470302582\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.0525810532271862\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03333798423409462\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.0054194508120417595\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07354503124952316\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.0414680540561676\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06761320680379868\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.044192124158144\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061307456344366074\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08759559690952301\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023925652727484703\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.062001023441553116\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08798656612634659\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.01402145903557539\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.02037939243018627\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04717979580163956\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04538275673985481\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12447217851877213\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05215780436992645\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03338642418384552\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005419181194156408\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07577335089445114\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04155474901199341\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06769046187400818\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.043958548456430435\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06129486858844757\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08713892102241516\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023892605677247047\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061923008412122726\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08797992765903473\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.01405492052435875\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.0203997865319252\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046927545219659805\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04537317156791687\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12493116408586502\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.051588814705610275\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03343501687049866\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005421970505267382\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07827074825763702\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.041908420622348785\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06758387386798859\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.044222284108400345\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.0612792894244194\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08716431260108948\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023923933506011963\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06185919791460037\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08798523992300034\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014185050502419472\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02041303738951683\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04676711931824684\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04523714259266853\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12549123167991638\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05123083293437958\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033382974565029144\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005418119486421347\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.0782507136464119\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04188473895192146\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06758060306310654\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.044083237648010254\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06129317730665207\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08700565248727798\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023954272270202637\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06186610087752342\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08800111711025238\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014394523575901985\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020458506420254707\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04659605771303177\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04518336430191994\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12661238014698029\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05119962617754936\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03332575783133507\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005417056381702423\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07530730962753296\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04108864441514015\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06981251388788223\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042833562940359116\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.061286237090826035\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.0863715186715126\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.02399415522813797\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06219141557812691\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08797953277826309\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014368346892297268\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020623236894607544\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04659440740942955\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04493987560272217\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12763167917728424\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.051472194492816925\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033404331654310226\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005465599242597818\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07215305417776108\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041686419397592545\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07405291497707367\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04301172494888306\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06139717623591423\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08635236322879791\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02401328645646572\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06247985363006592\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08845462650060654\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014095262624323368\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02048407308757305\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04897201806306839\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04484716057777405\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12446165084838867\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.051580801606178284\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03335680067539215\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005411552265286446\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07409636676311493\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04101158306002617\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.0704081729054451\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04270476475358009\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06137073412537575\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0866536870598793\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023919448256492615\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.062091290950775146\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08823945373296738\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014018851332366467\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020309126004576683\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04860149323940277\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04484036937355995\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12453807145357132\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05155404284596443\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03336147591471672\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005411573685705662\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07433967292308807\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04103177785873413\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07045143842697144\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04270227625966072\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06140003353357315\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.0866391584277153\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023925675079226494\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.062112364917993546\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08826015144586563\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014018812216818333\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020305495709180832\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.048421233892440796\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04484114423394203\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12455011159181595\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05150517076253891\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03335823491215706\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.0054125310853123665\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07435391843318939\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04112110286951065\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07075605541467667\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04270980879664421\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06142198666930199\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08658812195062637\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023930376395583153\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.062122415751218796\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08826836198568344\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014019092544913292\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020319337025284767\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.048262663185596466\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04484371468424797\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.1245688647031784\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05144582688808441\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033355943858623505\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005415481049567461\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.0742649957537651\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04139053821563721\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07111280411481857\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.042739637196063995\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06143650412559509\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08653584867715836\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023932306095957756\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06210525706410408\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08826760947704315\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014019912108778954\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020319972187280655\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04806936904788017\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04484253749251366\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12454362958669662\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.051364582031965256\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03335518762469292\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005424574948847294\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07380742579698563\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04289589449763298\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.07242835313081741\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04275434836745262\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061434634029865265\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08640661090612411\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023961903527379036\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06202949956059456\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08813203871250153\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014048513025045395\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02057153917849064\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04739638790488243\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.0450047105550766\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.1259579360485077\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05116228386759758\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.0333622582256794\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005444880574941635\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07400813698768616\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.048342470079660416\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07526383548974991\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04399070516228676\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06132044643163681\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08634943515062332\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023867759853601456\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06198533624410629\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08798038959503174\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014216074720025063\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020255601033568382\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04673612490296364\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04512765258550644\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12726294994354248\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05115977302193642\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03332595154643059\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005495969206094742\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07262624800205231\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.051630206406116486\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07151665538549423\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.044241368770599365\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06170103698968887\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08687020093202591\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.0239397045224905\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06203669682145119\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.0884077399969101\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01402689702808857\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020364435389637947\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04960931837558746\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04483780637383461\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12436214834451675\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051624491810798645\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03332517296075821\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005412796046584845\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07261006534099579\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.05563890561461449\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07511064410209656\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04378173500299454\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06199735775589943\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08746744692325592\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.024005495011806488\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06194430962204933\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08866100013256073\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014022400602698326\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020263617858290672\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04979553818702698\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04486975073814392\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12435309588909149\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05169925466179848\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03338674455881119\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005439390428364277\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07338616251945496\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04636909440159798\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07142090797424316\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04389122501015663\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.061550844460725784\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08669298887252808\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023858705535531044\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06193253770470619\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08867070823907852\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014018822461366653\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.02016785554587841\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04951275885105133\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04484715312719345\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12435269355773926\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.051689304411411285\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033377546817064285\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005423226859420538\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07365827262401581\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.049987003207206726\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07173341512680054\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.044002335518598557\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06166128069162369\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08686881512403488\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023848826065659523\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06184142082929611\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08858197182416916\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014024553820490837\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020183563232421875\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.048996634781360626\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.044866275042295456\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12435267865657806\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051615990698337555\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03341647610068321\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.0054235272109508514\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07392871379852295\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.05260102450847626\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07191554456949234\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.043453142046928406\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06178745627403259\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08712764084339142\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02388807199895382\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061850689351558685\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08856350928544998\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014050670899450779\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020179446786642075\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04861047863960266\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04484720528125763\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12452863156795502\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05147823318839073\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03352220728993416\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005417157895863056\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.0744858831167221\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04867757111787796\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06903306394815445\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04333026707172394\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06154819577932358\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08659400045871735\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023858357220888138\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06177477911114693\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08836326748132706\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014167050831019878\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020285900682210922\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04795074462890625\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04502350464463234\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12443850189447403\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.051809877157211304\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03350391983985901\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005417439620941877\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07409396022558212\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.047819629311561584\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06969423592090607\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04328109696507454\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.061542313545942307\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08668310940265656\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023864423856139183\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06179044395685196\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08845102787017822\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014104045927524567\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020416662096977234\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04811738431453705\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04490610212087631\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.124534472823143\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.051314450800418854\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03351416066288948\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.0054113189689815044\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07469499111175537\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.049418091773986816\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.0682142823934555\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.043317973613739014\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06148592755198479\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08649616688489914\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023848887532949448\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.061822470277547836\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08827332407236099\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014259222894906998\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020715083926916122\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04770258441567421\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.045065686106681824\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12439359724521637\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051766201853752136\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03345286473631859\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005411083810031414\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07358844578266144\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.05034222453832626\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.0691080242395401\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.043510083109140396\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06146945059299469\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08656716346740723\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023831307888031006\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06176579371094704\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08838392049074173\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014164124615490437\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020539306104183197\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04770183563232422\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.044935472309589386\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12436657398939133\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051657553762197495\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03346984088420868\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005415181163698435\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07382848113775253\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.05231873691082001\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06983226537704468\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04296877980232239\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06176389381289482\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08668874204158783\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02391507662832737\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06176610663533211\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08840657770633698\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014209064655005932\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.02057413011789322\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04743378981947899\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04496549069881439\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12463608384132385\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05176790431141853\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03340648114681244\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005411422345787287\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.0738588348031044\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04807668924331665\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06849564611911774\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04396943375468254\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0613408163189888\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.0863582193851471\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.02381465584039688\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06195937097072601\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08841992169618607\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014130592346191406\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02057773619890213\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04806342348456383\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04489366337656975\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12443286925554276\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05171472206711769\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03349107503890991\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005411989521235228\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.074632927775383\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.05248033627867699\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06851762533187866\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.043201711028814316\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06146438792347908\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.0866168886423111\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023858314380049706\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06179248169064522\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08828233182430267\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014250979758799076\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.021008595824241638\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04765937477350235\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04493648186326027\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12435286492109299\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05169033631682396\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03347206860780716\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0054116928949952126\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07452166080474854\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.05005181208252907\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06782856583595276\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.043528929352760315\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06141241267323494\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08644411712884903\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02384178899228573\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061734311282634735\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08824735134840012\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014231842942535877\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02099122479557991\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04770459607243538\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04489298537373543\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12474527209997177\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05166065692901611\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03359542414546013\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005411119665950537\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07502196729183197\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.05291786044836044\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06758532673120499\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04275643825531006\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06133796647191048\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08664750307798386\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023900197818875313\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06183727830648422\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08812803775072098\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014311150647699833\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020467005670070648\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.047092605382204056\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04495023563504219\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12453779578208923\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.051785603165626526\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033564355224370956\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005411793943494558\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0754292830824852\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.051089636981487274\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06761214137077332\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.042746007442474365\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06135028973221779\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08663017302751541\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023912226781249046\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06179111823439598\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08807958662509918\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014284679666161537\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02062552608549595\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047070667147636414\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.0450277253985405\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12445097416639328\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05180291086435318\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033442966639995575\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005411128047853708\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07452968508005142\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.05149812623858452\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.0678909420967102\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04307479411363602\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06134554743766785\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08665288239717484\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023928234353661537\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.061651427298784256\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08819279819726944\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014427212998270988\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02038402110338211\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04766979441046715\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044854599982500076\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12469528615474701\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05168233811855316\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.033695995807647705\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005450340919196606\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07729554176330566\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.05390375852584839\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06858761608600616\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042880620807409286\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06129806488752365\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08727267384529114\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02397940494120121\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06176595389842987\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08820968121290207\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014349468052387238\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020656393840909004\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04777933657169342\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.044877778738737106\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1246199831366539\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05197213590145111\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03383614495396614\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005411073565483093\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07635175436735153\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.050279971212148666\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.07166904956102371\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04278183728456497\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06143490970134735\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.0883447527885437\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.024007821455597878\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06170647218823433\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08838675916194916\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014534047804772854\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020174624398350716\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04747212305665016\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.0448613241314888\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12468957155942917\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05236535519361496\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.034193940460681915\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.00586306769400835\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07523838430643082\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.048522431403398514\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06868007779121399\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.043222419917583466\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.0612993985414505\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08698169887065887\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023984696716070175\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.062439993023872375\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08809367567300797\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014338679611682892\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.02127401903271675\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04867352172732353\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.0448848158121109\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12603898346424103\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.053090762346982956\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03422190621495247\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005543850362300873\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07271099835634232\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04987908899784088\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06937717646360397\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.043145861476659775\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06127914413809776\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08870390802621841\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02383110485970974\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06206357106566429\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08800338953733444\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014249682426452637\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02142559178173542\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04853690788149834\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044943585991859436\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12540537118911743\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.0534241683781147\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033756811171770096\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005413326434791088\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07191634923219681\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.043874114751815796\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06937197595834732\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042729463428258896\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06134213134646416\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08657961338758469\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023822037503123283\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.0617937371134758\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08801073580980301\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014232044108211994\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.022172173485159874\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04806734621524811\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04497095197439194\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12597456574440002\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.0537060983479023\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03381621092557907\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.00541383121162653\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.0719115287065506\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04405813664197922\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.0693821907043457\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04274025559425354\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06129523739218712\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08645183593034744\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023888660594820976\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06172996759414673\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08804431557655334\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014244851656258106\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.021787473931908607\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04810389503836632\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.045015279203653336\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12602069973945618\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05373961478471756\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03367151692509651\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005411084275692701\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07205452024936676\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.0430058091878891\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06926795840263367\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042703717947006226\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06131843850016594\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08634866029024124\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02383708395063877\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06178555637598038\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08801959455013275\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014298549853265285\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.021621298044919968\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04802488163113594\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04500994086265564\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1264754682779312\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.053910668939352036\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03356032073497772\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.00542215071618557\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.0722423791885376\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04243316501379013\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06930502504110336\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.0426996611058712\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061317328363657\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08634835481643677\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02383175864815712\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06175953522324562\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.088026262819767\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.01430288702249527\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.021473325788974762\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.048039503395557404\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.045010607689619064\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.1265135258436203\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.053850628435611725\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033532824367284775\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005425379611551762\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07223725318908691\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04238061234354973\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06930524110794067\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04270591214299202\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06129448860883713\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08636391162872314\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02383682131767273\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061752792447805405\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.0880371481180191\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014321391470730305\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.021399037912487984\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.047971148043870926\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04501557722687721\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12655200064182281\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05382736399769783\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03350795805454254\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005431115627288818\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07223430275917053\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.042272649705410004\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06924577802419662\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042709507048130035\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06128537282347679\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08637796342372894\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02383548766374588\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.061745017766952515\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.0880461260676384\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014324904419481754\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02113301306962967\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04796557500958443\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04502374678850174\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12647397816181183\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05382300540804863\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033476293087005615\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005436684004962444\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07226326316595078\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04215205833315849\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.0691942423582077\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04271217808127403\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06127982586622238\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08639618009328842\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023833390325307846\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06173890829086304\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08805805444717407\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014318537898361683\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02115311659872532\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04801099747419357\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04502704367041588\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12644892930984497\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.0538000762462616\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03345959633588791\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005441144574433565\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0722450390458107\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04209265857934952\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.069163478910923\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042716704308986664\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061276648193597794\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08642014116048813\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023834319785237312\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061736878007650375\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.0880742222070694\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014321797527372837\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02108268067240715\n",
      "Search Iteration [11/20], Validation Loss: 0.05975910232148387\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.206258624792099\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.13455034792423248\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.15159006416797638\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05758516490459442\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.033538833260536194\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.025719720870256424\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.11659733206033707\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.04791688919067383\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07675212621688843\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04629046469926834\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06131549924612045\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.1313147097826004\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02617150917649269\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06743372976779938\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.08803009986877441\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.036326248198747635\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.021909261122345924\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.04757937043905258\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.05521514639258385\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12673287093639374\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.051193222403526306\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.035360030829906464\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.00576193630695343\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07262931764125824\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04183555766940117\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07383789122104645\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04839826002717018\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06810292601585388\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.08670280128717422\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02876126393675804\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06955435872077942\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08843225240707397\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.019886933267116547\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.024844666942954063\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.049976710230112076\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04532294347882271\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12490178644657135\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.051182813942432404\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03337618708610535\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005430746823549271\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07187801599502563\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04158460721373558\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.07225193083286285\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04418167844414711\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06539647281169891\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08732632547616959\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.027486244216561317\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.062477096915245056\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.0879831463098526\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.018832940608263016\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.022581130266189575\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.0488705039024353\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04536914452910423\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12571580708026886\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.052074987441301346\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03332849591970444\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005460964050143957\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07195491343736649\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04121275246143341\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07232187688350677\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.043070562183856964\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06343445926904678\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08719911426305771\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.026588143780827522\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06175800412893295\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08800465613603592\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.017626844346523285\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02183985337615013\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04948687553405762\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04510872811079025\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1253189891576767\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051848724484443665\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03332386165857315\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005505491979420185\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07203472405672073\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04101262986660004\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.0722806453704834\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.042696040123701096\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06246589869260788\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08699502050876617\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.026012970134615898\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06165217235684395\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.0880376473069191\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01611804962158203\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.021386871114373207\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.0487917959690094\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04494195431470871\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12485159188508987\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05172587186098099\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03332618996500969\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005514146760106087\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07186868786811829\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.041187893599271774\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.0730111226439476\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.0430586002767086\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.0618034265935421\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08670572191476822\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.025575701147317886\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06165580451488495\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08801942318677902\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014814015477895737\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020896999165415764\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04778699949383736\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04491795226931572\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12458383291959763\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05176025256514549\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03332642838358879\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005517167504876852\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07175498455762863\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.0414743572473526\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07279086112976074\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04350646212697029\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06151077523827553\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08662909269332886\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.025227179750800133\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06166374683380127\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08800679445266724\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014331494458019733\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020618310198187828\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.047316018491983414\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.044917792081832886\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12449734658002853\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05193265900015831\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03335332125425339\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005467861890792847\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07190622389316559\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04143378883600235\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07137253880500793\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.043707266449928284\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061417002230882645\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08679473400115967\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.025075092911720276\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.0616944320499897\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08798687160015106\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.01425226405262947\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02052556909620762\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04700322449207306\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04493648186326027\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.1244637668132782\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.0520959235727787\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03341195359826088\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005429706536233425\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07236065715551376\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04132010042667389\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06990393251180649\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.043579068034887314\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06141391396522522\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08694339543581009\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.02506188303232193\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.061714112758636475\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08798004686832428\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014197149313986301\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020473649725317955\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04684442654252052\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04489296302199364\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12446009367704391\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05206901580095291\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03338589519262314\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005423367023468018\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07232476770877838\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04146258533000946\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06993799656629562\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04376817122101784\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06132866442203522\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08689117431640625\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02497500367462635\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06174513325095177\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08799074590206146\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014126493595540524\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02040696144104004\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04667692258954048\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.0449453704059124\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12448904663324356\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05224977433681488\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033412616699934006\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005428462754935026\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07256551086902618\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04139937832951546\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.0693369209766388\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.043557118624448776\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061337053775787354\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08696287870407104\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.024963486939668655\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061746980994939804\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.0880105122923851\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014112147502601147\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020404890179634094\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.046622201800346375\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04487711563706398\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12455060333013535\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05232305824756622\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03340627998113632\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005431529600173235\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07260582596063614\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04150300845503807\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.0692235603928566\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04362804442644119\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06130412966012955\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08690940588712692\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.024735698476433754\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06176498904824257\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08801905065774918\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014107536524534225\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020344233140349388\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04659358412027359\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04500831663608551\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12452152371406555\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05242852866649628\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03345469757914543\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005423427559435368\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07290366291999817\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04142192006111145\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.0691499188542366\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04365791752934456\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06130459904670715\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08696412295103073\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.024648409336805344\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.061766620725393295\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08802789449691772\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014173517003655434\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02035634219646454\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046590663492679596\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04509551078081131\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12446398288011551\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.0523686520755291\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033523306250572205\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005411218851804733\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07355286926031113\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.041421789675951004\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06912925839424133\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04370468854904175\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06130671873688698\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08704512566328049\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.024646785110235214\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06178309768438339\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08804679661989212\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014231104403734207\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020348694175481796\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.046588998287916183\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04514733701944351\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12443746626377106\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05230733007192612\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03356163576245308\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005412971135228872\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07409373670816422\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.041616447269916534\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06932845711708069\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04385947436094284\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06129170581698418\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08693313598632812\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.024588167667388916\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.061763640493154526\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.0880463495850563\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.01422677468508482\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020330939441919327\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.0465862900018692\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.0451744869351387\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12440644204616547\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05225319415330887\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03362074866890907\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005422369576990604\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07467583566904068\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04184471443295479\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.0693206638097763\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04394366219639778\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06128185614943504\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.0868835374712944\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.024568427354097366\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06175597384572029\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08805272728204727\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.01422271877527237\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02030702494084835\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04658961296081543\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04515799880027771\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12439361959695816\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.052276212722063065\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.033730398863554\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005452939309179783\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07530809193849564\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.042493369430303574\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.069179967045784\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.043995775282382965\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06127666309475899\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0868263691663742\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.024521954357624054\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.061742138117551804\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08806336671113968\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.01422126404941082\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02028529718518257\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04658995568752289\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04513201117515564\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12438728660345078\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05216909945011139\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033793237060308456\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005485942587256432\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07593915611505508\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04276050254702568\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06885157525539398\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.043355878442525864\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.0612807460129261\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08658282458782196\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02494274452328682\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.061809081584215164\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08815869688987732\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014264099299907684\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020229848101735115\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04679958149790764\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.044846683740615845\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12474335730075836\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05280086398124695\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033610712736845016\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005411570891737938\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07377373427152634\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.043789155781269073\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06779345124959946\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04294906184077263\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06128714233636856\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08636344969272614\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.024923650547862053\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06184614822268486\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08806939423084259\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014240396209061146\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020192600786685944\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04689733684062958\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04494338482618332\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12550552189350128\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05321929231286049\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03344016149640083\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005466835107654333\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07179272174835205\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04426432400941849\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06765241920948029\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.042889513075351715\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061279114335775375\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.0863657295703888\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.025045422837138176\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.061815690249204636\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08807357400655746\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.01416848786175251\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020176365971565247\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04694068804383278\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04525322467088699\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12716557085514069\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05121302977204323\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033673789352178574\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005796524696052074\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07439828664064407\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04104655981063843\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.07225628942251205\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04286982864141464\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06152205914258957\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08635051548480988\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.024630509316921234\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.061821043491363525\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08828049153089523\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014148087240755558\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020167604088783264\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.0469529964029789\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04484391212463379\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12456570565700531\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05374827980995178\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.034288469702005386\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005475360434502363\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07417720556259155\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04419289156794548\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06757998466491699\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04283444583415985\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061276767402887344\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08647739142179489\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.025118961930274963\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.061978865414857864\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08821824938058853\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014391734264791012\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020165644586086273\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04688074439764023\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.044843994081020355\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12482619285583496\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05429444462060928\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.0344003364443779\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005543150473386049\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07395311444997787\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04506344348192215\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.0677216425538063\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.042707376182079315\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06129460036754608\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08639220148324966\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02521422505378723\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.0621073842048645\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.0882258489727974\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014383157715201378\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020170314237475395\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04686717316508293\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044839974492788315\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.1250414252281189\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05446624010801315\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.034449100494384766\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005572737660259008\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07379224896430969\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.044558677822351456\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06790562719106674\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042811110615730286\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06130295991897583\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08636584877967834\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.025188636034727097\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06218082830309868\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08821377903223038\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014332843944430351\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020191624760627747\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.0469437800347805\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04485009238123894\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.1249367892742157\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05415784940123558\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03451642766594887\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.0056013306602835655\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.073662169277668\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04437166452407837\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06810472905635834\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04291953891515732\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06130076199769974\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08635161072015762\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.025145333260297775\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06223431974649429\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08818960189819336\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014311190694570541\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020218312740325928\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04702485352754593\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04485907405614853\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12472895532846451\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05368569493293762\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03458137437701225\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005615465342998505\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07348320633172989\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.044171784073114395\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06839996576309204\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04295340180397034\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061286985874176025\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08634856343269348\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.025106817483901978\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.062256764620542526\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08816006779670715\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014286154881119728\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02022760920226574\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04704559966921806\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04487433284521103\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12467019259929657\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05347684770822525\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.034592241048812866\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005602471996098757\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07291845977306366\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04378744959831238\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06852864474058151\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04295943304896355\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.0612773671746254\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08637488633394241\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.024985965341329575\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.062222275882959366\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08811245113611221\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014250717125833035\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020238541066646576\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04713274538516998\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04490216076374054\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12456841766834259\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.053154826164245605\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03453937545418739\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005564522463828325\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07237562537193298\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.043410271406173706\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06877586245536804\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.042799998074769974\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06128000095486641\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08644039183855057\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.024935642257332802\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.062204714864492416\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08810210227966309\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.01416169572621584\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.02021825686097145\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04683781415224075\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.044867660850286484\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12589114904403687\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.056071341037750244\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03490199148654938\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005630030762404203\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07184860855340958\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04305076226592064\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06829023361206055\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04283224418759346\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06129441782832146\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08659327775239944\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.02452937327325344\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06199957802891731\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08801726251840591\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.01410051342099905\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020260347053408623\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04717997461557388\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04487379640340805\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12509723007678986\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.054633237421512604\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.034644026309251785\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.0055280644446611404\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07176288962364197\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04208078980445862\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06778702884912491\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04280335083603859\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06139900162816048\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08661027252674103\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.024307282641530037\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06191086769104004\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08798915892839432\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.0140763521194458\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020405376330018044\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.0477936752140522\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.045059364289045334\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12437625974416733\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.052641648799180984\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.034062739461660385\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005443216767162085\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07191972434520721\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04201705381274223\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.0679301992058754\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04283689707517624\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061312831938266754\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08650809526443481\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.02493143267929554\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.062236908823251724\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08802029490470886\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014050360769033432\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020182685926556587\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04660854861140251\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04483899474143982\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.1255178153514862\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05444867163896561\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.034202173352241516\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005547594744712114\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07349223643541336\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04129258170723915\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06795256584882736\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04271451383829117\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.061470698565244675\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08634757995605469\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.024082140997052193\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.0617232508957386\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08798515796661377\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014145798981189728\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.02016610838472843\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04683312028646469\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04484901577234268\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1251436024904251\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05436618626117706\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03402291238307953\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.00543248699977994\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07230812311172485\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.0415140762925148\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06768999248743057\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04270379617810249\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06153283640742302\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08643051236867905\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.024103593081235886\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06176207214593887\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08797955513000488\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.0140343913808465\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020474011078476906\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04775204136967659\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.045050300657749176\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1245090514421463\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05309513956308365\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03404776006937027\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005426068790256977\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07282517105340958\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04130478948354721\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06786858290433884\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.042722202837467194\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.061545636504888535\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08640393614768982\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.024224495515227318\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06184065341949463\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0879819393157959\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014040309004485607\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020257486030459404\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.046913061290979385\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04483843967318535\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12550051510334015\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.054815471172332764\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033859215676784515\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005411077756434679\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07372884452342987\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04101945832371712\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06761128455400467\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.042726486921310425\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06178412213921547\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08641905337572098\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023778488859534264\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06165151298046112\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.0880783200263977\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01401880756020546\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020438889041543007\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04922168701887131\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04515276476740837\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12436433881521225\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.052172549068927765\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033663418143987656\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005422085989266634\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07479919493198395\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04101041704416275\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.0676533505320549\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.042942605912685394\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06130804494023323\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08634749799966812\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.024552682414650917\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06202864646911621\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.0879887267947197\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014024033211171627\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02021787501871586\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04660136252641678\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044855885207653046\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12497293204069138\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05352488532662392\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033934205770492554\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005417847540229559\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07445931434631348\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.04105568677186966\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.0675867348909378\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04276663810014725\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061732217669487\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08634834736585617\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.02382182888686657\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.0616566464304924\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08802145719528198\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014040932059288025\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02028399519622326\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047963742166757584\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04510420933365822\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12436185777187347\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05227339267730713\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033627964556217194\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005415346007794142\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07413244992494583\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.0410127118229866\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06766752898693085\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04283709079027176\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06141601502895355\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08634749799966812\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.024260278791189194\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06183451786637306\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08798309415578842\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014023641124367714\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020194966346025467\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04665485396981239\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044848889112472534\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12491223216056824\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05350346490740776\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03379199653863907\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005415722727775574\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.0743955746293068\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.041027430444955826\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06760529428720474\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04277344048023224\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06172936037182808\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08636558800935745\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023737801238894463\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06165977194905281\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08809918165206909\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014019613154232502\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02036680094897747\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04915162920951843\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04521831497550011\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12435579299926758\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.052560050040483475\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03365468978881836\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005422762129455805\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07544372975826263\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.041143644601106644\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06760703027248383\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04289548844099045\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06159894913434982\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08635522425174713\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.024100355803966522\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.061741556972265244\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08798115700483322\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014036692678928375\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020192651078104973\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04668399691581726\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04485776275396347\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12485012412071228\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05319880321621895\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033614687621593475\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005431529600173235\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.0744602158665657\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04102259501814842\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06758825480937958\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04274943843483925\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.061777710914611816\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08634829521179199\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023831382393836975\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06166019290685654\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08802589774131775\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014027923345565796\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020429780706763268\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04834914952516556\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04508284479379654\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12435617297887802\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.052264418452978134\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033501509577035904\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005445042625069618\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.0749308317899704\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.041021134704351425\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06763722747564316\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04282878711819649\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061405472457408905\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.0863628163933754\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.024193765595555305\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06175857037305832\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08798681199550629\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014023647643625736\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02019496075809002\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04667576402425766\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044854436069726944\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12475941330194473\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.053126875311136246\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03363210707902908\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.0054450626485049725\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07473935186862946\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.041016582399606705\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06758075952529907\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04274211823940277\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06169066205620766\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08634726703166962\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02383396402001381\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06165407970547676\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08799830079078674\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.01402977854013443\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02034798637032509\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.048040058463811874\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.045064736157655716\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12435685098171234\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05225010961294174\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033456940203905106\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005456787534058094\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07460590451955795\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04101041704416275\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06766536086797714\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04278920590877533\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061389416456222534\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08636955916881561\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02413257770240307\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06174704059958458\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.0879875123500824\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014021257869899273\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020189641043543816\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04671624302864075\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04484992474317551\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1247314065694809\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05312545225024223\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.033603545278310776\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005456959363073111\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07496068626642227\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04101056605577469\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06758218258619308\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042738817632198334\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06166012957692146\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.086350217461586\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023842880502343178\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061652932316064835\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08798355609178543\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014030818827450275\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02028300054371357\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04767341911792755\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04502176120877266\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12437376379966736\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05239666998386383\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03344602882862091\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.0054670521058142185\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07439917325973511\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04101099073886871\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06769219785928726\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.0427398607134819\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.061397045850753784\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08639265596866608\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.024069856852293015\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06169573590159416\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08799126744270325\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014023764990270138\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02018488571047783\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04675374925136566\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04484505578875542\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12472081929445267\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.053105972707271576\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03356345370411873\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005468267947435379\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07508666068315506\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.041012201458215714\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06759411096572876\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04272225871682167\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06156560406088829\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08636396378278732\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023924320936203003\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06165347248315811\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08798203617334366\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.01405755802989006\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020234234631061554\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.0471792072057724\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04490712285041809\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12453019618988037\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05294332653284073\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.033469367772340775\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005471911747008562\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07458401471376419\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.0410580076277256\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06764513999223709\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04273897409439087\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061449892818927765\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08643833547830582\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.024056851863861084\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.0616600401699543\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08799734711647034\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014052296057343483\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020183414220809937\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04673893749713898\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.0448388010263443\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12471127510070801\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05309617519378662\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03348693624138832\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005471452139317989\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07477688789367676\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.041042666882276535\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06760040670633316\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.042724065482616425\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06147051602602005\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08642139285802841\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023991728201508522\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06165348365902901\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08800512552261353\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014078548178076744\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.0201957356184721\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04684558883309364\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044842544943094254\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12459539622068405\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.052851345390081406\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033457446843385696\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005467348266392946\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07443715631961823\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.041051775217056274\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06760392338037491\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042733632028102875\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06145768240094185\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08644777536392212\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.024009397253394127\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061654239892959595\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08803156018257141\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014067359268665314\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020191766321659088\n",
      "Search Iteration [12/20], Validation Loss: 0.05922728525474667\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.0833706185221672\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.07050026953220367\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.13242828845977783\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.07112981379032135\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.04575291648507118\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.02691451832652092\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.21036189794540405\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.06150837615132332\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.09662985801696777\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.0430825911462307\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06127865985035896\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.1911860555410385\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.028928527608513832\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06490673869848251\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.0883457362651825\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.05144057050347328\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.020279889926314354\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.052451666444540024\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.050535425543785095\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12475243955850601\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05239507183432579\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03907535597681999\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.00602254644036293\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07396140694618225\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04104651138186455\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07703527808189392\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.04330882057547569\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06172017753124237\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1033511757850647\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.030505632981657982\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.07730444520711899\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08860082179307938\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.059268560260534286\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.021685384213924408\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.054379258304834366\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04539819806814194\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.124435655772686\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.051659632474184036\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03809696063399315\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.0054951012134552\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07355169206857681\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.04131048545241356\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.0721452534198761\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.044940728694200516\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.061334624886512756\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08983233571052551\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024261120706796646\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06176992878317833\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08799397200345993\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014523448422551155\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02091958187520504\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04659320414066315\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04543879255652428\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12504999339580536\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05286094918847084\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03332144021987915\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005411086138337851\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07904014736413956\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04203072935342789\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07257482409477234\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.042818017303943634\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06127919629216194\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08688286691904068\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02369002066552639\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06211695820093155\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08807667344808578\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014152538031339645\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020543811842799187\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04788891598582268\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04630788788199425\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12445227801799774\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05592776834964752\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03336132690310478\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005433287937194109\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07199571281671524\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04118886962532997\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06764993071556091\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04334046691656113\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06128304451704025\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.0884377583861351\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02415170706808567\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.062230344861745834\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08800999820232391\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01432331744581461\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020425651222467422\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.046587467193603516\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04548829421401024\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12658679485321045\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.051192231476306915\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03332528844475746\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005430877208709717\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07501719892024994\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04171242192387581\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06826946139335632\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04550083726644516\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06157485023140907\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08895456790924072\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02412388101220131\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06202234327793121\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08798040449619293\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014130293391644955\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020297111943364143\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04712998867034912\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.045283447951078415\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12477245181798935\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05260852351784706\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.033328089863061905\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005411173682659864\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07191790640354156\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04107736796140671\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07049217820167542\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04332880675792694\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06128060817718506\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08738115429878235\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023792419582605362\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06261590868234634\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08808518201112747\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014074339531362057\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02025805599987507\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.047746725380420685\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.045676831156015396\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12435612827539444\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05372841656208038\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03332154452800751\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005412222817540169\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07175809144973755\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04105214774608612\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06759095191955566\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04376418516039848\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06128016114234924\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08869000524282455\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.024116305634379387\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06256058812141418\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08806823939085007\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014029188081622124\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020297912880778313\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04779849573969841\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.045564908534288406\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12437466531991959\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05351456627249718\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033323731273412704\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005411145277321339\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.0718965008854866\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.041015226393938065\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06758993864059448\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04355929419398308\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061293989419937134\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08794794976711273\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.024087024852633476\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06238933652639389\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08803475648164749\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014060480520129204\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02032933197915554\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047445472329854965\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04560649022459984\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12435907125473022\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05320774391293526\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03332507237792015\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.00541576137766242\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07324449717998505\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04109802469611168\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06763556599617004\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.0435468964278698\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06129429489374161\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.0874764621257782\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02399512752890587\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06222837418317795\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08802413195371628\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014066620729863644\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02032383717596531\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04733199626207352\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04555399343371391\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12439369410276413\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.053151119500398636\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03333321586251259\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.0054182508029043674\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07429249584674835\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04111760854721069\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.067776158452034\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04347670450806618\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.0613010972738266\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08712593466043472\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023938894271850586\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.0621257908642292\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08801132440567017\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.01408302504569292\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020334653556346893\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.047136612236499786\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04555328190326691\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12450436502695084\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05297241359949112\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03334980458021164\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005416365340352058\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07559797912836075\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.041128844022750854\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06793121248483658\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.043428368866443634\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06130405515432358\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08688078820705414\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02389412559568882\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06204712390899658\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08799734711647034\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014111760072410107\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020350346341729164\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.0469379648566246\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04554499313235283\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1247534528374672\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.052584849298000336\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03337541222572327\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.00541277090087533\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07708155363798141\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.041150759905576706\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06793130934238434\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.043473370373249054\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.0612955205142498\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08678510785102844\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023880839347839355\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06199008598923683\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.0879853144288063\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.01418222300708294\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020377028733491898\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04677066206932068\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04552898183465004\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12517811357975006\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05197777599096298\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.033404845744371414\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005413827486336231\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07924386858940125\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04132191464304924\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06761109828948975\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04369998723268509\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06127912178635597\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08696071058511734\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023943332955241203\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.061924953013658524\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08798015862703323\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014391565695405006\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.02042667753994465\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04666456580162048\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04546128958463669\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.125715970993042\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.0513739250600338\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03338243067264557\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.0054201530292630196\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.08018399029970169\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.041442837566137314\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.0675872266292572\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04388834908604622\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06127683073282242\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08714930713176727\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.024034496396780014\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06190712749958038\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08798036724328995\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014684312045574188\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020477550104260445\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04658646881580353\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04529162123799324\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12685638666152954\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.051358662545681\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03339989110827446\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005448213778436184\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07577148824930191\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041055966168642044\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07165968418121338\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04296265169978142\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.061304979026317596\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08638625591993332\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023938708007335663\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06228042393922806\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08804307132959366\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014967271126806736\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02070721425116062\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04803042858839035\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.044924985617399216\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.13121487200260162\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.053013745695352554\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03342462703585625\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005429242737591267\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07177899032831192\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04453814774751663\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.07113608717918396\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042697396129369736\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06181996315717697\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0864146277308464\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.02414923720061779\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06288983672857285\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08806508779525757\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014227100647985935\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02051733061671257\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04822366684675217\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.044838350266218185\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12483131140470505\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05130823701620102\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03334713727235794\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005433517508208752\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07475421577692032\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04124708101153374\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07333125919103622\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042823147028684616\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06146174296736717\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08642077445983887\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023876404389739037\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06254573911428452\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08839508891105652\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014019140973687172\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020214028656482697\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.05033600702881813\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04484429582953453\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.1243801936507225\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05206834524869919\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033345479518175125\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005471460055559874\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07383503764867783\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04124317318201065\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07169261574745178\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.0427456870675087\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06148018315434456\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08662646263837814\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023869074881076813\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.062375012785196304\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08849388360977173\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014032741077244282\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020189067348837852\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.05038496479392052\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.044840991497039795\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12444218248128891\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.052212752401828766\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03338843584060669\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.0054723653011024\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07439727336168289\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04124495014548302\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.0711868479847908\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04272126406431198\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06149337813258171\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08664169907569885\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.02388680726289749\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.062426794320344925\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08849592506885529\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014029460959136486\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020192744210362434\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.050027526915073395\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.0448385514318943\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12441491335630417\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05220647156238556\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03340565040707588\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005479888990521431\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07524776458740234\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04131525754928589\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0717313140630722\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.042723845690488815\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061519041657447815\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08660434186458588\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023891540244221687\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06248588114976883\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08847803622484207\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014025288634002209\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02019793726503849\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04968621954321861\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.044838208705186844\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12438619881868362\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05217806622385979\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03339878097176552\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005484320688992739\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07585018873214722\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04160827770829201\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07303756475448608\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04275982826948166\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06155652180314064\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08655151724815369\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023888859897851944\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06252054125070572\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08845001459121704\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014021318405866623\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020206477493047714\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04937353357672691\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04483921453356743\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12436351180076599\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05214392766356468\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033404167741537094\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005482865031808615\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07646044343709946\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04209765046834946\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07439731061458588\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04282110556960106\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.061565469950437546\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.0864887610077858\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023887787014245987\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06250615417957306\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08839001506567001\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014018810354173183\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.0202273391187191\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04902490973472595\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04484439268708229\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12435303628444672\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05205615609884262\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.0334148183465004\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005478068254888058\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07707254588603973\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04294433072209358\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07591881603002548\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042835529893636703\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06141327694058418\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08634860813617706\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.02394120581448078\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.0622217170894146\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08802024275064468\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.01417785044759512\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020409489050507545\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04697036370635033\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04487664997577667\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12595918774604797\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.051198843866586685\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03332441672682762\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005435314029455185\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07543931901454926\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.046752795577049255\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07423889636993408\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.042695991694927216\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.0618293397128582\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08659867197275162\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023692017421126366\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.061652250587940216\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.0881430134177208\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.016761017963290215\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020458819344639778\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.046655263751745224\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.045268651098012924\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12828652560710907\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05144385248422623\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033331286162137985\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005431106314063072\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07259391993284225\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.046068478375673294\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06946133077144623\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04310520738363266\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.0615650936961174\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08634787052869797\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02388264797627926\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06293296813964844\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08823603391647339\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014028281904757023\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02021666429936886\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.05057961866259575\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04484836012125015\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12436284124851227\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05175815522670746\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03334883600473404\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005472423043102026\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07492204755544662\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04533589631319046\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07494601607322693\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04375247657299042\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06175518408417702\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08664412051439285\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023826582357287407\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06252864003181458\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08853130042552948\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014021104201674461\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020182212814688683\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.051339179277420044\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04499392211437225\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.124440997838974\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.051769811660051346\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.033323366194963455\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005494008772075176\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07379793375730515\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04885895550251007\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07445492595434189\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.043260253965854645\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06213728338479996\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08644154667854309\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023798750713467598\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.062440380454063416\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08832760900259018\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014038550667464733\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020274050533771515\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.049514129757881165\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04491810500621796\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12440630048513412\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.0514703206717968\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033326875418424606\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005447945557534695\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.0743003636598587\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.05134877935051918\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07306670397520065\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042794838547706604\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06157384067773819\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08639911562204361\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023883579298853874\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.062623530626297\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08811883628368378\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014196922071278095\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020524539053440094\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.048680853098630905\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04513241723179817\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.125091090798378\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05117432400584221\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03332678601145744\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005487691145390272\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07370951026678085\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04908595606684685\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06978097558021545\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04307214170694351\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06158032268285751\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08663655072450638\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02382473461329937\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06234748288989067\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08835742622613907\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014047007076442242\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020165635272860527\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.05093078687787056\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04509381204843521\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12457059323787689\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051435645669698715\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.033321402966976166\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005455044563859701\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07453309744596481\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.054042477160692215\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06846732646226883\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04280664026737213\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061471786350011826\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.0869448259472847\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023829640820622444\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06232284754514694\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08850084245204926\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014129061251878738\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020437927916646004\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.05069630593061447\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.045523080974817276\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12516508996486664\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051325034350156784\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03335002437233925\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.0054471734911203384\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.0744016095995903\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.05378654599189758\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06771621108055115\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042696285992860794\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06141616031527519\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08712930977344513\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023872753605246544\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06238555908203125\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08834002912044525\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.01410690601915121\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020215200260281563\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.050688646733760834\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.045261599123477936\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12489478290081024\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.051317088305950165\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.033361367881298065\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005462894681841135\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07541846483945847\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.05375457927584648\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06760287284851074\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04277399554848671\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06134099140763283\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08857761323451996\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023951109498739243\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06283964216709137\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08858107030391693\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014302561990916729\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02019963227212429\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04940725117921829\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04517988860607147\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12478815019130707\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05144526809453964\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03345927968621254\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005411261692643166\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07373946160078049\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04811536520719528\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06758453696966171\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.042705267667770386\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06149835139513016\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08825284987688065\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.02383347973227501\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06261923164129257\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08850254118442535\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.01432567648589611\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020313343033194542\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04943378269672394\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.045062363147735596\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12498794496059418\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05238991603255272\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03369467705488205\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005653005558997393\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07250940799713135\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04826589673757553\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06782019138336182\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04273439198732376\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.061398204416036606\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08826471865177155\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02391461655497551\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06252258270978928\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08845282346010208\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014469300396740437\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020830262452363968\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.048325516283512115\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044884100556373596\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.1247028335928917\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.053257670253515244\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03393356129527092\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005880358163267374\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07282726466655731\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.05178196728229523\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06793556362390518\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04277152568101883\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061375942081213\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08828989416360855\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.0238436758518219\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06318120658397675\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.0880998894572258\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014185725711286068\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020165856927633286\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04923636093735695\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.045198727399110794\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12636756896972656\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.054296523332595825\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03412631154060364\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005747111514210701\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07181968539953232\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.04916011169552803\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06834230571985245\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04275553673505783\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061505626887083054\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08916620165109634\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.02377924695611\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.062415264546871185\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08800645172595978\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014149817638099194\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.021769322454929352\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.049483850598335266\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04511924833059311\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12603424489498138\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05445864424109459\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033802345395088196\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.00544854998588562\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.0720207616686821\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04607057571411133\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06841933727264404\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042697057127952576\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06152203679084778\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08770424127578735\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023766392841935158\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06194663792848587\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08800137042999268\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014116710983216763\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.021417034789919853\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.0492401123046875\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04515013471245766\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12573781609535217\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05474906787276268\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.033654242753982544\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005417296197265387\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07242073863744736\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.044079218059778214\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06856095790863037\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042709071189165115\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.0615970753133297\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08682166039943695\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02379082329571247\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06180814653635025\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08801932632923126\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014162649400532246\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02109198272228241\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04898405447602272\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04509532451629639\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12523536384105682\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.054876793175935745\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03367599844932556\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005427998024970293\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07233796268701553\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04387689754366875\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06848064810037613\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04271102696657181\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.061571650207042694\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08660480380058289\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023793989792466164\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06185061112046242\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08802339434623718\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014173806644976139\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.021314524114131927\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04922383278608322\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.045155011117458344\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12582078576087952\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05489557981491089\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03367043659090996\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.00545145757496357\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07224182784557343\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.044018615037202835\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06850539147853851\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04269746318459511\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06150667741894722\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08655854314565659\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023794924840331078\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.061844002455472946\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08802447468042374\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014178052544593811\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.021488891914486885\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04931683465838432\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04515281319618225\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12586896121501923\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05484013259410858\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033648531883955\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005452980753034353\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07218750566244125\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04401577264070511\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06852744519710541\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269610717892647\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06148466840386391\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08649827539920807\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.02379392832517624\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061848390847444534\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08802498131990433\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01417615171521902\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.02160198614001274\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.0493791364133358\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04514771327376366\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12610021233558655\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.054897602647542953\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03363010659813881\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005474635399878025\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07215367257595062\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04392583668231964\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06860275566577911\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04269636049866676\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.0614641010761261\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08645153045654297\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02379731275141239\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06183899939060211\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08802652359008789\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014181289821863174\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.021659815683960915\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.049324776977300644\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04515130817890167\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12613224983215332\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.054743241518735886\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03360680863261223\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0054623279720544815\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07213868200778961\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.0437813326716423\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06856320798397064\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04269745200872421\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06143610551953316\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08641092479228973\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023803094401955605\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.061822958290576935\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08803755789995193\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014179092831909657\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.021482566371560097\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04941936954855919\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.045116156339645386\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12591297924518585\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05480383336544037\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03363003209233284\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005500836297869682\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07205840945243835\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04384101927280426\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.068515844643116\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042702049016952515\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06140686571598053\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08638358861207962\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023807233199477196\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06181615963578224\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08804292976856232\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.01419173926115036\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02168155461549759\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04933957755565643\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04512963443994522\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12596821784973145\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05468938499689102\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033613335341215134\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005489838309586048\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07202832400798798\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.043616652488708496\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.0684460699558258\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04270472750067711\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06138528138399124\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08636581152677536\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02380308136343956\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06181006878614426\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08804689347743988\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014187474735081196\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02158157154917717\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04936397075653076\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.045103900134563446\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12600190937519073\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05480889603495598\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033585451543331146\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005466163158416748\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07206074893474579\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.0433083102107048\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06844013184309006\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04270259663462639\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06137853115797043\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08635250478982925\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023808132857084274\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06179811805486679\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08805929124355316\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014191724359989166\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.021560465916991234\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.049463655799627304\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04509614035487175\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1258770376443863\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05477096140384674\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03360371291637421\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005488970782607794\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07201778888702393\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04332739859819412\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06844712048768997\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042708009481430054\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061361804604530334\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08634869009256363\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023805206641554832\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.0617867112159729\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08805923908948898\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014185130596160889\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02166762202978134\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.049372583627700806\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.045096803456544876\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12592089176177979\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05479663982987404\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033575765788555145\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005479276180267334\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.0720234289765358\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.0432085320353508\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06849449127912521\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04270978644490242\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061356641352176666\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08634740114212036\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023800794035196304\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06178096681833267\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08806295692920685\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014181261882185936\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.021628739312291145\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.049416206777095795\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.045099858194589615\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12592557072639465\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.054744306951761246\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03356500715017319\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005465479101985693\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07202793657779694\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04325767979025841\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06852621585130692\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04271450266242027\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06134717911481857\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08634719252586365\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023793144151568413\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06176917999982834\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08806688338518143\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014169310219585896\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02165621519088745\n",
      "Search Iteration [13/20], Validation Loss: 0.0631632068194449\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.09114715456962585\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.09442393481731415\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12436391413211823\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05453360080718994\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.05043605715036392\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.006511170417070389\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.07429353892803192\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.05011967197060585\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.0824018269777298\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04727376624941826\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.0669335424900055\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.13056108355522156\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023694468662142754\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06644415110349655\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09672153741121292\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04235784336924553\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.03335719183087349\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.061515968292951584\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.04669523611664772\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12451294809579849\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05115201696753502\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03470171242952347\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005417253822088242\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07299008220434189\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04879061505198479\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.0677158460021019\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.058051515370607376\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06765108555555344\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.09689542651176453\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.025655733421444893\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.0665375292301178\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08800657093524933\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.017079750075936317\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.03368951007723808\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.048236120492219925\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04827537387609482\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12444383651018143\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.051812972873449326\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033371224999427795\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005444798618555069\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07224807143211365\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.050106823444366455\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.0676925778388977\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05344955250620842\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06614326685667038\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.0929182916879654\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.025755679234862328\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06423025578260422\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08808116614818573\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.018428226932883263\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02441943809390068\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.05157473310828209\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04826536029577255\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12496346235275269\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05122886225581169\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03368012234568596\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005660508759319782\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07286527752876282\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.042387012392282486\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07751274853944778\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.043404750525951385\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06257503479719162\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08922658115625381\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.024917220696806908\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06259628385305405\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08797985315322876\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.015473850071430206\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02076146751642227\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04694373160600662\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.045709360390901566\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12448102980852127\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051732733845710754\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.0335346944630146\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.0065614753402769566\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07239353656768799\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04101210832595825\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07676596194505692\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04306178167462349\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061881259083747864\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.0864093154668808\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023724107071757317\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06165426969528198\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.0879882350564003\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014514565467834473\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020253028720617294\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04668957367539406\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04488713666796684\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12443934381008148\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05117842182517052\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03368762135505676\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.006175011396408081\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07218196243047714\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04108933359384537\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07246441394090652\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04354654625058174\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06155681237578392\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08641517907381058\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02368899993598461\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06194581091403961\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08798062056303024\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.01492880005389452\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020347701385617256\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04669949412345886\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04532759636640549\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12439041584730148\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.051686711609363556\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03434193879365921\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.006797693204134703\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07443870604038239\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.0410132110118866\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07188833504915237\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.043475933372974396\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06143147870898247\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08634757250547409\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023695683106780052\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.061894144862890244\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.0879860520362854\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014259985648095608\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020325787365436554\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04681031033396721\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04503509774804115\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12435387820005417\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05135077238082886\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03408576548099518\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.0060865310952067375\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07389866560697556\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04104328155517578\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07160128653049469\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04348815977573395\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061350204050540924\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08636461198329926\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023685486987233162\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06197511777281761\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08799371123313904\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.0143243707716465\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02030290849506855\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04676077514886856\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.0453142374753952\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12437250465154648\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05158476531505585\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.034173883497714996\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.00607282854616642\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07454658299684525\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04101073369383812\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.07111889868974686\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04341334104537964\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06129789724946022\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08637567609548569\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023686792701482773\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06185239925980568\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08799120783805847\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014216000214219093\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02030199207365513\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04677068814635277\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04533785954117775\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12435980141162872\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.051611628383398056\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03400656208395958\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005854128859937191\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.0740140751004219\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.041017692536115646\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07053062319755554\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04341081157326698\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06127871572971344\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08642414212226868\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02370300516486168\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06181737408041954\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08798925578594208\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014219874516129494\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020291665568947792\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04675355181097984\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04554738476872444\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12437523156404495\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05177285149693489\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03391813859343529\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005767175927758217\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07378446310758591\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.0410146526992321\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06994161754846573\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04334576800465584\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061279114335775375\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08649507164955139\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.02373541332781315\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06175755709409714\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.0879855528473854\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014206623658537865\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020296957343816757\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04675044119358063\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.0457148402929306\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12438329309225082\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05185294151306152\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03378954157233238\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005653909873217344\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07325505465269089\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.0410250760614872\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06925034523010254\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.043310459703207016\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.061295803636312485\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08661912381649017\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023790137842297554\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.0617213174700737\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08798490464687347\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014235124923288822\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020303744822740555\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046743325889110565\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04595045745372772\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12440012395381927\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.051926139742136\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03365326300263405\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005563224665820599\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07262128591537476\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04105323180556297\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.0685822144150734\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.043264176696538925\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06132614612579346\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08678843826055527\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023862898349761963\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.061696141958236694\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.0879863053560257\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014290541410446167\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02031986601650715\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.0467260405421257\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.046206943690776825\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12440022081136703\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051980044692754745\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03350749984383583\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.00549002829939127\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07198785245418549\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.0411236435174942\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.0681062713265419\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04324174299836159\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06135847046971321\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08696790039539337\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02393360063433647\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.061684269458055496\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08799095451831818\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014379007741808891\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020344365388154984\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04669865965843201\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04639232158660889\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12437428534030914\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05199108645319939\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.0333845391869545\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005441879387944937\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07176289707422256\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04124782606959343\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06785847991704941\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04329460859298706\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06137854605913162\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08718766272068024\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023992963135242462\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06169665977358818\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08800101280212402\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.01449232455343008\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020383641123771667\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04668040946125984\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04646209627389908\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12435553222894669\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05187290534377098\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033326733857393265\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005414903629571199\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07213232666254044\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041374705731868744\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06774930655956268\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04343058541417122\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06137634068727493\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08752985298633575\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.024060653522610664\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.061753153800964355\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08801520615816116\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.01460431981831789\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020460082218050957\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.046685364097356796\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04648229479789734\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12435267865657806\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05167793855071068\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03332679718732834\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005415528081357479\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07259206473827362\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04141848906874657\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.0677688866853714\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04357244074344635\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061343394219875336\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08775021135807037\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.0240884181112051\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06185498088598251\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08803510665893555\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014717803336679935\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020577149465680122\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.046669621020555496\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04642346501350403\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12436141073703766\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05147437006235123\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03338421881198883\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005460885353386402\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07317811995744705\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04141974449157715\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06775391101837158\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04364657774567604\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061297956854104996\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.0878349021077156\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02408965677022934\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06195526570081711\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08804351836442947\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014755538664758205\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020681003108620644\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04666798934340477\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.046102073043584824\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.1243775337934494\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.051337823271751404\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.0334172248840332\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.00547249848023057\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07363362610340118\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04120274633169174\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.0680822804570198\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04343309998512268\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06127818673849106\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08716367185115814\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02394852787256241\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06196369603276253\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.0880783423781395\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014797377400100231\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02074422687292099\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.0465875044465065\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04581509530544281\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12458960711956024\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.051154591143131256\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033559463918209076\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005509442184120417\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07492364943027496\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04107725992798805\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06794370710849762\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.043172888457775116\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061294324696063995\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08672277629375458\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023890726268291473\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06181947514414787\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08808880299329758\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014914121478796005\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020830050110816956\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04665737971663475\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04554099217057228\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12508182227611542\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05122527480125427\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033400729298591614\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005411235615611076\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07400448620319366\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04128545522689819\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0710771381855011\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04272058606147766\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06142797693610191\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08652906864881516\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023780083283782005\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06186261028051376\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08818049728870392\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.015165344811975956\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02139437012374401\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04896339029073715\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04512577876448631\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12770797312259674\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051159050315618515\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03419516235589981\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.006747105624526739\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07263118028640747\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04374193772673607\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07081396132707596\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04279469698667526\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06136387214064598\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08634714037179947\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023722492158412933\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06165162846446037\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08804627507925034\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014020485803484917\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020523851737380028\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04760851338505745\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04486489295959473\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12435704469680786\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05126267299056053\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03333379328250885\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005447040777653456\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07178474217653275\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04158538579940796\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07258838415145874\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04298732802271843\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06127973273396492\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08635265380144119\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02378658577799797\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06189445033669472\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08807924389839172\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014020544476807117\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.02053668722510338\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04739465191960335\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04485670104622841\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12441103160381317\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05133500695228577\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03332170844078064\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005436635576188564\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07208684831857681\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04176425561308861\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07231717556715012\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04299321398139\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08634869009256363\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023796746507287025\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.061965107917785645\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08808163553476334\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014020562171936035\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02051607519388199\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04726861044764519\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04486269876360893\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12443139404058456\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05127391219139099\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03332135081291199\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005442841909825802\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07211831957101822\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.042117949575185776\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07259704172611237\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04305676743388176\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06127709150314331\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08635139465332031\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023795371875166893\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06201823055744171\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08808043599128723\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014022584073245525\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020549815148115158\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.047200169414281845\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.044861748814582825\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12443265318870544\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05125740170478821\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03332154080271721\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005455134902149439\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07209956645965576\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.042680297046899796\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07279638946056366\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04316023737192154\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06127914413809776\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08635098487138748\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023786375299096107\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06203840672969818\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08808652311563492\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014021429233253002\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020562900230288506\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04719877243041992\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04486848786473274\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12439800053834915\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05127869173884392\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03332165628671646\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005465032532811165\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07205500453710556\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04373368248343468\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07283785939216614\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04333466663956642\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061284758150577545\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08634714782238007\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02377486787736416\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.062010571360588074\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08810275793075562\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014018806628882885\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02061721496284008\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04725058004260063\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04487798735499382\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12435533106327057\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05132686719298363\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03332189470529556\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005463623907417059\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07196637243032455\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04669387266039848\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07262424379587173\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.043746765702962875\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.0613289475440979\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08644328266382217\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02378067374229431\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.061902448534965515\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08822863548994064\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.01405891589820385\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020772593095898628\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.047544240951538086\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04492020606994629\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12438860535621643\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.0514867827296257\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03332135081291199\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005433457437902689\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07194482535123825\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.049431703984737396\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.0716114416718483\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.043540824204683304\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06146122142672539\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08707943558692932\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023811550810933113\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06189454346895218\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.0886392593383789\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.01411902904510498\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020226944237947464\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04849874973297119\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04525693878531456\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12460538744926453\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.051678698509931564\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03340955078601837\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.0054554748348891735\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07282465696334839\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04417620971798897\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.07073011994361877\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04329335689544678\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06139155477285385\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08639790117740631\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02385205589234829\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06186055392026901\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08822725713253021\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014025810174643993\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02032875083386898\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.047448623925447464\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044932182878255844\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12435850501060486\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05152887850999832\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03341320902109146\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005421620327979326\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07386038452386856\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04869867116212845\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.07078374922275543\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.044184308499097824\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061875101178884506\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08681617677211761\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.024164604023098946\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.0623355470597744\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08818002790212631\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014056574553251266\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020247522741556168\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.047623731195926666\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.0449054092168808\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12439075112342834\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05154763162136078\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03336156904697418\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.00541674206033349\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07386468350887299\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04271619766950607\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.07162109017372131\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04301534593105316\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06134333461523056\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08639676123857498\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02380019798874855\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.0620599165558815\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08826012909412384\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014023127034306526\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020305005833506584\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04802175611257553\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044875528663396835\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12435328215360641\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.051781896501779556\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.033406853675842285\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005454012658447027\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07372374087572098\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04372936859726906\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.07183459401130676\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04317687451839447\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061367738991975784\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08640795201063156\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023825062438845634\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06204177811741829\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08824805170297623\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014026752673089504\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020283358171582222\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.047947295010089874\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.044878214597702026\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12435444444417953\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05173957720398903\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03345693275332451\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005486378446221352\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07412620633840561\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04492344334721565\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07073686271905899\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.0432160459458828\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06138741225004196\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08645409345626831\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023806942626833916\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06203862652182579\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08825097233057022\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014034677296876907\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02027783915400505\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04788347706198692\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044891439378261566\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12436556816101074\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05172685906291008\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03350395709276199\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005508239846676588\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07436307519674301\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.046839531511068344\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06927422434091568\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.043070752173662186\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06138646975159645\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08657988160848618\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023790204897522926\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.0620388500392437\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08826367557048798\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014059681445360184\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020239999517798424\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04778549447655678\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04489920660853386\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12435834854841232\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05166997015476227\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.0335574597120285\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005500581581145525\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07462666183710098\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.05150992423295975\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06763971596956253\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.0426996611058712\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06128856539726257\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08708411455154419\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.02379007451236248\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.061951249837875366\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08824198693037033\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014145173132419586\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02023940719664097\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04765954241156578\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044981155544519424\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12436196208000183\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05156825855374336\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033614613115787506\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005523437634110451\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07435054332017899\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.05164891853928566\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06780187785625458\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04330459609627724\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06133345142006874\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08718772977590561\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023913536220788956\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.062003299593925476\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08820660412311554\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014159542508423328\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020200954750180244\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047655388712882996\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.0448518805205822\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12466507405042648\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05152187496423721\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033508893102407455\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005456422455608845\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07359878718852997\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04902870953083038\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06808680295944214\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04360659420490265\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.0613241009414196\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08764365315437317\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023938728496432304\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.0621311329305172\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08831057697534561\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014129526913166046\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020175062119960785\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.047599438577890396\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044838469475507736\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.1250845491886139\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05213497579097748\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.033761754631996155\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005528537556529045\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.0735897496342659\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.0484301820397377\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06799813359975815\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.0433557890355587\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.061276961117982864\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08840348571538925\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02385999634861946\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06207292154431343\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08826720714569092\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014164368622004986\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020166508853435516\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.0474892221391201\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04483891651034355\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1257541924715042\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.052924398332834244\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03413650020956993\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005739299580454826\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07296165823936462\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04693492874503136\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06780485063791275\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.043066661804914474\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06129844859242439\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08838187903165817\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023781362920999527\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06204391270875931\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08807831257581711\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014205548912286758\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020228618755936623\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04776609688997269\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04483809694647789\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12607252597808838\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.053466252982616425\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.034220825880765915\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005697163287550211\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07216194272041321\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04663391783833504\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06762576848268509\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04276847094297409\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06147097423672676\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08926092833280563\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023719564080238342\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.061986181885004044\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08799605071544647\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014101884327828884\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020450621843338013\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04843027517199516\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044854193925857544\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.125892773270607\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05354418605566025\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03405660018324852\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005504551809281111\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07175445556640625\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04388241469860077\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06760739535093307\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04272119328379631\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061782799661159515\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08840156346559525\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023709101602435112\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061919085681438446\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08798238635063171\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.0140876779332757\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020594600588083267\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04858486354351044\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04485669732093811\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12562352418899536\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.0532660037279129\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03385130316019058\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005426187068223953\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07209354639053345\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04185151681303978\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06770246475934982\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.0428362675011158\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.0619596466422081\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08711256086826324\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023728419095277786\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06193535402417183\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08798003196716309\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014154823496937752\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020501982420682907\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.048588886857032776\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04485199600458145\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12548331916332245\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.053255464881658554\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03363458067178726\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005411103833466768\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.0725390762090683\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.0412457212805748\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06775528192520142\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042911652475595474\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06210238113999367\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08657832443714142\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023746613413095474\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.061870276927948\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08798355609178543\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014223017729818821\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020450422540307045\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04827765002846718\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04484972357749939\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.1253003180027008\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.053094640374183655\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03360890597105026\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005411599297076464\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07268428802490234\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04104815796017647\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06781035661697388\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042905643582344055\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061832498759031296\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08639705926179886\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023782534524798393\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061917662620544434\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08798769116401672\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014272118918597698\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02044391632080078\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.048276614397764206\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04485025629401207\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12530729174613953\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05326978862285614\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03351384401321411\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005416428670287132\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07292346656322479\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04102519527077675\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06779066473245621\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042904749512672424\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06176973879337311\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08634957671165466\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023796234279870987\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06178488954901695\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08800210803747177\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014270461164414883\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02048349566757679\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.048078861087560654\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04485651105642319\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12514415383338928\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05313801020383835\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033515021204948425\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005416661035269499\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07302019745111465\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04101230949163437\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06779376417398453\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04290732368826866\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06173429638147354\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08634717017412186\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023815393447875977\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061800915747880936\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08799491077661514\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014283232390880585\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020488334819674492\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.048102233558893204\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04485751688480377\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1251102089881897\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.053235847502946854\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03344367817044258\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005425700452178717\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.0732005164027214\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04101058468222618\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06779178231954575\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04289636388421059\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06168091297149658\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08636796474456787\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02382340095937252\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.061724405735731125\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08800824731588364\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014275960624217987\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02055233344435692\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04797189310193062\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.044864557683467865\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12501950562000275\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05312284827232361\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03343941271305084\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.0054235151037573814\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07323698699474335\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.041011400520801544\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06775810569524765\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04287118837237358\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06164710968732834\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08638625591993332\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02383860945701599\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06172936037182808\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08800435811281204\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014292225241661072\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020536361262202263\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04792559891939163\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04486436769366264\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12498535215854645\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.053156767040491104\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033395908772945404\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005428414326161146\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07331728935241699\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.041010744869709015\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06775107979774475\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04286036267876625\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06160581484436989\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.0864126980304718\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023839497938752174\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06168971583247185\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08801411837339401\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014268510043621063\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020618809387087822\n",
      "Search Iteration [14/20], Validation Loss: 0.06303037968887525\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.08170794695615768\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.05170411244034767\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12859374284744263\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05889935418963432\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.05323507636785507\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.042419880628585815\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.16750149428844452\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.24940147995948792\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08951037377119064\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.09135719388723373\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.07550392299890518\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.20880363881587982\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.026032909750938416\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06318611651659012\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09762335568666458\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04623863473534584\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.05087488144636154\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.06385685503482819\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.06262773275375366\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12474917620420456\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.06740129739046097\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.041395656764507294\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.008848574943840504\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.0951007753610611\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.051992736756801605\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.10390952974557877\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.042933207005262375\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06905046850442886\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1283150017261505\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.030292782932519913\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06408832222223282\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08885110169649124\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.020765837281942368\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02122761309146881\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.0467957966029644\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04698384925723076\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12955540418624878\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05113617330789566\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03334960341453552\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005477301776409149\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07522763311862946\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.051800407469272614\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.0869050920009613\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04272760450839996\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06584170460700989\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08797260373830795\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024219408631324768\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06458078324794769\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08807079493999481\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014046142809092999\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02165479026734829\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04834715276956558\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.044851671904325485\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12600533664226532\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05114978924393654\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.0333244614303112\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005553134251385927\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07642413675785065\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.05496207997202873\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.08101946115493774\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.042784739285707474\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.0636829361319542\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08761078864336014\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.024167362600564957\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.062391020357608795\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08800529688596725\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01403879001736641\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02055000700056553\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.048094820231199265\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.044922687113285065\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1251572221517563\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05117732286453247\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03332202881574631\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.0056989481672644615\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07725181430578232\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.05189421772956848\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07609481364488602\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.042772822082042694\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.0626426488161087\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.0866030678153038\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02381722815334797\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.061804093420505524\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08800928294658661\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01403794251382351\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02022925391793251\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.047825608402490616\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.045021697878837585\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12487376481294632\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05124986171722412\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03332174941897392\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0057420674711465836\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07711590826511383\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.047538794577121735\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07244069129228592\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.0427432581782341\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.062032751739025116\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08641086518764496\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02371680550277233\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06166567653417587\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08801297098398209\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014025330543518066\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02016562782227993\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04758889228105545\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.045028023421764374\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12477652728557587\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05134064704179764\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03332322835922241\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005748022347688675\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07665790617465973\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.044412363320589066\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07029375433921814\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04271373152732849\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06171810254454613\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08637396991252899\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.023691676557064056\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06165270134806633\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08802120387554169\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014019917696714401\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020192041993141174\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.0474279411137104\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04498404264450073\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12473856657743454\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05143847316503525\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03332306817173958\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.0057494184002280235\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07614363729953766\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04250285029411316\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06902456283569336\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04269750416278839\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06155092269182205\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08636122196912766\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02368590235710144\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06167067214846611\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08802589774131775\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014019092544913292\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020244315266609192\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04734538868069649\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04492134600877762\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12473349273204803\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.051545169204473495\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03332207351922989\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.0057561080902814865\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07563402503728867\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04147406294941902\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.0682707279920578\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.042700089514255524\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06146414950489998\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08635079115629196\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023685162886977196\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.061698608100414276\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08802466094493866\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014025025069713593\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02029688097536564\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04730997979640961\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04486735910177231\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12475913763046265\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05167613551020622\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03332138434052467\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.0057675582356750965\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07516859471797943\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04106321930885315\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.0678485855460167\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.0427253358066082\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061423659324645996\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08634832501411438\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02368585392832756\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.061732884496450424\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08801678568124771\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01404265034943819\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020336560904979706\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.047293659299612045\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.044839926064014435\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12481243908405304\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.051840558648109436\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03332177922129631\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005774220917373896\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07476790249347687\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04102626070380211\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06764931976795197\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04276939108967781\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.0614134781062603\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.0863773375749588\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023687411099672318\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06177324056625366\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08800438791513443\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014074243605136871\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020357105880975723\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.047277167439460754\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04484305903315544\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12487751990556717\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.052029404789209366\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03332412987947464\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005764210596680641\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07443898916244507\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04115734249353409\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06758500635623932\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04281872138381004\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.061424944549798965\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08646482229232788\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023690158501267433\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06181906908750534\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08799129724502563\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014115431345999241\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.0203589778393507\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04725749418139458\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.04486793652176857\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12493119388818741\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05221906676888466\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.0333290733397007\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005733453668653965\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07418537139892578\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.041300274431705475\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06758268922567368\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04285404831171036\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.061450596898794174\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08662101626396179\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02369454875588417\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.061866652220487595\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08798199892044067\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014156972989439964\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.0203469917178154\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04724649712443352\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.044903792440891266\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12495946139097214\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05238999426364899\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03333588317036629\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005688642151653767\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07401664555072784\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04135286435484886\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06759313493967056\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042860109359025955\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06148092448711395\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08681727200746536\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02370002679526806\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06190602481365204\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08797959238290787\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014186353422701359\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020327003672719002\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04726250469684601\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04494619369506836\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12496395409107208\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05253683403134346\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033342309296131134\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005641465075314045\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07394188642501831\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04128986597061157\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06759502738714218\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04283878207206726\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.061506617814302444\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08698625862598419\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023704376071691513\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06192300096154213\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08798208087682724\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014191154390573502\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020303858444094658\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.047321513295173645\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.044996242970228195\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.124954454600811\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.052660875022411346\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033345744013786316\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.0056018345057964325\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07394969463348389\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04116634652018547\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06758890300989151\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04280862584710121\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.0615241639316082\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08707468956708908\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023705678060650826\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.061911508440971375\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08798474073410034\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014170650392770767\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02028019167482853\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.047423943877220154\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.045050956308841705\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12493464350700378\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05275065079331398\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03334401920437813\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005573299713432789\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07399411499500275\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04106118157505989\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.0675818994641304\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042785629630088806\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.0615365207195282\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08709020167589188\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023704444989562035\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06188037246465683\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08798608928918839\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014138206839561462\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02025659941136837\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04754892364144325\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04509515315294266\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12489777058362961\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05278082191944122\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033336739987134933\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.0055534509010612965\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07400881499052048\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04101398214697838\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.0675802156329155\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04277363792061806\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.0615481473505497\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08707273006439209\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023702261969447136\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06184312328696251\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08798719942569733\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014107223600149155\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020233197137713432\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04766896367073059\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.045111872255802155\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12483932077884674\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.0527404323220253\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033327266573905945\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005537211894989014\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07394775003194809\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.0410153828561306\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06758851557970047\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.042771097272634506\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06156221404671669\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.0870538130402565\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023700185120105743\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.061808981001377106\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08798877894878387\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014083778485655785\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020211240276694298\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.047766584903001785\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.0450977124273777\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.1247657984495163\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05264557898044586\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03332158550620079\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005520643200725317\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07380980998277664\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04103214293718338\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06760573387145996\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04277641698718071\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06157989799976349\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08704765141010284\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023698600009083748\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06178192421793938\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.0879909098148346\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014068837277591228\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02019277773797512\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.047837499529123306\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04506257176399231\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12468978762626648\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05252545699477196\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033323999494314194\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005502869840711355\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07362322509288788\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04103925824165344\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.06762458384037018\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04278839752078056\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06159989908337593\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08705491572618484\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.02369748242199421\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06176236271858215\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08799346536397934\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014060861431062222\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02017921581864357\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04788576439023018\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.045019734650850296\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12462130188941956\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.052405260503292084\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03333476185798645\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005485135596245527\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07341957837343216\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04103200137615204\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06763708591461182\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04280548542737961\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061619073152542114\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08706966042518616\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023696651682257652\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06174929440021515\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08799643814563751\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014057987369596958\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020170744508504868\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.0479164682328701\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04497825726866722\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12456417828798294\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05229891836643219\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033351458609104156\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005468902178108692\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07322260737419128\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04101846367120743\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06763909757137299\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04282524064183235\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06163341924548149\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08708517253398895\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023695984855294228\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.0617416650056839\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08799993991851807\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014059044420719147\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.02016660012304783\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.047931745648384094\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04494195803999901\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12451829016208649\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05221174284815788\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.033370934426784515\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005454993341118097\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07304678857326508\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04101048782467842\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06763112545013428\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042844127863645554\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06163930147886276\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08709462732076645\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023695411160588264\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.061738576740026474\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08800402283668518\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014063208363950253\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020165622234344482\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.047931354492902756\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04491163790225983\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12448198348283768\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05214446783065796\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03338964283466339\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.0054437825456261635\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07289880514144897\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04101767763495445\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06761717051267624\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04285871237516403\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06163570284843445\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08709250390529633\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02369493991136551\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06173913553357124\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08800821751356125\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014069038443267345\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020166616886854172\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.047915518283843994\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.044887080788612366\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.1244535967707634\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05209524556994438\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033404041081666946\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005435551516711712\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07277854532003403\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04104319214820862\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06760273873806\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04286852851510048\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06162666529417038\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08708016574382782\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023694653064012527\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.061742573976516724\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08801158517599106\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014074311591684818\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020168401300907135\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04788787662982941\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.0448681004345417\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.1244317963719368\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05206054449081421\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03341229259967804\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005430283956229687\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07268136739730835\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04108338803052902\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06759166717529297\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04287605732679367\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06161794811487198\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08706677705049515\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023694710806012154\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061748817563056946\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08801370859146118\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014078095555305481\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02017001248896122\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04785242676734924\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04485427215695381\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12441514432430267\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05203628167510033\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.033415455371141434\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005427219904959202\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07260243594646454\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.041133806109428406\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06758461147546768\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04288269579410553\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06161091476678848\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08705829828977585\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.0236952044069767\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06175805628299713\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08801533281803131\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014081276021897793\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020171064883470535\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.047809500247240067\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04484492912888527\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12440206110477448\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.052018653601408005\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03341536223888397\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0054253339767456055\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07253742963075638\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04119332134723663\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06758087128400803\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.042887698858976364\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06160401180386543\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08705390244722366\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023696111515164375\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06177026033401489\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08801718056201935\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014084715396165848\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02017163299024105\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04775754734873772\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04483954235911369\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12439140677452087\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05200442671775818\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.033413082361221313\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005423970054835081\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07248232513666153\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04126172885298729\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06757981330156326\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.042890194803476334\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061596229672431946\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08705129474401474\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023697366937994957\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06178514286875725\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08801955729722977\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014088640920817852\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.0201718807220459\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04769621416926384\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04483780637383461\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12438258528709412\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051991600543260574\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03340914845466614\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005422833375632763\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07243431359529495\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.041338030248880386\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06758076697587967\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04288984835147858\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061587460339069366\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08704926073551178\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023698940873146057\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06180233880877495\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08802251517772675\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014092967845499516\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02017192915081978\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04762660712003708\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04483934864401817\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12437533587217331\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05197947472333908\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03340395912528038\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005421803332865238\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07239191979169846\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.0414203442633152\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06758297234773636\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04288673773407936\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06157806143164635\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08704729378223419\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023700794205069542\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.061821434646844864\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08802603930234909\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014097548089921474\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020171860232949257\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.047550734132528305\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044843703508377075\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1243695467710495\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.051968228071928024\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03339787945151329\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005420826841145754\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07235464453697205\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.041506577283144\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06758581101894379\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04288111627101898\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0615684948861599\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08704549819231033\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023702874779701233\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.0618419349193573\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08803005516529083\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014102187007665634\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020171714946627617\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04747104272246361\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04485016688704491\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12436510622501373\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05195873975753784\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03339117020368576\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005419885274022818\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07232259958982468\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04159411042928696\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06758879870176315\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04287330433726311\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06155924126505852\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08704403042793274\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023705102503299713\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.061863236129283905\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08803441375494003\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014106632210314274\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02017151564359665\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.047390274703502655\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04485786706209183\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12436187267303467\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05195266380906105\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033383991569280624\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005418973043560982\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07229620963335037\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.041680190712213516\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06759165972471237\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.042863622307777405\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06155077740550041\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.0870433822274208\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02370736375451088\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06188467517495155\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08803889900445938\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014110557734966278\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.0201712679117918\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04731103405356407\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044865790754556656\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12435966730117798\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05195198208093643\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03337641432881355\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.00541807571426034\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07227607816457748\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.041761528700590134\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06759419292211533\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.042852338403463364\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06154340133070946\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08704374730587006\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023709533736109734\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06190546602010727\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.0880432277917862\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014113523997366428\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020170971751213074\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04723581299185753\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04487289488315582\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12435828894376755\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.051958926022052765\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03336847946047783\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005417163018137217\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0722627192735672\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.041835587471723557\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06759633123874664\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.042839642614126205\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.06153693422675133\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.0870450809597969\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023711519315838814\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06192488595843315\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08804716169834137\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014115110039710999\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02017064392566681\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04716675728559494\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.044878315180540085\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12435753643512726\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05197446048259735\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03336058184504509\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005416186060756445\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07225563377141953\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.0419035442173481\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06759823858737946\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042825669050216675\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06153044477105141\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08704711496829987\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023713335394859314\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06194250285625458\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08805079013109207\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014115299098193645\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020170342177152634\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04710520803928375\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044881779700517654\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12435705959796906\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05199583247303963\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.0333537831902504\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.00541514391079545\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07225269824266434\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04197351261973381\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.0676005557179451\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04281097650527954\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06152300164103508\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08705019950866699\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02371508814394474\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06195835769176483\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08805470168590546\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014114871621131897\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020170163363218307\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04705096036195755\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04488370567560196\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1243564635515213\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05201677232980728\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.033349040895700455\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005414125043898821\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07225130498409271\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.0420515239238739\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06760387122631073\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04279660806059837\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06151537969708443\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08705516159534454\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023716818541288376\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06197241321206093\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08805921673774719\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014114569872617722\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020170127972960472\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04700324311852455\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04488437995314598\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.1243557259440422\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.052034053951501846\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03334607183933258\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005413214210420847\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07225076854228973\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04213240370154381\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06760796159505844\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04278336837887764\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.061508920043706894\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08706166595220566\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023718426004052162\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.061984166502952576\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.0880640372633934\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014114168472588062\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020170137286186218\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04696226492524147\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04488351196050644\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.1243550255894661\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05205007642507553\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033344049006700516\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.00541243702173233\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.0722515806555748\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.042212627828121185\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06761270016431808\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04277154430747032\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06150414049625397\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08706989139318466\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.0237199105322361\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06199353188276291\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08806885778903961\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014113358221948147\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020170098170638084\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04692842811346054\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04488098993897438\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12435441464185715\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05206705257296562\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033342596143484116\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005411806982010603\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07225379347801208\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04229537025094032\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.0676184669137001\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04276125878095627\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06150105595588684\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08708031475543976\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023721367120742798\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06200074031949043\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08807361125946045\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014112129807472229\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020169977098703384\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04690128192305565\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04487723112106323\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12435387820005417\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05208424851298332\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033341698348522186\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0054113594815135\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07225757092237473\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04238204285502434\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06762552261352539\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042752642184495926\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06149962916970253\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08709217607975006\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023722831159830093\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.062005698680877686\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08807818591594696\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.01411039475351572\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02016977220773697\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04687997326254845\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04487280175089836\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12435338646173477\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.052099816501140594\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.0333414152264595\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005411116871982813\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07226303964853287\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.0424727164208889\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06763414293527603\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04274575039744377\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06149963662028313\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08710382878780365\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02372434362769127\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06200831010937691\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08808232098817825\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014108051545917988\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02016950398683548\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.046863406896591187\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04486827924847603\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12435298413038254\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05211138352751732\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03334186226129532\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005411080084741116\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07227035611867905\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.042567178606987\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06764450669288635\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042740531265735626\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06150057911872864\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08711326867341995\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023725945502519608\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.062008533626794815\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08808589726686478\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014105086214840412\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020169194787740707\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04685021936893463\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.0448642261326313\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12435272336006165\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05211615189909935\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033343248069286346\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005411216989159584\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07227960228919983\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.042664747685194016\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06765668839216232\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04273682087659836\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06150160729885101\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.087117500603199\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023727701976895332\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.0620063878595829\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08808869123458862\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014101501554250717\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020168883726000786\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04683898389339447\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04486103728413582\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12435272336006165\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05211132392287254\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03334587439894676\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.0054114628583192825\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07229055464267731\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04276616498827934\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06767059862613678\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04273433983325958\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06150130182504654\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08711282163858414\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023729810491204262\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.062002114951610565\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.088090680539608\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014097318984568119\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020168626680970192\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04682852700352669\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04485902562737465\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12435321509838104\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.052094120532274246\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03335026279091835\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005411738064140081\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07230264693498611\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.042875904589891434\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06768608093261719\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04273258522152901\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06149682030081749\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08709295839071274\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023732900619506836\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06199635937809944\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08809192478656769\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014092537574470043\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02016851119697094\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04681806638836861\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04485861957073212\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12435482442378998\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05205993354320526\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03335758298635483\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005411951337009668\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07231495529413223\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.043002497404813766\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06770235300064087\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042730625718832016\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06148197501897812\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08704394847154617\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023738911375403404\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.061990078538656235\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.0880918949842453\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.01408640667796135\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020168721675872803\n",
      "Search Iteration [15/20], Validation Loss: 0.057139738606797025\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.057042356580495834\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.16614598035812378\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12435689568519592\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.06322415918111801\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.03708744794130325\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.008465328253805637\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.07842626422643661\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.043262895196676254\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08498696982860565\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04609940946102142\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06494247168302536\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.146225243806839\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.02528616599738598\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.07210700213909149\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.08803050965070724\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.03504950553178787\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.02151741459965706\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.04708591103553772\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.05882032960653305\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12638366222381592\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.052122149616479874\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03892292454838753\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005884533282369375\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07509835809469223\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04709634557366371\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.06870664656162262\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.05788951367139816\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06604225933551788\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.10692994296550751\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.024899456650018692\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06728655844926834\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08806128054857254\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01848970726132393\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.03608502820134163\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04795650392770767\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05351392924785614\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12435267865657806\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05275760963559151\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03340137377381325\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005413608625531197\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07218968868255615\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.06121525168418884\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.07056881487369537\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05776260048151016\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06848540157079697\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.10455713421106339\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024153361096978188\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06309744715690613\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.09323134273290634\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.024291230365633965\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.025707973167300224\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.05200333148241043\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04524696618318558\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12460967898368835\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.051443763077259064\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.033360011875629425\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.00542284594848752\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07179541140794754\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.050658173859119415\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06845168769359589\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.05041071027517319\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06525112688541412\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.09178350120782852\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02526559866964817\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06246455758810043\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.0879797637462616\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01443403959274292\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02241554670035839\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04697631299495697\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04624250903725624\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12435922026634216\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05174318701028824\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03332135081291199\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005455166567116976\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07196303457021713\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04421078413724899\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07243556529283524\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.044881053268909454\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06210019066929817\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08991273492574692\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024732941761612892\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06187862530350685\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.0880155935883522\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014300428330898285\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.020226536318659782\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.046642545610666275\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.044925507158041\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12456221133470535\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.051502618938684464\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033400196582078934\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.00644651660695672\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07178431004285812\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04116290807723999\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.077112577855587\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04271595925092697\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06142960861325264\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.0863470807671547\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023701678961515427\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06165305897593498\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08804958313703537\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014507940039038658\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020437045022845268\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04678120091557503\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.045397303998470306\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.1251566857099533\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05130866914987564\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03337545320391655\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.00631811423227191\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07177349179983139\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04122033715248108\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07566210627555847\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04270389303565025\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06139107793569565\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08635964244604111\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02368517778813839\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06169045716524124\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08802950382232666\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014266805723309517\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020601453259587288\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.046627987176179886\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.0453852079808712\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12520438432693481\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05133325234055519\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03337385132908821\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.006239654961973429\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07176514714956284\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.041130825877189636\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07441409677267075\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04270855337381363\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06136905774474144\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.0863635241985321\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023686259984970093\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.0617515929043293\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08801296353340149\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014142121188342571\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02068518102169037\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.046586427837610245\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04532570764422417\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12514226138591766\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05136621370911598\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03338484838604927\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.006190083455294371\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07176700979471207\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04109279811382294\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.07340149581432343\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04271278157830238\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06135540083050728\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08637263625860214\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023687563836574554\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06179070472717285\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08799830824136734\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.01408587396144867\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02073335088789463\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.046613048762083054\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04529350996017456\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12505142390727997\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.051374733448028564\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03340756148099899\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.006139478646218777\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07177790254354477\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04107535257935524\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07278165221214294\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.042720336467027664\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.061343029141426086\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08637818694114685\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023686641827225685\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06181352958083153\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08798803389072418\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014056148938834667\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020751385018229485\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04665601998567581\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04527600109577179\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12494869530200958\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.051362235099077225\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033430904150009155\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.006076531019061804\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07179923355579376\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.041067030280828476\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.07236945629119873\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04272708669304848\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06133157014846802\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08638111501932144\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023685378953814507\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061831630766391754\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08798211812973022\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014041549526154995\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020760146901011467\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04668804258108139\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04525366052985191\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12485334277153015\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.051335789263248444\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03345032036304474\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.006009467877447605\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07183040678501129\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04106753319501877\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.07210071384906769\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04273227974772453\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06132128834724426\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08638548105955124\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023685291409492493\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061849355697631836\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08797968924045563\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014035931788384914\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.02077670581638813\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04670378938317299\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045211486518383026\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1247759461402893\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05130523070693016\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033467359840869904\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.00595397874712944\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07187260687351227\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04107894003391266\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.07199753075838089\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04273878410458565\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06131232529878616\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08639353513717651\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02368674799799919\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06186899542808533\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08798007667064667\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014035305008292198\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02080545388162136\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046711515635252\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04515223950147629\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.1247175931930542\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05127741023898125\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03348374366760254\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.00591507600620389\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07192916423082352\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04110294207930565\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.0720716118812561\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04275056719779968\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06130441278219223\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.0864042267203331\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02369004115462303\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.061892714351415634\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08798307180404663\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014036789536476135\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020838098600506783\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04672177881002426\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04508500173687935\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12466790527105331\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05125671997666359\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03350142389535904\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.0058924308978021145\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07201095670461655\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04114389419555664\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.07228627055883408\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042771466076374054\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06129687651991844\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08641617000102997\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.02369571290910244\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06192063167691231\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08798966556787491\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.01403853390365839\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020865872502326965\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04674379155039787\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04501475393772125\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12461476027965546\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05124755576252937\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033524129539728165\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.0058885603211820126\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.0721438080072403\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041210662573575974\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07260341942310333\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042805254459381104\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06128910928964615\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08642737567424774\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02370416559278965\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06195005401968956\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08800306171178818\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014039251953363419\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02088121511042118\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04678667336702347\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04494697228074074\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12455237656831741\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05125558748841286\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03355348855257034\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005902835633605719\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07237197458744049\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.041310571134090424\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.07295885682106018\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04285159334540367\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061281539499759674\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.0864306166768074\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023715078830718994\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06197400763630867\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08802805840969086\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.01403737161308527\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020873120054602623\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04685717076063156\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04489186033606529\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12448596954345703\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05128911882638931\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03358127549290657\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005918727722018957\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07274331152439117\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04143095016479492\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07320340722799301\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04289668798446655\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061276890337467194\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08641482889652252\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02372650057077408\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06198083981871605\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08806636184453964\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014031527563929558\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.02083178609609604\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.046947743743658066\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04485827684402466\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12443213164806366\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05135267972946167\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03358409181237221\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005895528942346573\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07321946322917938\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04151669517159462\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07316814363002777\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.042913783341646194\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061278294771909714\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.0863831490278244\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02373575046658516\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.061968155205249786\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08811064064502716\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014023887924849987\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020763538777828217\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.0470317117869854\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04484350234270096\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12440261244773865\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.051431719213724136\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03354886174201965\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005813347175717354\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07359123229980469\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04151926562190056\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07290105521678925\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04289635643362999\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061283860355615616\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.0863577276468277\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.0237430352717638\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06195371598005295\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08814913034439087\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.01401953399181366\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020691432058811188\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.047088686376810074\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04483848065137863\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12439335882663727\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05149507522583008\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03349687531590462\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005713507067412138\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07365608960390091\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04147044196724892\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.07259634137153625\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04286687821149826\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06128935515880585\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.0863480418920517\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.023750748485326767\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06195259094238281\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08817378431558609\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014018803834915161\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020632518455386162\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04711677506566048\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04483792185783386\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12439597398042679\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051520511507987976\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03345147892832756\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005636959802359343\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07343312352895737\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.041425976902246475\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07234366238117218\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042842015624046326\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06129322201013565\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08634720742702484\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02375953271985054\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06196543574333191\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08818241953849792\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014018803834915161\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020592156797647476\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04711964726448059\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.044838953763246536\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12440577894449234\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.051509466022253036\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03341858834028244\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005590038374066353\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07308001071214676\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.041418418288230896\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07217112928628922\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04282670468091965\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06129510700702667\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08634793013334274\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.02376849576830864\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.061987269669771194\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08817731589078903\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014019284397363663\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020570967346429825\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04710247367620468\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044839706271886826\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12442022562026978\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051475442945957184\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03339533135294914\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005563945975154638\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07272635400295258\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.0414862334728241\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07211283594369888\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042825035750865936\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06129450350999832\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.0863477811217308\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023777252063155174\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.062008004635572433\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08816280961036682\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014021895825862885\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02057596668601036\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04707508906722069\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04483970254659653\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12443291395902634\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05143759027123451\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03337954729795456\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005551206413656473\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07244952768087387\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.041769251227378845\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07224790006875992\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.042841117829084396\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.0612933374941349\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08634717017412186\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023784214630723\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06203164905309677\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08813630789518356\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014030332677066326\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020622070878744125\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04701443389058113\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04483858495950699\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12444982677698135\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05137598142027855\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033365704119205475\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.0055409446358680725\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07221657782793045\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04290228709578514\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07287606596946716\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04319947957992554\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06135416775941849\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08639775216579437\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023795615881681442\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06210324168205261\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08815589547157288\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014018826186656952\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020516986027359962\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04708900675177574\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04484114423394203\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12443450838327408\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051516514271497726\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.033399131149053574\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005659494549036026\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07231464236974716\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04618796333670616\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07479798793792725\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04393007606267929\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06135131046175957\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08642756938934326\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023841246962547302\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061907075345516205\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08839982748031616\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.01404711976647377\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020418493077158928\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04762473702430725\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04502137750387192\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12436196208000183\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05181978642940521\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03335407003760338\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005460621789097786\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07260753214359283\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.052039735019207\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07441757619380951\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04394250363111496\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06171565130352974\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.0876595750451088\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023869959637522697\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06188172101974487\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08928372710943222\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014242093078792095\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020201437175273895\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04979487136006355\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04559394717216492\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1259748488664627\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.051138993352651596\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03361818939447403\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0054747615940868855\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07188162207603455\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04201735928654671\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06940635293722153\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04278731718659401\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06138404831290245\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08648096024990082\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023819420486688614\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06166861206293106\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08837079256772995\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014019026421010494\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020251184701919556\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04839560389518738\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.0449434332549572\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12441205978393555\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05222708359360695\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.0333881676197052\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005481271538883448\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07213229686021805\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04293828457593918\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.07088632881641388\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.043112292885780334\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06143147870898247\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.0864245593547821\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023876363411545753\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06192105636000633\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08858315646648407\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014033851213753223\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02020997554063797\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04814881458878517\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04508147016167641\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.1243944764137268\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.052232980728149414\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03344414383172989\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005482950713485479\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.0727057158946991\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.043048761785030365\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.07161255180835724\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.043255191296339035\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061470966786146164\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.0864090695977211\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023879462853074074\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06186722591519356\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08831233531236649\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014034101739525795\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020203296095132828\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04735581949353218\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04504655301570892\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12436654418706894\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051920145750045776\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03345286473631859\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005437317304313183\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.073371522128582\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.049051545560359955\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.07325946539640427\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04414379969239235\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06167663633823395\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08683118224143982\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02382953092455864\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.061922550201416016\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08882494270801544\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014055398292839527\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020216237753629684\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04807997867465019\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.045210178941488266\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1244468241930008\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.052062682807445526\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03346262499690056\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005470109172165394\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07321611046791077\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04115031287074089\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.07156451791524887\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.042859792709350586\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06139329448342323\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08634823560714722\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023864030838012695\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06187085807323456\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08818290382623672\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014116339385509491\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020207533612847328\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.047058798372745514\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.0450168140232563\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.1245298758149147\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05165896937251091\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03345496207475662\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005413981154561043\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07420945167541504\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.043554797768592834\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07319501042366028\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04350116476416588\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06148263067007065\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.0863673985004425\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.02381599321961403\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06189734861254692\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08818413317203522\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014103755354881287\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020198170095682144\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04724840074777603\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.0450817234814167\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12436576187610626\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05187750980257988\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03352009132504463\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005422036163508892\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07425599545240402\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.05073421075940132\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.07099621742963791\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04356823116540909\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06154068931937218\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08677409589290619\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023787371814250946\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06175752729177475\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08825913071632385\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01408257707953453\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020192570984363556\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04753699526190758\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04501418396830559\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12435894459486008\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05194603651762009\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033564332872629166\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005449613090604544\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07462178170681\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.054404567927122116\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06869041174650192\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04278641566634178\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061337750405073166\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08695785701274872\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023820938542485237\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06180768460035324\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08818849176168442\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014152356423437595\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020170947536826134\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.047138575464487076\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044953353703022\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12466905266046524\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05176451802253723\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03355429321527481\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005415443331003189\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07519515603780746\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.05120692402124405\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.0677398294210434\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.042715247720479965\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061278752982616425\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.0867403969168663\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023876938968896866\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.061899974942207336\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08812779933214188\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014222723431885242\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020172636955976486\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04698917642235756\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04502272978425026\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12475109845399857\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.051833637058734894\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033600810915231705\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.0054191588424146175\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07492976635694504\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.0554870069026947\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06781628727912903\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.043568458408117294\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06135556101799011\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08749518543481827\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02397279441356659\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06208217516541481\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08825578540563583\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014117100276052952\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02028847113251686\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04738762974739075\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04488614946603775\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12527431547641754\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05191946402192116\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03364204615354538\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005457475781440735\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07409024983644485\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.05086660012602806\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.0681743174791336\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04361376911401749\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06130426004528999\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08738448470830917\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023930426687002182\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06212211400270462\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08821944147348404\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014161486178636551\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02038411609828472\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.047251686453819275\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04487237334251404\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12568114697933197\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05219569057226181\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.033744849264621735\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005542865488678217\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07363928109407425\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.050867754966020584\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06827367842197418\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.043393246829509735\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06127725914120674\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08829089254140854\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023809755221009254\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06207204982638359\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.0880904272198677\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014124572277069092\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02054906077682972\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.047408491373062134\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.0448475182056427\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12597601115703583\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05253900587558746\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03387697786092758\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005551059264689684\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07289741933345795\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04844951629638672\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06784912943840027\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.042909011244773865\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06133032217621803\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08872264623641968\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.02372511476278305\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06200788915157318\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08799904584884644\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014065802097320557\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020773008465766907\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.047880496829748154\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04484029859304428\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12610888481140137\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05288524180650711\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03384790197014809\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.00546878669410944\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07194507122039795\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.046743668615818024\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06760663539171219\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.0426962785422802\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06158844009041786\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.0891009196639061\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023691663518548012\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06194538250565529\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.0879797637462616\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014022458344697952\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020875558257102966\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.048417627811431885\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.0448630154132843\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12571844458580017\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05283939838409424\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03362284600734711\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005422036163508892\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.0718541145324707\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.041798949241638184\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06769414991140366\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042786870151758194\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.061606403440237045\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08670777082443237\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023736942559480667\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06201859936118126\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08799119293689728\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.01410973072052002\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.02077917940914631\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04799658805131912\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04484580457210541\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1256406605243683\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.052815813571214676\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03348376601934433\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005443100817501545\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07216670364141464\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04232718423008919\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06770452111959457\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04293740540742874\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061852145940065384\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08704657107591629\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02371431328356266\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.061861466616392136\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08797985315322876\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014060385525226593\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020654426887631416\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04798934608697891\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.044845160096883774\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12534251809120178\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.0525822639465332\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03341040387749672\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005506431683897972\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07253224402666092\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.041079141199588776\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06790764629840851\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042934395372867584\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061669375747442245\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08637917786836624\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023763246834278107\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061935923993587494\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08798988163471222\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014170798473060131\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020525142550468445\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04767462983727455\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044841066002845764\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1253174990415573\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05262548848986626\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03337952122092247\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.0055021969601511955\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07260363548994064\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04129372164607048\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06776579469442368\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.0429108589887619\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06165250763297081\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08642769604921341\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.023747771978378296\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06182954087853432\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08798260986804962\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014122452586889267\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020486125722527504\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.0476551316678524\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044842615723609924\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12521763145923615\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05256572738289833\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03336641937494278\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005515359342098236\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07269303500652313\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.0410500206053257\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06784854084253311\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.042884647846221924\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06158249452710152\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08634791523218155\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02377205714583397\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06181900575757027\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.0879908949136734\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014142691157758236\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020428230985999107\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04761837422847748\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04484870657324791\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12517312169075012\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.052628301084041595\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03336143493652344\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005502711981534958\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07271481305360794\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04118732735514641\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06773386895656586\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04284573718905449\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06156568229198456\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08635487407445908\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023762743920087814\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.0617716908454895\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08798728138208389\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014108135364949703\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020454712212085724\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04764118045568466\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04485255852341652\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12512826919555664\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.052616193890571594\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03335575759410858\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005499847233295441\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07277080416679382\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04116150364279747\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06773050874471664\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04283417761325836\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061555929481983185\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08634775876998901\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023766623809933662\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06175319105386734\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08798941969871521\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014102010056376457\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020462069660425186\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.047629114240407944\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044856082648038864\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12508748471736908\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.052633099257946014\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03335129842162132\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.0054915850050747395\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0728057473897934\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04118563234806061\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06770648807287216\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.042819730937480927\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06154646351933479\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.0863470658659935\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02376769296824932\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06173625588417053\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08799029886722565\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.01409437321126461\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02047637850046158\n",
      "Search Iteration [16/20], Validation Loss: 0.06074871220202609\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.11089887470006943\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.09243801981210709\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12448587268590927\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.08456650376319885\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.03507247194647789\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.02613263949751854\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.14235804975032806\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.041010480374097824\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07395351678133011\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.044641755521297455\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06350300461053848\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.150928795337677\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023721864446997643\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06279689073562622\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09929943829774857\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.04457153007388115\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.022169847041368484\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05650673061609268\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.04525930806994438\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1254604458808899\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05647822096943855\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03967064619064331\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.00580032542347908\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.08274471759796143\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.042283106595277786\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.06924185156822205\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.046138014644384384\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06151801347732544\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.0961102768778801\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.026143349707126617\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06464903056621552\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.0920247882604599\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.015431228093802929\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.020199472084641457\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.0503692701458931\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.045179203152656555\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.13386593759059906\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.051187850534915924\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.03380772843956947\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005694795399904251\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07329784333705902\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.041012994945049286\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06764841079711914\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04289461299777031\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06136725842952728\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08642662316560745\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.023844879120588303\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06194857880473137\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08802003413438797\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014109182171523571\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.020533263683319092\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.047227054834365845\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04592553898692131\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12436136603355408\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05391266569495201\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.033331047743558884\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005411936901509762\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.0718398466706276\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.041236940771341324\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06841867417097092\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04379679635167122\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06146395578980446\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08830585330724716\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.024182837456464767\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06317472457885742\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08849148452281952\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014018858782947063\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.02039087750017643\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04771001264452934\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04682905226945877\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1248931735754013\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05196216329932213\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03339885547757149\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005434474907815456\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07320398837327957\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04118771478533745\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.067683145403862\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04284577816724777\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06128106638789177\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08705220371484756\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024176083505153656\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06251738220453262\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08800750225782394\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01426532119512558\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.0205928273499012\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.046757567673921585\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.048246048390865326\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12448187917470932\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.0526847317814827\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03333791345357895\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0054344236850738525\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07206219434738159\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04107210412621498\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06811146438121796\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04320869222283363\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06130519509315491\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08763506263494492\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.02410385198891163\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06309521198272705\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08818598836660385\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.01404681708663702\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.020395606756210327\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.047498319298028946\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.04796691983938217\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12463196367025375\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05211968347430229\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.033340565860271454\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005411106161773205\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.0725427195429802\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04119796305894852\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06766463816165924\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.042830854654312134\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06127705052495003\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08696983754634857\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.024215634912252426\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06259320676326752\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08799753338098526\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014328432269394398\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02067890577018261\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04665287584066391\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04878748208284378\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12490460276603699\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.051962971687316895\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03341054916381836\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005576448980718851\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07438468188047409\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.041129931807518005\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06795389205217361\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04315539821982384\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06130066141486168\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.0871732085943222\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023989835754036903\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06249922513961792\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08802018314599991\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014110640622675419\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.02040930464863777\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04720574989914894\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.047032058238983154\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12435934692621231\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05299543961882591\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03332522138953209\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005422703456133604\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07177171856164932\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04101806879043579\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06758061051368713\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04297630116343498\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06127915903925896\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08705464750528336\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.02402442693710327\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06262035667896271\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08803388476371765\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014049631543457508\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020436212420463562\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047087106853723526\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04790855944156647\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12436044961214066\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.052509721368551254\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03332533687353134\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005437169224023819\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07175436615943909\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.041098713874816895\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06758484244346619\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04281679540872574\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06127705052495003\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08680535107851028\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02408137358725071\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06239442899823189\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08798535168170929\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01419067569077015\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02058650553226471\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04670682176947594\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04822869226336479\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12466605007648468\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05232957378029823\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03342169150710106\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005537961144000292\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07434402406215668\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04107188433408737\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.067741259932518\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04294699430465698\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061277106404304504\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08697637915611267\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.024010004475712776\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06231159344315529\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08798743784427643\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014173317700624466\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020473558455705643\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04688428342342377\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.0471932515501976\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12454142421483994\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05274733528494835\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.0333552360534668\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005444956477731466\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07290390878915787\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04101164638996124\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.0675843358039856\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.0429515466094017\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06127720698714256\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08681315183639526\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02391471341252327\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06234673783183098\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08799713104963303\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.01405100803822279\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.02042338252067566\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046999115496873856\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.047123901546001434\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12438660115003586\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05301123857498169\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03333761915564537\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005435507744550705\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07209538668394089\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04102707654237747\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06760615110397339\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.0428326353430748\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06127714365720749\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08667901903390884\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023944728076457977\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06221814826130867\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08798683434724808\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014079168438911438\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02050255611538887\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046831462532281876\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.04745340347290039\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12444737553596497\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.052902378141880035\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03338342905044556\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005467807408422232\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07302609831094742\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04101787880063057\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06759924441576004\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04283027723431587\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06127827987074852\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08679076284170151\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.0239939596503973\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06216125190258026\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08798599243164062\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.01414711493998766\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.0205247662961483\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04683670774102211\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.047282736748456955\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12448865920305252\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05287374556064606\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03339897096157074\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005474855192005634\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07346444576978683\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04103243723511696\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06761178374290466\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042864203453063965\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06127886846661568\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08690999448299408\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.024006541818380356\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06220989301800728\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08799463510513306\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014122714288532734\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02049160748720169\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04697177931666374\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04705240577459335\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12441923469305038\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.052871424704790115\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03337676823139191\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005471840500831604\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07296379655599594\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041012149304151535\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06758084148168564\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04284666106104851\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06127934902906418\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08680782467126846\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023995233699679375\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06214207038283348\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08799127489328384\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014129109680652618\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020520726218819618\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04690749570727348\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.047016389667987823\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12444949150085449\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05286077782511711\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.033405859023332596\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005489144008606672\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07349050790071487\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04102237522602081\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.0675966814160347\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.042862243950366974\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061281509697437286\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08695757389068604\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.024038152769207954\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06216726452112198\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08799935132265091\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014134002849459648\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020505353808403015\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04701509326696396\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.046838223934173584\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12441638112068176\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05275709182024002\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033397573977708817\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005501623265445232\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07337730377912521\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.041011106222867966\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06758048385381699\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042867280542850494\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061280593276023865\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08690309524536133\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.024036504328250885\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.062114983797073364\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08799652010202408\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014152802526950836\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020523790270090103\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.046976808458566666\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04674560949206352\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12444311380386353\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.052711501717567444\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03342217206954956\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005518915131688118\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07382212579250336\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04101041704416275\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06758005172014236\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04288842901587486\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.0612805001437664\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08698540180921555\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.0240574162453413\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.0621243454515934\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.0880003422498703\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014155020006000996\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020505990833044052\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04705178365111351\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.046571485698223114\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12442658841609955\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05259380862116814\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033414386212825775\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005529323127120733\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07378589361906052\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.041031405329704285\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06760930269956589\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04288855567574501\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06127787381410599\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.0868452861905098\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.024028955027461052\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06201063096523285\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08799070864915848\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014210191555321217\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020537909120321274\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04691483452916145\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.046499915421009064\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.1245085820555687\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.052552901208400726\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.03346250206232071\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005543259903788567\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07433363795280457\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04109770432114601\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0676514059305191\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.042916156351566315\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.0612768828868866\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08691629022359848\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.024060651659965515\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06203984469175339\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08798788487911224\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014225820079445839\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020487701520323753\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04698134586215019\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.0463249608874321\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12450607866048813\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05233707278966904\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03345705196261406\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005563504062592983\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07411343604326248\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04144597426056862\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06796913594007492\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042897142469882965\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.061276983469724655\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08675294369459152\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02403709851205349\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.0618804506957531\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08797980844974518\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014408466406166553\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020529642701148987\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04674666374921799\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04632654786109924\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12470290064811707\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05200664699077606\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.0335836261510849\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005673511419445276\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.075189508497715\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04158826544880867\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06768376380205154\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04291965439915657\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06129196658730507\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08698135614395142\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.024160236120224\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.061935700476169586\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08798491209745407\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014488684013485909\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020520497113466263\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04694046452641487\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04629669710993767\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12457618862390518\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051999397575855255\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03346811607480049\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005590623710304499\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.074008509516716\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.044657591730356216\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.07150951772928238\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04270920529961586\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06135617941617966\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08671300858259201\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023785823956131935\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06173571199178696\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.0882936492562294\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.015568365342915058\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02080235630273819\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.05034451559185982\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04660656675696373\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12868915498256683\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.052669353783130646\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.034800317138433456\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.00674222968518734\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07259353250265121\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.046890828758478165\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07049636542797089\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04364127665758133\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06132151186466217\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.0863470658659935\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02400433085858822\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06327050924301147\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08826502412557602\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.01403897162526846\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.02016562782227993\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.05099795013666153\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04483797773718834\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12446911633014679\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05171765759587288\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03357647359371185\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005610163323581219\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07251325994729996\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04701622948050499\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07178843766450882\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04398053139448166\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06139063462615013\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08643504977226257\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02393181435763836\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06260208785533905\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08837717771530151\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014075096696615219\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02018108405172825\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.05075520649552345\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04485096037387848\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12446192651987076\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05183693394064903\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03357274830341339\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.00556870037689805\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07292269915342331\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.05051540210843086\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07290900498628616\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04432128369808197\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06152535229921341\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08660610765218735\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023895034566521645\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06269454956054688\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08856004476547241\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014067263342440128\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.02016613632440567\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.05117904767394066\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04484840855002403\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12440621107816696\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05185777321457863\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03361416980624199\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005563451908528805\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07358445227146149\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.0496719554066658\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07164902985095978\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04404059797525406\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.061461105942726135\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08643586933612823\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02388051524758339\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06267474591732025\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.0884680226445198\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014025066047906876\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020176567137241364\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.050664301961660385\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04488691687583923\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12436040490865707\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05184059962630272\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03359594568610191\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0055790008045732975\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07440607994794846\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.056876979768276215\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07156036049127579\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04388582706451416\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.0615040585398674\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08687455952167511\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.02382858283817768\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06269252300262451\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08851640671491623\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014020225033164024\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020169241353869438\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.05084961652755737\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.044917088001966476\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12436266988515854\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05185210704803467\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03359651193022728\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005591865163296461\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07447246462106705\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.053174253553152084\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06967630237340927\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.043499406427145004\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061392106115818024\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08656488358974457\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023854371160268784\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.0639587864279747\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08948815613985062\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014031744562089443\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.02111457847058773\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.049270980060100555\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04619944840669632\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12435688078403473\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05159278213977814\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03339259698987007\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005641215480864048\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07238651812076569\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.042011190205812454\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.0701700896024704\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04295143112540245\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06144414097070694\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08635369688272476\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.02408764697611332\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06229909881949425\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08805261552333832\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014090823009610176\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020650627091526985\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04786118119955063\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.045011043548583984\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12468484789133072\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051632799208164215\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03340606763958931\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.0055381543934345245\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07480199635028839\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04269356653094292\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.07267458736896515\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042999811470508575\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.061328038573265076\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08637689799070358\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023991864174604416\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06243449077010155\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08811737596988678\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014040923677384853\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020418263971805573\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04901536554098129\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04495086893439293\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12438458949327469\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.051742855459451675\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.033422354608774185\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005608689971268177\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.0737653523683548\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04419347271323204\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.07161382585763931\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04324527457356453\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061320822685956955\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08635600656270981\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023925259709358215\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06234743446111679\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08817208558320999\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014037317596375942\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020345933735370636\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04929116740822792\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04492834582924843\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12435901165008545\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05179597809910774\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033414844423532486\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.0056075784377753735\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07354485243558884\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04555439203977585\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07181873917579651\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04331909120082855\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06138310581445694\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08635622262954712\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023924577981233597\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06223444268107414\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08819002658128738\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.01402601320296526\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02033085748553276\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.049334779381752014\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.044935666024684906\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12435959279537201\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.0518130399286747\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.0334564708173275\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005616741720587015\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07363041490316391\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.04437222704291344\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.07150617986917496\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.043304916471242905\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06137314811348915\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08634836971759796\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023921113461256027\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06226527318358421\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08818535506725311\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014026877470314503\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.0205963384360075\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04941067472100258\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04506750404834747\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12440783530473709\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.051797013729810715\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03340583294630051\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005581785924732685\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07375458627939224\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04680449515581131\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.07134174555540085\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04345529526472092\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06138743460178375\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.0863613411784172\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023865239694714546\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06246938183903694\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.0882888212800026\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014025016687810421\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02019231952726841\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.050042733550071716\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.0449027344584465\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12435375154018402\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05187128856778145\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03344164788722992\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.00562811316922307\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0735081285238266\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.0500427782535553\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06931953132152557\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04331618547439575\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061382751911878586\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08653191477060318\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023831915110349655\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06259435415267944\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.0884540006518364\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014059798792004585\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02019200101494789\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.05021652951836586\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.044924743473529816\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12435386329889297\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05192973464727402\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033472903072834015\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005635200068354607\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07382462173700333\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.05207930505275726\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06820526719093323\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04284841939806938\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061366721987724304\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08687432110309601\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023835323750972748\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06255708634853363\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08823613822460175\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014065678231418133\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020165733993053436\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04933304339647293\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044930968433618546\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12442682683467865\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05195831134915352\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03344609588384628\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.0055730948224663734\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07501345127820969\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.051052529364824295\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.0683075487613678\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04288334771990776\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06139611080288887\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.086754210293293\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02388964407145977\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06293891370296478\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08829546719789505\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014071397483348846\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020311662927269936\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.049283716827631\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.045080069452524185\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1243680939078331\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05189584940671921\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03341248258948326\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005594176240265369\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07354384660720825\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.05312780663371086\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06761038303375244\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04276091605424881\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06129679083824158\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08756187558174133\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023844555020332336\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06273694336414337\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08812128752470016\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014020180329680443\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020199155434966087\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.04884697496891022\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044912345707416534\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12435276061296463\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05206512287259102\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033413249999284744\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005578982178121805\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07437975704669952\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.04764920100569725\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06784362345933914\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.042699750512838364\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06133006140589714\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.0865502655506134\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023912562057375908\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06241403892636299\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08807441592216492\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014108088798820972\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020166441798210144\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04915536195039749\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04493321105837822\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12441591918468475\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.052150655537843704\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03340354934334755\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005554963368922472\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.0738600417971611\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.05046475678682327\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06760866194963455\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.042707618325948715\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061285071074962616\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08689461648464203\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023853791877627373\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.062188513576984406\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08803673088550568\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014211072586476803\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020281653851270676\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04820850118994713\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04504181817173958\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.124989353120327\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05252883583307266\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03357687592506409\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005547079257667065\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07533172518014908\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.05349625647068024\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06977840512990952\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04343511909246445\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.0615420900285244\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08872256428003311\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.023954123258590698\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06222386285662651\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08799997717142105\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014177204109728336\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020872751250863075\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04784763976931572\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04497689753770828\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1252344697713852\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05282047018408775\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03369149565696716\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.0055627962574362755\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.0765814408659935\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.05488487333059311\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.07039554417133331\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04454641044139862\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.0612933523952961\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.09334412217140198\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02404286153614521\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06296584755182266\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08858049660921097\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.01406001579016447\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.021339649334549904\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04759082943201065\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04491806402802467\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12462949752807617\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.052075572311878204\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03380277380347252\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005532262846827507\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07551058381795883\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04994494467973709\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.08685749024152756\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04337820038199425\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061297204345464706\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08978530764579773\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.026818187907338142\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06211356818675995\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08798812329769135\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.016271287575364113\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02145078033208847\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04682967811822891\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.045150935649871826\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12651985883712769\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05221180245280266\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.033380210399627686\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.006826719734817743\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07272066920995712\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04146413877606392\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06813086569309235\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.042922355234622955\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06147366389632225\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08646295964717865\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02426096424460411\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.062183678150177\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08823015540838242\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014924248680472374\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02040572464466095\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04771816357970238\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04506950080394745\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12650339305400848\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.052610766142606735\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03385450690984726\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.0066512152552604675\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07197968661785126\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04401515796780586\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06758231669664383\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04271366819739342\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06136617809534073\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08641310036182404\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02426256239414215\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06279291212558746\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08815684169530869\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.015095560811460018\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.02017565257847309\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04768018051981926\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.044893164187669754\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1271301954984665\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.0531412698328495\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03394985944032669\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.006452195346355438\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07210321724414825\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.046246785670518875\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06798096746206284\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04290664196014404\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06128475069999695\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08638499677181244\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.024186905473470688\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.062486693263053894\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08809362351894379\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.015006756410002708\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020175563171505928\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04776840656995773\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04493142291903496\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12661108374595642\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05336964130401611\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03374467045068741\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005856083706021309\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07178029417991638\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.046452246606349945\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.0683918371796608\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.043003667145967484\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.06128186360001564\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08646199852228165\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.024020643904805183\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06222466006875038\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.0880286768078804\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014780370518565178\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020171407610177994\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04789382219314575\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04498675465583801\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12628211081027985\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.053578123450279236\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033688656985759735\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005627972073853016\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07176369428634644\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04624273627996445\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06849007308483124\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04293687641620636\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06129971146583557\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08655736595392227\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02390628680586815\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.062080904841423035\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08799973875284195\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014623324386775494\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020184963941574097\n",
      "Search Iteration [17/20], Validation Loss: 0.06344954912466082\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.06839583814144135\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.10078244656324387\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.1254790723323822\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05434314161539078\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.049038272351026535\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.005651823710650206\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.07463916391134262\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.05553858354687691\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08535133302211761\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04311271384358406\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.0640634298324585\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.13644330203533173\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023909687995910645\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.0700111910700798\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09316379576921463\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.032397665083408356\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.02764640748500824\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05654563382267952\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.045415375381708145\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12495135515928268\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.052361514419317245\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03697967156767845\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005924885161221027\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07178135961294174\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04107882082462311\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07850904762744904\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.047857098281383514\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06485477089881897\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.09106685221195221\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02586420439183712\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06398864835500717\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08798916637897491\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.017123015597462654\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.027419954538345337\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.05318305268883705\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04514008015394211\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12507331371307373\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05121466889977455\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033509451895952225\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.00547513784840703\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07303468883037567\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.042009614408016205\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06770235300064087\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.04528042674064636\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06290081888437271\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.08930730074644089\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024604888632893562\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06323058903217316\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08834242075681686\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.01653819903731346\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02277149073779583\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04673861339688301\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04617183282971382\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.1260659545660019\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05114518105983734\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03334937244653702\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005426500458270311\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07476141303777695\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04158933088183403\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.0686599537730217\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04359162226319313\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.062051963061094284\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08829183876514435\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.024571603164076805\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06177891418337822\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08804680407047272\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.01424785703420639\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020756341516971588\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.0474933423101902\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04526253044605255\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12435539066791534\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.05130412429571152\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.03347563371062279\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005536634474992752\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07199125736951828\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.041010428220033646\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06911048293113708\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.043239254504442215\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061281923204660416\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08714281022548676\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024139653891324997\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06266967207193375\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08801377564668655\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.01411049161106348\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02057502605021\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04666805639863014\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.0458858348429203\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12460704147815704\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05241019278764725\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033359866589307785\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0054476261138916016\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.0733676552772522\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.041068222373723984\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07232313603162766\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.042809516191482544\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.0612766370177269\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08636611700057983\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023883938789367676\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06230912730097771\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08798768371343613\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014221963472664356\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02087712474167347\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04722471535205841\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.045471109449863434\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.1279856115579605\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05234872177243233\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03373328223824501\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005504015367478132\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07175303250551224\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.042588282376527786\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07343260943889618\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.042829275131225586\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.06152593344449997\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08693964779376984\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02396801859140396\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06223877891898155\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08817952126264572\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014297871850430965\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.021633274853229523\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.046638473868370056\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.044984202831983566\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12489204108715057\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05114087089896202\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03332357481122017\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005432891193777323\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07263397425413132\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04142254590988159\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.07634211331605911\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04282930865883827\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.0613308809697628\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08653191477060318\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023900100961327553\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06278479099273682\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08819055557250977\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014057963155210018\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020944809541106224\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.046885788440704346\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04486383870244026\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12465815991163254\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05121663957834244\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03333529829978943\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.0055053820833563805\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07202634960412979\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04167763143777847\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.07467950135469437\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.042847033590078354\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06129062548279762\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.0863981693983078\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.02388659305870533\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.0628068819642067\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08824887871742249\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014021271839737892\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.02081334963440895\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.047018084675073624\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04486118257045746\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12449853122234344\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05147571116685867\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03336522728204727\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005598268937319517\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07175340503454208\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.041821956634521484\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.07287904620170593\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04280412197113037\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06127668544650078\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.0863473117351532\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023870043456554413\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06265541166067123\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08829115331172943\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.014021022245287895\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020750895142555237\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04691547900438309\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04488131403923035\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12449976801872253\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05158096179366112\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03334597870707512\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005541452206671238\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07175815850496292\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04155195504426956\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.07065610587596893\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.042737171053886414\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061277151107788086\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08639262616634369\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.0238684993237257\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06252121180295944\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08821335434913635\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014019250869750977\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020744893699884415\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.046775128692388535\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.044979918748140335\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12457691878080368\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.051591403782367706\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03333178162574768\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005519408732652664\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07179111987352371\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04156303405761719\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06987456977367401\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.04272282496094704\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06127793341875076\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08641065657138824\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.023865513503551483\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06246717646718025\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08815155178308487\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014020116999745369\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020793728530406952\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04668501019477844\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045132409781217575\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12465592473745346\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05155866593122482\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03332437202334404\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005516443867236376\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07184764742851257\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04173186048865318\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06967238336801529\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.042734887450933456\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06127794831991196\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08638202399015427\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02385210059583187\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.062427420169115067\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08810371905565262\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014029093086719513\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02087218500673771\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046622853726148605\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.045284707099199295\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12477174401283264\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05137298256158829\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03332171216607094\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005490936804562807\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07205693423748016\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04199418053030968\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06939154118299484\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042769551277160645\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061276670545339584\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08635183423757553\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023837430402636528\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06238919869065285\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08805077522993088\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014058871194720268\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020964644849300385\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.046590059995651245\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.045443035662174225\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12495245039463043\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.051168303936719894\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033346988260746\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.005426054820418358\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07254734635353088\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04241643100976944\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06863479316234589\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04283105209469795\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.061286214739084244\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08635126054286957\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023858260363340378\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.062249913811683655\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.088007353246212\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.01412238273769617\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020968832075595856\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.046589359641075134\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04561877250671387\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12486165761947632\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05115608870983124\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03337373584508896\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005428217351436615\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07241804152727127\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04546254873275757\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07142654806375504\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.043292250484228134\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.061469387263059616\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08671558648347855\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023860881105065346\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.062414661049842834\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08808252960443497\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014151046983897686\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.021218907088041306\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.0465872623026371\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04525899142026901\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.125126451253891\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05152392014861107\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.033322036266326904\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005411074962466955\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07191283255815506\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.05000738427042961\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.07393419742584229\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04454795643687248\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061624374240636826\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08652521669864655\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.024162326008081436\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.0625435933470726\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.0885394737124443\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014027356170117855\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02090640738606453\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04723598062992096\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.0448732003569603\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12435547262430191\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05127869173884392\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.0335029736161232\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005742640700191259\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07241971045732498\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04739094898104668\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07172289490699768\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04385092481970787\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06145457550883293\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08661402016878128\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.023880427703261375\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06222621351480484\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08943405747413635\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014088156633079052\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020410120487213135\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04834802448749542\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04536603391170502\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12509505450725555\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.0512947253882885\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03332836180925369\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005422534886747599\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07182152569293976\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.043557148426771164\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06976836174726486\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.043501097708940506\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061399444937705994\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08643803745508194\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.024021202698349953\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06213774159550667\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08848776668310165\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014039317145943642\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.020521432161331177\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.047719407826662064\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04485354945063591\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12442344427108765\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05170256644487381\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033387597650289536\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005412086378782988\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07264606654644012\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04263285920023918\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.06985342502593994\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.043622758239507675\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.06131139397621155\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.0863916277885437\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.02389686554670334\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06236520782113075\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08835355192422867\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014018842950463295\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020498597994446754\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.04714785888791084\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.044851068407297134\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12436127662658691\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05138217657804489\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033423446118831635\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005414477549493313\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07354185730218887\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04531412944197655\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0727715715765953\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04419310763478279\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06134198606014252\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08637669682502747\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.02385767363011837\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.06221897527575493\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08843012899160385\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014123749919235706\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020307490602135658\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04791421815752983\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.0448717400431633\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12445767223834991\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05170242860913277\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03336213901638985\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005411870777606964\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07277318090200424\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04503629356622696\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07184763252735138\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04447728395462036\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06131571903824806\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.0863485112786293\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02391866408288479\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06250372529029846\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08875452727079391\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014047317206859589\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020271139219403267\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.048029568046331406\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04495463892817497\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12457234412431717\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05151090398430824\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.033464886248111725\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005420616362243891\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07366243749856949\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.047084562480449677\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07161054760217667\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04473395273089409\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06151896342635155\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.0864294245839119\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023937653750181198\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.062357425689697266\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08871183544397354\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014024428091943264\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.02029401995241642\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04790385812520981\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.044928357005119324\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12452460080385208\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05145859345793724\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03353063017129898\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005435008089989424\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.0743139237165451\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.04682303965091705\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06984570622444153\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.0452151820063591\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061338286846876144\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08637482672929764\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023865627124905586\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06230658292770386\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08853518217802048\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.01402211096137762\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020245302468538284\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.047835443168878555\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.044965051114559174\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12438341230154037\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05144466832280159\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03366604074835777\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.0054662199690938\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07542595267295837\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.052298303693532944\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06871648877859116\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04449798911809921\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06147502735257149\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08664234727621078\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023828264325857162\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06229564547538757\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08873562514781952\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014061596244573593\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.02021770551800728\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04803425073623657\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04497654363512993\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.1243956983089447\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05136006325483322\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033663950860500336\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.00546176265925169\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07540635764598846\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.0561356358230114\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06764818727970123\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04271777719259262\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061288513243198395\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.087600477039814\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023963715881109238\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06252193450927734\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.0883464440703392\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014174142852425575\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020239979028701782\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.0474797748029232\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.044864196330308914\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12474682182073593\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.051340676844120026\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03374404460191727\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005478421691805124\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07718414068222046\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.05039765313267708\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06790122389793396\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04271049052476883\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06127886101603508\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08766002207994461\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023958265781402588\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.06248674914240837\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08820031583309174\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014127708971500397\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020169373601675034\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04791082441806793\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04485543817281723\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12509550154209137\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05150573328137398\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03385011851787567\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005530534777790308\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07619044184684753\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.05172652751207352\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06783043593168259\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04316335916519165\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06130245327949524\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08957059681415558\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.024208730086684227\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.062390461564064026\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08851394057273865\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014097006991505623\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.0201664250344038\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04774681478738785\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04484844207763672\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1256668120622635\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.051918864250183105\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03394874557852745\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.0056897238828241825\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07527262717485428\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04617771506309509\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06836538761854172\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04284033551812172\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06128458306193352\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08755472302436829\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.0241025872528553\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06252611428499222\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08834097534418106\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014125794172286987\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020239243283867836\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04807515814900398\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04489878565073013\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12727892398834229\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05283679813146591\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03448571264743805\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.00636358791962266\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07429993897676468\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04534623399376869\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06858943402767181\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04269932955503464\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061461806297302246\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.0871950164437294\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.02414875291287899\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06244097277522087\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.088176429271698\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014337722212076187\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020171644166111946\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.048188257962465286\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04485159367322922\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12602411210536957\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05326548218727112\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03450208157300949\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.00586451031267643\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.0732165202498436\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04827997833490372\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06827906519174576\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04270666837692261\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06135522946715355\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08856534212827682\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.024041693657636642\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.06284672766923904\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08828635513782501\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014099180698394775\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.02121751941740513\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.048730429261922836\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04487317055463791\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.1270751953125\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.053924765437841415\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03432569280266762\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005546992179006338\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07181543111801147\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04602326452732086\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06780163198709488\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.042696159332990646\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.061390917748212814\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08916723728179932\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02397359535098076\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.062092944979667664\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08808264881372452\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014112786389887333\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020652079954743385\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.048705704510211945\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04489044472575188\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12598201632499695\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.053815629333257675\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03411583974957466\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005411897785961628\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07195330411195755\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.041619155555963516\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06778217107057571\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.043047018349170685\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06166256591677666\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08653130382299423\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.024036169052124023\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06251396983861923\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.088067926466465\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014144150540232658\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020939286798238754\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04945483058691025\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04493766650557518\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12588125467300415\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05402279272675514\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03391919657588005\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005413019564002752\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07226956635713577\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.0414007306098938\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06771790236234665\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04311985522508621\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06163763999938965\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.0864163413643837\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.024069298058748245\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06229101121425629\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08805935829877853\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014154156669974327\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02092863991856575\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.049314457923173904\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04496873915195465\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12572172284126282\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05393711477518082\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03376031666994095\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.00541883148252964\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07258448749780655\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.041042208671569824\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06767810136079788\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04319680854678154\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06161666661500931\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08635644614696503\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02411685511469841\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.062257084995508194\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08807393163442612\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.01421542838215828\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020895976573228836\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04918592795729637\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04498251900076866\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.1256798803806305\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05383516848087311\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033612802624702454\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005432543810456991\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07287827879190445\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.04101206362247467\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06764274835586548\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.043230317533016205\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06158106401562691\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.0864136815071106\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.024134283885359764\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.062161725014448166\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08806972205638885\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.01424636784940958\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02088605985045433\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.049029625952243805\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044988375157117844\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12559933960437775\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.05368724465370178\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033512264490127563\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.005448114592581987\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07311845570802689\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.041027892380952835\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06762847304344177\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.043206848204135895\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.0615369938313961\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08645863085985184\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.024139324203133583\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.062021784484386444\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.0880608856678009\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014254258014261723\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020863814279437065\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.04890014976263046\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04499020427465439\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12553861737251282\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05359400436282158\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03346523642539978\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005456141661852598\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07324358075857162\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04105058312416077\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06763094663619995\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.043180935084819794\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061493970453739166\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08653532713651657\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.024148492142558098\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06194836273789406\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.0880788043141365\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014265007339417934\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020911771804094315\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.04883795976638794\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04499500244855881\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12548121809959412\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.053574685007333755\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03342406824231148\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005469449795782566\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07337559759616852\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04103365167975426\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06765440851449966\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.043093353509902954\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06145172566175461\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08654585480690002\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.024145716801285744\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06182997673749924\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08808675408363342\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014257549308240414\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02094130590558052\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.04872354120016098\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04499096795916557\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.1254536509513855\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.053584907203912735\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03341829776763916\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005465999711304903\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07332931458950043\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.041015129536390305\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.06770335137844086\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.043027929961681366\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06141342222690582\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08660414069890976\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.02414093166589737\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.061793528497219086\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08812002837657928\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014271807856857777\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02090122364461422\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.048525746911764145\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044967781752347946\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12546329200267792\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.053602103143930435\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03339949622750282\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.0054655252024531364\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07336767762899399\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.041014865040779114\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06775695085525513\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.0429266020655632\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06137749180197716\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.086563341319561\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.02411593683063984\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06172281876206398\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08810464292764664\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014235151000320911\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020818501710891724\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04852328822016716\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04497162997722626\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12525685131549835\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.053516075015068054\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03340621292591095\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005467340350151062\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07336702942848206\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.041019149124622345\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06782931834459305\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04289031773805618\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061360131949186325\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08660068362951279\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.024095237255096436\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061698898673057556\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08812513947486877\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014231985434889793\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020731626078486443\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.0484166145324707\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04495713487267494\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12522192299365997\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.053468067198991776\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03340672701597214\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005451572593301535\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07322192192077637\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04108395799994469\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06796235591173172\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.042809002101421356\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.061322569847106934\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.0865912139415741\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.024077951908111572\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.061673834919929504\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08812637627124786\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014219408854842186\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020819032564759254\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04849482327699661\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04496242478489876\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1252271980047226\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05337400361895561\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033419787883758545\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005469189956784248\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07337874919176102\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04105569049715996\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06801892071962357\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04279794543981552\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06132448464632034\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08661980926990509\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02404659427702427\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06165885180234909\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08816775679588318\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.01421683095395565\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020871499553322792\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.048333264887332916\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04495779424905777\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12521924078464508\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05334657430648804\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.033416543155908585\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005446369294077158\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.0731125921010971\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.04117199033498764\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06816693395376205\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042747803032398224\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06129694730043411\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08658995479345322\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.024039553478360176\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06165254861116409\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.088149793446064\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014194360002875328\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.02086763083934784\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04849277064204216\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.04496512934565544\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12512971460819244\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.053184691816568375\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03343191742897034\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005473542958498001\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07342567294836044\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.041113290935754776\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06829085201025009\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04277028515934944\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06134472042322159\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08660166710615158\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.024009428918361664\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061657097190618515\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08818792551755905\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014197517186403275\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.020906556397676468\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04832874611020088\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044982220977544785\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12525512278079987\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05314722657203674\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03342713043093681\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005458686966449022\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07310820370912552\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.041196249425411224\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06815236061811447\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.042716801166534424\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06128672882914543\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08649765700101852\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02394147403538227\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061659179627895355\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08824101835489273\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.01412412989884615\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.02091302163898945\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04850746691226959\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.045022763311862946\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1250409483909607\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05284205824136734\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03340631723403931\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005427734460681677\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07270191609859467\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.041566863656044006\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.0684783011674881\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04272030293941498\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06128454580903053\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08651886880397797\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023962557315826416\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06166388466954231\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08817771077156067\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.01417526789009571\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.021108312532305717\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.048396043479442596\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04503253847360611\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12516579031944275\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.052753519266843796\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03341737762093544\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005444184876978397\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07278335094451904\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04158629849553108\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06863348186016083\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04273562878370285\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061370763927698135\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08646892011165619\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02399788610637188\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06165172904729843\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08819025009870529\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014156987890601158\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020740961655974388\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.047981612384319305\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.045034684240818024\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12510092556476593\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.052706800401210785\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.033379361033439636\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005483523942530155\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0734347328543663\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.041050318628549576\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06933895498514175\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04269743710756302\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06141268089413643\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08644802123308182\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023926980793476105\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06168114393949509\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.0882595032453537\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014257773756980896\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.02051306702196598\n",
      "Search Iteration [18/20], Validation Loss: 0.06244344099170782\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.10061002522706985\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.11632905900478363\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.12457896023988724\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.061491627246141434\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.052082087844610214\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.005464156623929739\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.072064608335495\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.05009867623448372\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.07764074951410294\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.04555997997522354\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06430307775735855\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.13739407062530518\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.023697543889284134\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.06666138023138046\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.09562015533447266\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.046882085502147675\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.027835389599204063\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.05794943496584892\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.04807383567094803\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.12437454611063004\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.05164431035518646\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03899846225976944\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.005469080526381731\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07223807275295258\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.045511599630117416\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.07198796421289444\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.05584148317575455\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06669829785823822\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.10188958048820496\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.025097543373703957\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06942132860422134\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08799959719181061\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01866305060684681\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.038789357990026474\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.05110109597444534\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.048207126557826996\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12456399202346802\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05138026922941208\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.0333746112883091\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005419793073087931\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07206300646066666\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.0501948781311512\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06816447526216507\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05399302765727043\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06595565378665924\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.0949709415435791\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.024907533079385757\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06314411014318466\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08798930048942566\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.014421557076275349\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.026400679722428322\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04890201985836029\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.048534560948610306\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12497326731681824\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05160084366798401\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03469888120889664\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.005648191086947918\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.0719204768538475\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.042327430099248886\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.08968085050582886\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.04274437949061394\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.061851754784584045\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.0929509624838829\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.025628454983234406\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06342851370573044\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08806470781564713\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014891077764332294\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.022469382733106613\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04658631607890129\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04681846499443054\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12437532097101212\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051715780049562454\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.033396001905202866\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.00567790400236845\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07176952809095383\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.041207075119018555\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.07207465171813965\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.0432274267077446\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.061627812683582306\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08648014068603516\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.024009397253394127\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06166347861289978\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08821764588356018\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014713557437062263\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02118189074099064\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04738229140639305\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.045116059482097626\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12609605491161346\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.051200058311223984\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.034347791224718094\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.0073668877594172955\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07543214410543442\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.042770881205797195\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.06760189682245255\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04497479647397995\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06145000830292702\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.09128529578447342\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.024323392659425735\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06338834017515182\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08802103996276855\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.015649816021323204\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.021964116021990776\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04659748822450638\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.049604810774326324\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12475208938121796\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05238104239106178\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03356413170695305\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.0057283262722194195\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07435326278209686\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.042391613125801086\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.06879185885190964\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.0465657114982605\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061482325196266174\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.09434366971254349\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.024937011301517487\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06204747408628464\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.0881662666797638\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.01433610450476408\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.02074681781232357\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.047382187098264694\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04488633945584297\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12435272336006165\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05114582180976868\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03409869968891144\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005657329224050045\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07371056079864502\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04136500880122185\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06993917375802994\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.044764187186956406\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.06146099418401718\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08831622451543808\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02403443679213524\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06166215240955353\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08800400793552399\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014869144186377525\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020447270944714546\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04677555710077286\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04580480977892876\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12465814501047134\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05126367136836052\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033647701144218445\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.0056156860664486885\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07371697574853897\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04121094569563866\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.06764373183250427\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04467501491308212\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06128890439867973\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.09076946973800659\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.024615872651338577\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.0617351233959198\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08801259845495224\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.01476922444999218\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020540721714496613\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04718301072716713\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04643503576517105\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12465277314186096\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05132390931248665\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03336882218718529\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005414067767560482\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07199349999427795\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.041491858661174774\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06759714335203171\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04482407867908478\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06127755716443062\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.09046229720115662\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.024514613673090935\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.061744727194309235\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08806470781564713\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.015207846648991108\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020507745444774628\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.0468418262898922\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04666409268975258\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12439962476491928\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05160343274474144\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03332138806581497\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.0054127369076013565\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07231445610523224\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04190776124596596\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06759097427129745\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.04470830410718918\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06127695366740227\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.0892256647348404\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.02427702024579048\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.06174611300230026\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08818312734365463\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.016099119558930397\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020601047202944756\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.046590544283390045\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04671798646450043\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.12443755567073822\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05164044350385666\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03333575278520584\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.005464853253215551\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.0739295557141304\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.041675616055727005\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.06763207167387009\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.044910773634910583\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06129227951169014\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.0891038328409195\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.024151289835572243\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.061831556260585785\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08820494264364243\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.0160607248544693\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020703664049506187\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046607498079538345\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.046418555080890656\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.12451544404029846\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05155124515295029\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03332176432013512\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005572715308517218\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07363705337047577\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04127604514360428\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06831114739179611\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04388968273997307\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06131117790937424\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08741524070501328\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02388671226799488\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.0618787482380867\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08835571259260178\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.015890533104538918\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.02085948921740055\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04703151807188988\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.045904383063316345\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12525197863578796\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.051208868622779846\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03337876871228218\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.006103646941483021\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07259376347064972\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.04109815135598183\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.07348141074180603\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042724721133708954\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06147763133049011\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08682268112897873\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.023698804900050163\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06178620085120201\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08828787505626678\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014793635345995426\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.021316489204764366\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.048186469823122025\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.0448697954416275\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12582945823669434\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05132828652858734\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.033911507576704025\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.007384089287370443\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07179722189903259\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04195861518383026\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.07547469437122345\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04300515726208687\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.061388611793518066\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08658235520124435\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023693334311246872\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06173710525035858\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08798030018806458\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014025263488292694\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02060462348163128\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.0468117892742157\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.0448378324508667\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12478742003440857\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.051218610256910324\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033532388508319855\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005809049587696791\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07175557315349579\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04133482649922371\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.07336551696062088\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.042944010347127914\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06129329279065132\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08634842187166214\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02380450628697872\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06192871555685997\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08798016607761383\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014018939808011055\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02045772597193718\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04719877243041992\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.04485993832349777\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12455656379461288\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.0513295903801918\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03351021558046341\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005757915787398815\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07178980112075806\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04136546701192856\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.07253239303827286\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04288887232542038\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.061280712485313416\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08635490387678146\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023814557120203972\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.061913564801216125\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.0879867896437645\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014020309783518314\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020505724474787712\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04723137617111206\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04486081004142761\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12452319264411926\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05139380320906639\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.0335155613720417\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005747070070356131\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07180628925561905\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.041429389268159866\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.07266898453235626\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04290316253900528\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06127678602933884\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08636307716369629\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02383415959775448\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06191396713256836\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08799565583467484\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.01402235496789217\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020537234842777252\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.047229304909706116\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04486226662993431\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12450719624757767\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05142941698431969\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03351280838251114\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005730949807912111\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.0718245729804039\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.041485559195280075\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07274298369884491\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04291364550590515\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06127740442752838\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08636730909347534\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023846691474318504\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.06192498281598091\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.0880061462521553\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014023637399077415\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02054748497903347\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.047247905284166336\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04486413300037384\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12448596209287643\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05147164314985275\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03350783511996269\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.005713418126106262\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07185077667236328\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04153064638376236\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07275673002004623\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04291902855038643\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061280298978090286\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08636588603258133\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023855125531554222\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.06193484365940094\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08801772445440292\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014023886993527412\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020548725500702858\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.047262370586395264\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.044862695038318634\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12446948140859604\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05151721090078354\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.0334966778755188\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.00569456210359931\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07187913358211517\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04156997799873352\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.07267826795578003\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04292183741927147\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.061284199357032776\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08636347949504852\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.02385915443301201\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.061943743377923965\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08802936971187592\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014023886993527412\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.02054777555167675\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.04726690053939819\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04485982656478882\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12445744127035141\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051560353487730026\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.033482421189546585\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005674955900758505\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07190077006816864\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04160330444574356\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.07257353514432907\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042923491448163986\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06128816679120064\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08636147528886795\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02386021614074707\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.06195203214883804\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08804009854793549\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014023905619978905\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.020546797662973404\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.047262903302907944\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04485677555203438\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12444858253002167\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05159754678606987\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03346719220280647\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005655266344547272\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07191242277622223\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04163682088255882\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.07246995717287064\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.042925313115119934\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06129162758588791\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08636026084423065\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023858919739723206\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06196020543575287\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.0880495086312294\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014023958705365658\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020546207204461098\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.04725562781095505\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04485422000288963\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12444055825471878\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.051628243178129196\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.033452440053224564\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005635509733110666\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07191476225852966\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.041683536022901535\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.0723826214671135\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042928267270326614\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.061294134706258774\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08635951578617096\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023856069892644882\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06196683272719383\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.08805742859840393\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014023986645042896\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020550481975078583\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.047247301787137985\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04485176131129265\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12443190068006516\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.0516536608338356\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.033438585698604584\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005615685600787401\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07191061228513718\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04177992790937424\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.07233940809965134\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.042932260781526566\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06129550561308861\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08636030554771423\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.02385096251964569\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.061973731964826584\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08806253224611282\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014024211093783379\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020568883046507835\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04723251610994339\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04484882950782776\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12442244589328766\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.051670100539922714\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03342583775520325\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005596288479864597\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07189996540546417\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04199592396616936\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07235122472047806\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.04294414073228836\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06129680946469307\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08636250346899033\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.023843353614211082\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06198437884449959\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08806536346673965\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014024420641362667\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020592227578163147\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.047208402305841446\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04484649747610092\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12441159039735794\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.05167509987950325\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.03341414034366608\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005578160285949707\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.071884885430336\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04257170110940933\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07244816422462463\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04297984763979912\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.06129246577620506\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.0863640084862709\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.02383086085319519\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061979085206985474\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.0880698710680008\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014023845084011555\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020794887095689774\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.047182366251945496\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04483787342905998\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12440229952335358\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.051684021949768066\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03340470790863037\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.00557974586263299\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07187577337026596\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.044269487261772156\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07285626977682114\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04328633099794388\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06138195842504501\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08634938299655914\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023782409727573395\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.06190790235996246\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08811106532812119\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.014018808491528034\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020515017211437225\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.047280970960855484\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04483885318040848\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1243712455034256\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.051877252757549286\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.033386968076229095\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005533643998205662\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07191085070371628\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04623765870928764\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.07340900599956512\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04351944848895073\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06132941693067551\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08635865151882172\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.02386678382754326\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06198166683316231\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08819157630205154\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014027313329279423\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020474277436733246\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047481197863817215\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04486224055290222\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12435439974069595\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.051909688860177994\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03334503993391991\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005443181376904249\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07194925099611282\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.049663275480270386\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.0724310427904129\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04394184425473213\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06135696917772293\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08665879815816879\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023844752460718155\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06266491860151291\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.0892607793211937\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.01402418501675129\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020356090739369392\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04894277825951576\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.045729804784059525\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12537908554077148\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051283203065395355\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03336350992321968\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005429042968899012\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07198097556829453\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04213366284966469\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06947501003742218\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.042797915637493134\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.061313651502132416\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08634723722934723\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023882417008280754\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.061685364693403244\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08815346658229828\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.01403734553605318\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020368780940771103\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.047080714255571365\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04484689235687256\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12440554797649384\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.051879845559597015\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033336758613586426\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005412144120782614\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07199376076459885\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04401315003633499\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.07221897691488266\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.04331858456134796\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.061364345252513885\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08635015040636063\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02386220544576645\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.061857834458351135\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08818556368350983\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014026056043803692\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.022408660501241684\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04718242213129997\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044941313564777374\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1243927925825119\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05195945128798485\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03332800045609474\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005426426883786917\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07199379801750183\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04459042847156525\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.0723624974489212\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04357195645570755\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.061465971171855927\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.0863599181175232\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023864656686782837\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06202731654047966\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08820395916700363\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014020320028066635\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020280204713344574\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04736923798918724\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.044923122972249985\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12435675412416458\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.051897477358579636\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.0333399623632431\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005411074962466955\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07204724103212357\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04789868742227554\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07169564068317413\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.043936338275671005\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.0615149661898613\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08649969846010208\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023869896307587624\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.062439240515232086\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.0888763815164566\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014019197784364223\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02024821564555168\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04851705953478813\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04532690718770027\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12488367408514023\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05157088488340378\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03332718834280968\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005457308609038591\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07179459184408188\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.047972213476896286\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06990150362253189\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04322042688727379\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06156357005238533\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08662337809801102\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023870741948485374\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06176630035042763\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08834894001483917\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014023583382368088\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02022802084684372\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.047537464648485184\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044896986335515976\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12435376644134521\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.052083928138017654\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.033450838178396225\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005466817412525415\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07276720553636551\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.045010749250650406\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.07080969214439392\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.04340708255767822\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061472874134778976\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08638472110033035\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023871950805187225\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.061816103756427765\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08821021765470505\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014044605195522308\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020288266241550446\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04722801223397255\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044888462871313095\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12437298148870468\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.0518469363451004\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03342540189623833\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.0054277474991977215\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07317011058330536\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.0497988723218441\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.07228396832942963\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.04386894777417183\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061586715281009674\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08713528513908386\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023966632783412933\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06195174157619476\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08827797323465347\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.01401921920478344\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.020194269716739655\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.047527015209198\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.045096829533576965\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12436717003583908\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05169452354311943\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03345036506652832\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005451052449643612\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07307776808738708\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.05002715066075325\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.0692954733967781\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04304970055818558\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.06153547018766403\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08671682327985764\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02381843328475952\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.06179208308458328\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08833739906549454\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014088514260947704\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.02024700865149498\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.047566380351781845\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.044874660670757294\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.1243748664855957\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.052005112171173096\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03349995240569115\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005458670202642679\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07403896749019623\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04846205562353134\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06867087632417679\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.042883362621068954\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06146601215004921\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08662549406290054\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.02378528006374836\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06178264692425728\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08826908469200134\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014147493988275528\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.02019660919904709\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.047333087772130966\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04488407075405121\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12444483488798141\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.0519065223634243\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03351787105202675\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005430491175502539\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.0745001807808876\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.05287458747625351\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.0676979348063469\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.04272664710879326\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06130609288811684\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08694596588611603\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023804284632205963\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06178786978125572\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08819781243801117\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014229601249098778\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.02018091455101967\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.047235701233148575\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.044896449893713\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.124712735414505\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05196896195411682\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03350095450878143\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.005418720189481974\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07477346062660217\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.05198471620678902\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06759164482355118\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04291659593582153\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06128666549921036\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08685257285833359\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023912500590085983\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06184367462992668\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08820030093193054\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014273797161877155\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020167270675301552\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04724258929491043\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.044903893023729324\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12484419345855713\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.052065808326005936\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.033554766327142715\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005427704658359289\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07441318780183792\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.05278465524315834\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06802687048912048\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.0436096228659153\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061376042664051056\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08724526315927505\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023990314453840256\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06198336184024811\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08828343451023102\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01420355774462223\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020180711522698402\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04752080515027046\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044855065643787384\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12501269578933716\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05215217545628548\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03361479938030243\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005458994302898645\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07378567010164261\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.05191586911678314\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06850516051054001\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04386936500668526\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.061354298144578934\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08774406462907791\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02398972027003765\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06201445311307907\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08829130232334137\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014200717210769653\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020215995609760284\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.047456495463848114\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04484245553612709\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12542513012886047\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05266851186752319\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03377586975693703\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.00552792614325881\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07333129644393921\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04933369904756546\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06827079504728317\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04347667098045349\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.06128522381186485\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08763916045427322\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.023884836584329605\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.062018077820539474\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08819378912448883\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014242229983210564\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.020321916788816452\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04762125015258789\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.044840291142463684\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12572422623634338\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.053139425814151764\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03393012657761574\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005599868018180132\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07273758947849274\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.050423163920640945\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06806308776140213\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04307575896382332\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.06129451096057892\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08941999822854996\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.023753324523568153\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.061910491436719894\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.08804736286401749\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.01412238273769617\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020500201731920242\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.04810263589024544\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044844850897789\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.1258712112903595\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05356933921575546\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.034050919115543365\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005575283896178007\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07203219830989838\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04690485820174217\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06772459298372269\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04274202883243561\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06144319102168083\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08874619752168655\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02370649389922619\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.061850521713495255\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08799110352993011\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014067566022276878\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02082733064889908\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.048906680196523666\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044877126812934875\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.125643789768219\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.053575776517391205\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03392409160733223\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005452917888760567\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.0717846229672432\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.044656384736299515\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06789105385541916\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.0427037812769413\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06163575500249863\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08802982419729233\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023715458810329437\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06174547225236893\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08797993510961533\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.01408793218433857\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.020687423646450043\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.048653293401002884\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04487983509898186\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12540003657341003\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.05342092737555504\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03375625982880592\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005412077531218529\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07213623821735382\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.042087871581315994\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.0675833597779274\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.042791642248630524\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.061919331550598145\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08681829273700714\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.0237425547093153\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06175921484827995\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08797986060380936\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014120779931545258\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020541425794363022\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04863486811518669\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04487328231334686\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12516528367996216\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05306980386376381\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.03358686342835426\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005416755098849535\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07247937470674515\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04122060537338257\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06758017838001251\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.0428122840821743\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061935633420944214\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08639589697122574\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.0237859096378088\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.061724159866571426\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.0879802405834198\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014306452125310898\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02024594135582447\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04752916842699051\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044859617948532104\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12535788118839264\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.053146861493587494\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03361036628484726\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.0054111783392727375\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.0724981352686882\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04118607938289642\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06763415038585663\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.0428730770945549\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.06182687357068062\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.0864378809928894\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023753874003887177\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06173582747578621\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08799729496240616\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014151034876704216\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020492255687713623\n",
      "Search Iteration [19/20], Validation Loss: 0.058294023023071614\n",
      "Epoch [0/50], Batch [0/168], Loss: 0.06516783684492111\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.09841778874397278\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.1266176849603653\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05455492064356804\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.04087071120738983\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.005412084516137838\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.07219304889440536\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.0598825104534626\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.08166980743408203\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.042942460626363754\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.06419260054826736\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.1292351633310318\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.024467121809720993\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.07749608904123306\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.08950565755367279\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.02589106559753418\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.03235206753015518\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.054957810789346695\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.04589792340993881\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1243659183382988\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.052088748663663864\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.03797542676329613\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.0071257613599300385\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.07582914084196091\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.04218868166208267\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.08518048375844955\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.045658327639102936\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.06755911558866501\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.09256185591220856\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.024477694183588028\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06695841997861862\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.08871839195489883\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.01402722392231226\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.027895046398043633\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.04742755740880966\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.04576532170176506\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12448599934577942\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.05159008502960205\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.033329904079437256\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.005482526496052742\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.07209458202123642\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.05058794841170311\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.06998077780008316\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.05150156468153\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06507960706949234\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.09515023976564407\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.02433069236576557\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.06294550746679306\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08934925496578217\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.01443931832909584\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.020631901919841766\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04966744780540466\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04551069438457489\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.12482868880033493\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05188831686973572\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03339959308505058\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.0054200273007154465\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07178356498479843\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.04348008334636688\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.06757998466491699\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.044675033539533615\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06193038448691368\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.0896504670381546\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.02435048669576645\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06188777834177017\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08814115077257156\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014045893214643002\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.020255975425243378\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.04834093526005745\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.04492194578051567\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.12442981451749802\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.052187345921993256\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.033439841121435165\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005411101970821619\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07189404964447021\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.04155595600605011\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06911461055278778\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04349338635802269\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.06128881871700287\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08892396837472916\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.02423451654613018\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06165287643671036\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08800850063562393\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014235792681574821\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02024899236857891\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.04739460349082947\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04488801211118698\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12456444650888443\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05275242403149605\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.033344756811857224\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005803017411381006\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07273945957422256\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.041456274688243866\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07337155938148499\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.042778849601745605\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.0612766295671463\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08704575896263123\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023793736472725868\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.061661120504140854\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.0880742222070694\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014028896577656269\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.02025306411087513\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04724327102303505\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.044886574149131775\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12464169412851334\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.05213834345340729\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03335880488157272\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005734578240662813\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07264355570077896\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.041267648339271545\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07204096764326096\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04285505786538124\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061282481998205185\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08726776391267776\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02379973605275154\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.06172516569495201\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08803487569093704\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014035523869097233\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.020364558324217796\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.046974580734968185\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04484765976667404\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12472963333129883\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.05343946814537048\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.03337407857179642\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005847289692610502\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07349252700805664\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04121284559369087\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06899984925985336\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04324090853333473\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061277374625205994\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08767300099134445\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.02380814403295517\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06177058815956116\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08810818195343018\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014049441553652287\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.0204786267131567\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.04693301394581795\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.04486074298620224\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.12476955354213715\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.051878854632377625\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.033428456634283066\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005723209120333195\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07262637466192245\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04110594093799591\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.07003001123666763\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.043066829442977905\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.06129881367087364\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08758749067783356\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.023790214210748672\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.0618487223982811\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08800709247589111\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014019974507391453\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020431995391845703\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04681689292192459\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04496688395738602\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12482833862304688\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05400025099515915\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.033381812274456024\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005636777728796005\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07332007586956024\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04103590175509453\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.06783834099769592\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04353136941790581\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06128091365098953\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08842182159423828\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.02396482229232788\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.06186678260564804\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08800011873245239\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01402764581143856\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.020456673577427864\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.04707395285367966\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.04541796073317528\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.12436789274215698\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.05397043004631996\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.033323366194963455\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005433301907032728\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.0723038911819458\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04106007143855095\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06846781075000763\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.044286590069532394\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.061281196773052216\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.09056482464075089\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.024539360776543617\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061687469482421875\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.0879795253276825\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014539162628352642\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020669713616371155\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04660702124238014\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.045806754380464554\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.1252656728029251\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.05170419067144394\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03332553431391716\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.0055114091373980045\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07176357507705688\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.0411299504339695\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.07151064276695251\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.042737822979688644\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.0613216869533062\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08692841976881027\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02375476062297821\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06204139441251755\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08798103034496307\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014030530117452145\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020340336486697197\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.04672316461801529\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.045009709894657135\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1249794289469719\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05189717933535576\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.03334343060851097\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005723654292523861\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07205355912446976\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.04178786277770996\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.07047857344150543\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04270310327410698\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06133623421192169\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08664101362228394\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.023716244846582413\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06196313723921776\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08797953277826309\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014040366746485233\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020433342084288597\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.046643488109111786\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.0452035553753376\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12510070204734802\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05180416256189346\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03336897864937782\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.0058374651707708836\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07235801219940186\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.042262665927410126\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.07011115550994873\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.04269595071673393\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.06133647263050079\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08657034486532211\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02369811199605465\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06192303076386452\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08797955513000488\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014027953147888184\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020446274429559708\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.046645667403936386\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04526202380657196\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12508375942707062\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05183202028274536\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03338821977376938\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.00585045525804162\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.07255985587835312\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04235832765698433\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06932105123996735\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.042696140706539154\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06133413687348366\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08657869696617126\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.023691562935709953\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06185769662261009\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08797984570264816\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014020053669810295\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.020393582060933113\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.04667672887444496\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.045262411236763\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.1250011920928955\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.05203806236386299\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.033402446657419205\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005837932229042053\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07272366434335709\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.04229060932993889\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06861025840044022\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04269631952047348\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06132124364376068\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08662666380405426\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.023691920563578606\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.06177434325218201\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.0879807248711586\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014021712355315685\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.020312214270234108\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.0467371828854084\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.045226261019706726\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.12490878254175186\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.052354536950588226\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.03341924026608467\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005838985089212656\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07283410429954529\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.04222876578569412\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.0683322474360466\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04269617423415184\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06130312755703926\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08660148829221725\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023691967129707336\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.061720263212919235\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08798803389072418\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014018949121236801\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.020265694707632065\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04672827199101448\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.0453668013215065\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12480716407299042\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05271310731768608\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.033362627029418945\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.005803022533655167\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07259815186262131\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.042817313224077225\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06828385591506958\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.042710334062576294\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.06128222495317459\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.0865028128027916\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02368907444179058\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06168189272284508\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.0879918709397316\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014018858782947063\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.020261608064174652\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04669850319623947\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04542514681816101\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12492312490940094\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.05188259482383728\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.033329255878925323\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005646093748509884\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07194460183382034\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04710948094725609\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.07114839553833008\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.042966246604919434\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.06127702072262764\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08635827898979187\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.023699089884757996\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.061798304319381714\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.0879797637462616\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014033962972462177\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02053099125623703\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.046587709337472916\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04554213955998421\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.12588244676589966\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.05224139988422394\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.03434416651725769\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.006310557946562767\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07347123324871063\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.0427887924015522\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.07203007489442825\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04290490224957466\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061341382563114166\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08635126799345016\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.023695550858974457\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.062362197786569595\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08797957003116608\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014033802784979343\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.02097376063466072\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.046630263328552246\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.04508349671959877\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12503419816493988\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05137009173631668\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.0335070863366127\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.0055756657384335995\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.0729164406657219\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.06420882791280746\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.08095481991767883\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04566588252782822\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.0620630644261837\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.09231515973806381\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.024243002757430077\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.0620550736784935\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.0889161080121994\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014285735785961151\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020241230726242065\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.05195759981870651\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.0448654405772686\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12555848062038422\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.051307763904333115\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.033345915377140045\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005453147459775209\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07195641845464706\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.04151579365134239\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06765314191579819\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.04270169883966446\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.06137508526444435\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.08689147979021072\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.023751037195324898\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.061778195202350616\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08815693110227585\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014021104201674461\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.02027316577732563\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.048095058649778366\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04485584795475006\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12445655465126038\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05252683162689209\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03343316167593002\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005412477999925613\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07235704362392426\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04109813645482063\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06800241768360138\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.04272516071796417\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06130966171622276\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08655909448862076\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023755166679620743\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.061859797686338425\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.08808151632547379\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.014028134755790234\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020259929820895195\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.0473284088075161\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04489516094326973\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12467915564775467\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.05146866291761398\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03334001824259758\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005417142994701862\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07217948138713837\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.041710104793310165\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06933752447366714\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.042957089841365814\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06138567253947258\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08659034967422485\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023745957762002945\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06205659732222557\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.0881107747554779\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014019378460943699\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.020267833024263382\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04730672761797905\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04489625245332718\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.1246013268828392\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.05152567848563194\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.03333962708711624\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005428093485534191\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07222123444080353\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04227406159043312\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06917387247085571\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.043065495789051056\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06138225644826889\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08652987331151962\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023744484409689903\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.062041424214839935\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.08808046579360962\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.014019796624779701\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020329421386122704\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04702697694301605\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04486056789755821\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12470728158950806\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.051287878304719925\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.03332244232296944\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.005459505598992109\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07203926146030426\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.04408416152000427\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.07035030424594879\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.043617602437734604\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.061381127685308456\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.08650293201208115\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02374298684298992\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.06204624101519585\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08811236172914505\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014020989648997784\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.02038220502436161\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.047092314809560776\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04485273361206055\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12455540895462036\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.0516175739467144\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.033334631472826004\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.0054766712710261345\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07203231751918793\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.04678985849022865\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.07118366658687592\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04416000097990036\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061436206102371216\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.08664912730455399\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023745983839035034\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061895132064819336\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08818531036376953\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014051892794668674\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020321398973464966\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.047330040484666824\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04490213468670845\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.12440328299999237\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.052274189889431\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.033360473811626434\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.005472392775118351\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07203736156225204\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.046876054257154465\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.07081475853919983\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.04403286427259445\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.06146499887108803\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08670731633901596\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.023743391036987305\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.061810802668333054\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08820277452468872\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.01407057885080576\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.02024884894490242\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.047488391399383545\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04499473422765732\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.12436199933290482\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05239425227046013\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03338908776640892\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005436343606561422\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07228583842515945\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04510663449764252\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.0698627457022667\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04377010464668274\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.06138109043240547\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08650173246860504\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.02373395673930645\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.06180723384022713\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08811529725790024\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.01402964536100626\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.020235668867826462\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.047128867357969284\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04491761699318886\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.12451231479644775\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.051546305418014526\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.03336808457970619\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005439955275505781\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07252871990203857\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04689357057213783\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.07137798517942429\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04430210590362549\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.061419274657964706\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08648576587438583\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023734433576464653\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06188734248280525\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.08812762796878815\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014022796414792538\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020261000841856003\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.047071196138858795\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.04488625004887581\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12453759461641312\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.051615528762340546\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03337502107024193\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005463685840368271\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07243788987398148\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.050121743232011795\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.0720694363117218\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.044559869915246964\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06164638698101044\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08689505606889725\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023737791925668716\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.061803895980119705\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08826896548271179\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.01406132336705923\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020206820219755173\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.047845520079135895\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04509490355849266\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.12441320717334747\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05281351879239082\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.03342542052268982\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.005412748083472252\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07243600487709045\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04603239893913269\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06961625069379807\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.044082291424274445\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06143813580274582\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08661870658397675\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.02374817430973053\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.06174750253558159\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08814436942338943\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.01401984877884388\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.020175287500023842\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.047361135482788086\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.04499165713787079\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.12440571933984756\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05197460576891899\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.03348381444811821\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005415420979261398\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07337544113397598\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04602036997675896\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.07054197788238525\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04453222081065178\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.06138896569609642\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08638006448745728\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023720035329461098\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.06182762607932091\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08806269615888596\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014035552740097046\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.020181288942694664\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.046862028539180756\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04487619921565056\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12492059916257858\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.051262810826301575\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.033368416130542755\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.0054788291454315186\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07266228646039963\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.05310807749629021\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.07096491008996964\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.044531986117362976\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.06180189549922943\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08710192888975143\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.02370871789753437\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06172899529337883\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08822763711214066\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014020541682839394\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.02017642930150032\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04787193611264229\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04500463232398033\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12440957874059677\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.05281726270914078\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.03352611884474754\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.0054112705402076244\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07316494733095169\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.050493888556957245\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06907167285680771\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04401661828160286\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06161705031991005\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08688557147979736\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.02372531034052372\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.061694707721471786\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08814273029565811\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014073804020881653\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.020179329439997673\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.04725973680615425\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.04496541991829872\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12458879500627518\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.051726728677749634\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03354702889919281\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005411500111222267\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.07438302040100098\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.046649329364299774\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.07018361240625381\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.043672364205121994\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.061529796570539474\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.08644568920135498\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023734059184789658\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06178342550992966\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08803395181894302\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014191660098731518\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.02016889676451683\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.04665808752179146\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.04487662762403488\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.1256742775440216\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.0511711947619915\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.03332904726266861\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.00554877333343029\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.07220519334077835\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.05048895999789238\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.06798337399959564\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.0432359017431736\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061513472348451614\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08669151365756989\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023715056478977203\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.061701104044914246\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08804168552160263\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014310787431895733\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02017252892255783\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.046641118824481964\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.044949114322662354\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12568095326423645\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.051298387348651886\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.033365316689014435\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005452093202620745\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.0724569782614708\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04741928353905678\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06758157908916473\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.042923297733068466\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061431631445884705\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08651173859834671\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.023758579045534134\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.0617758110165596\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.0880255326628685\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014529455453157425\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020178357139229774\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.046631019562482834\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04502733051776886\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12563738226890564\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05161869525909424\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.033448148518800735\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005413830745965242\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07394826412200928\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04620504379272461\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06759597361087799\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04336119815707207\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.061402782797813416\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08642329275608063\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023760337382555008\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06178997457027435\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08804430067539215\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014519141986966133\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020170146599411964\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.046790242195129395\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.04501091316342354\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12513020634651184\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.05207926407456398\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03354465588927269\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005411300342530012\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07444927841424942\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.049269892275333405\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.0676930695772171\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.043813180178403854\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06136315315961838\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.08651445806026459\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023776838555932045\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06175246462225914\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08804269134998322\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.014463118277490139\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020179089158773422\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.046912189573049545\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04499141126871109\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12490316480398178\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.052330080419778824\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.03363357111811638\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.0054170205257833\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07429139316082001\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.0547606460750103\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06759495288133621\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.04276702553033829\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06127871572971344\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.0867018923163414\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023911140859127045\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.061950523406267166\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08805370330810547\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014372581616044044\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020351460203528404\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04735150933265686\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04495275393128395\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12466040253639221\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.052275896072387695\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03360183537006378\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005422502756118774\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07365652173757553\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.05398709699511528\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06802728027105331\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04269929602742195\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.06130590662360191\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08663452416658401\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.024014001712203026\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.06207433342933655\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08809634298086166\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.01437336951494217\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020584097132086754\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04755846783518791\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.04487292468547821\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.1252104490995407\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05253475531935692\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.03369227424263954\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005439531058073044\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07364902645349503\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.055925123393535614\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06917889416217804\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04301063343882561\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06140090152621269\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.08716399222612381\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02401745691895485\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06217065081000328\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.08809223771095276\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014283045195043087\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020796701312065125\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04764002934098244\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.0448487289249897\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.1261029839515686\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.05316019803285599\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.033839669078588486\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005475137382745743\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07289588451385498\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.0509159192442894\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.0701015368103981\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.042965903878211975\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061356235295534134\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08689821511507034\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.02399718202650547\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06208677962422371\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.0880683958530426\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.01430694479495287\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02101033553481102\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.047966551035642624\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04483779892325401\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12636451423168182\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.053799115121364594\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03387122601270676\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.005476243793964386\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07221731543540955\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.05024261772632599\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06963545083999634\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.04285377264022827\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061280298978090286\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.08742797374725342\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02385173738002777\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06198573485016823\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.0880008414387703\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.01418650895357132\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.021312428638339043\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.048498764634132385\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044858258217573166\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12628985941410065\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05451491102576256\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03385114669799805\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005416486877948046\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07175293564796448\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.0457458458840847\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.0695178359746933\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04272807016968727\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06129106879234314\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.0868012085556984\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02385829947888851\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06186109036207199\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08799158781766891\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014220844022929668\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.021465875208377838\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.04838988557457924\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.044884711503982544\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.1262953281402588\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.054775502532720566\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.033709000796079636\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005415255669504404\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07194153964519501\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.04454461485147476\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.0689123123884201\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.042707543820142746\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.06134096905589104\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08666718006134033\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.02387212961912155\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.061730604618787766\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08799030631780624\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014336930587887764\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.021077800542116165\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04774477705359459\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.04485824331641197\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.12603530287742615\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.054450806230306625\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.03359152749180794\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.005430083256214857\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.0721122995018959\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.04293278232216835\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06903685629367828\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04269606992602348\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06133376061916351\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08638758212327957\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.02387743443250656\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.06175493076443672\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08800250291824341\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.014316773973405361\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.02139085903763771\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04774714633822441\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04488571733236313\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.12668821215629578\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05474115163087845\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033573612570762634\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.005428035277873278\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07225612550973892\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.04257269948720932\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06875579059123993\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.0426960363984108\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061319395899772644\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08635340631008148\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.02386915311217308\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.06171109899878502\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08801554143428802\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.014420351944863796\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.020847728475928307\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04736771434545517\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.044852692633867264\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12628647685050964\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05444743484258652\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03357198089361191\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.0054190210066735744\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07219017297029495\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.04265550523996353\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06887949258089066\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04269617050886154\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061302874237298965\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.0863470733165741\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.02387538179755211\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06169462576508522\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08802168071269989\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014400636777281761\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020963048562407494\n",
      "Search Iteration [20/20], Validation Loss: 0.06731572703204372\n",
      "Best Hyperparameters:\n",
      "{'lr': 0.0001, 'batch_size': 512, 'num_layers': 3, 'hidden_size': 64, 'dropout_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "\n",
    "# Define the custom sampler for the data loader\n",
    "class CustomBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, data_source, batch_size=432, overlap=10):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.data_source)))\n",
    "        for start_idx in range(0, len(indices) - self.batch_size + 1, self.batch_size - self.overlap):\n",
    "            yield indices[start_idx : start_idx + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source) - self.batch_size) // (self.batch_size - self.overlap) + 1\n",
    "\n",
    "# Create the custom batch sampler\n",
    "batch_size = 526\n",
    "overlap = 60\n",
    "train_custom_sampler = CustomBatchSampler(range(len(xgb_X_train)), batch_size, overlap)\n",
    "valid_custom_sampler = CustomBatchSampler(range(len(xgb_X_valid)), batch_size, overlap)\n",
    "\n",
    "# Create the data loaders using the custom sampler\n",
    "train_dataset = TensorDataset(xgb_X_train, xgb_y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=train_custom_sampler)\n",
    "\n",
    "valid_dataset = TensorDataset(xgb_X_valid, xgb_y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_sampler=valid_custom_sampler)\n",
    "\n",
    "# Define the stacked LSTM with self-attention\n",
    "class StackedLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, attention_size, output_size):\n",
    "        super(StackedLSTMWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention_size = attention_size\n",
    "\n",
    "        # Stacked LSTM layers\n",
    "        self.lstm_stack = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Attention layer\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, attention_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, _ = self.lstm_stack(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(out)\n",
    "        attention_out = torch.sum(attention_weights * out, dim=1)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.fc(attention_out)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 64\n",
    "output_size = 1\n",
    "\n",
    "# Hyperparameter search space\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "batch_sizes = [256, 512, 1024]\n",
    "num_layers_values = [1, 2, 3]\n",
    "hidden_sizes = [64, 128, 256]\n",
    "dropout_rates = [0.0, 0.1, 0.2]\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Perform random search\n",
    "num_search_iterations = 20\n",
    "for search_iteration in range(num_search_iterations):\n",
    "    # Randomly sample hyperparameters from the search space\n",
    "    lr = random.choice(learning_rates)\n",
    "    batch_size = random.choice(batch_sizes)\n",
    "    num_layers = random.choice(num_layers_values)\n",
    "    hidden_size = random.choice(hidden_sizes)\n",
    "    dropout_rate = random.choice(dropout_rates)\n",
    "\n",
    "    # Initialize the model with sampled hyperparameters\n",
    "    model = StackedLSTMWithAttention(input_size, hidden_size, num_layers, attention_size, output_size)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Reshape data to (batch_size, sequence_length, input_size)\n",
    "            data = data.view(-1, 526, 64)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "\n",
    "            # Flatten the predictions and targets for loss calculation\n",
    "            outputs = outputs.view(-1)\n",
    "            target = target.view(-1)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print batch loss\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for data, target in valid_loader:\n",
    "            # Reshape data to (batch_size, sequence_length, input_size)\n",
    "            data = data.view(-1, 526, 64)\n",
    "\n",
    "            outputs = model(data)\n",
    "            outputs = outputs.view(-1)\n",
    "            target = target.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(valid_loader)\n",
    "\n",
    "        # Check if this combination of hyperparameters is the best so far\n",
    "        if average_loss < best_loss:\n",
    "            best_loss = average_loss\n",
    "            best_hyperparameters = {\n",
    "                'lr': lr,\n",
    "                'batch_size': batch_size,\n",
    "                'num_layers': num_layers,\n",
    "                'hidden_size': hidden_size,\n",
    "                'dropout_rate': dropout_rate\n",
    "            }\n",
    "\n",
    "        print(f\"Search Iteration [{search_iteration+1}/{num_search_iterations}], \"\n",
    "              f\"Validation Loss: {average_loss}\")\n",
    "\n",
    "# Print the best hyperparameters found during the search\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Batch [0/168], Loss: 0.13019907474517822\n",
      "Epoch [0/50], Batch [10/168], Loss: 0.07982006669044495\n",
      "Epoch [0/50], Batch [20/168], Loss: 0.15077170729637146\n",
      "Epoch [0/50], Batch [30/168], Loss: 0.05158255621790886\n",
      "Epoch [0/50], Batch [40/168], Loss: 0.04763662815093994\n",
      "Epoch [0/50], Batch [50/168], Loss: 0.04458417743444443\n",
      "Epoch [0/50], Batch [60/168], Loss: 0.17925280332565308\n",
      "Epoch [0/50], Batch [70/168], Loss: 0.24819859862327576\n",
      "Epoch [0/50], Batch [80/168], Loss: 0.09861975908279419\n",
      "Epoch [0/50], Batch [90/168], Loss: 0.09329180419445038\n",
      "Epoch [0/50], Batch [100/168], Loss: 0.0750410184264183\n",
      "Epoch [0/50], Batch [110/168], Loss: 0.21679197251796722\n",
      "Epoch [0/50], Batch [120/168], Loss: 0.025663891807198524\n",
      "Epoch [0/50], Batch [130/168], Loss: 0.061980701982975006\n",
      "Epoch [0/50], Batch [140/168], Loss: 0.10233894735574722\n",
      "Epoch [0/50], Batch [150/168], Loss: 0.040819890797138214\n",
      "Epoch [0/50], Batch [160/168], Loss: 0.04405321180820465\n",
      "Epoch [0/50], Validation Loss: 0.08191931904716925\n",
      "Epoch [1/50], Batch [0/168], Loss: 0.06317103654146194\n",
      "Epoch [1/50], Batch [10/168], Loss: 0.06774254888296127\n",
      "Epoch [1/50], Batch [20/168], Loss: 0.1265743225812912\n",
      "Epoch [1/50], Batch [30/168], Loss: 0.07535041123628616\n",
      "Epoch [1/50], Batch [40/168], Loss: 0.04867010563611984\n",
      "Epoch [1/50], Batch [50/168], Loss: 0.024458762258291245\n",
      "Epoch [1/50], Batch [60/168], Loss: 0.15606844425201416\n",
      "Epoch [1/50], Batch [70/168], Loss: 0.15050753951072693\n",
      "Epoch [1/50], Batch [80/168], Loss: 0.1212373897433281\n",
      "Epoch [1/50], Batch [90/168], Loss: 0.06121852248907089\n",
      "Epoch [1/50], Batch [100/168], Loss: 0.062151070684194565\n",
      "Epoch [1/50], Batch [110/168], Loss: 0.1951933354139328\n",
      "Epoch [1/50], Batch [120/168], Loss: 0.02586195059120655\n",
      "Epoch [1/50], Batch [130/168], Loss: 0.06246745213866234\n",
      "Epoch [1/50], Batch [140/168], Loss: 0.092486672103405\n",
      "Epoch [1/50], Batch [150/168], Loss: 0.03805213421583176\n",
      "Epoch [1/50], Batch [160/168], Loss: 0.02367725595831871\n",
      "Epoch [1/50], Validation Loss: 0.07285240248522976\n",
      "Epoch [2/50], Batch [0/168], Loss: 0.05374274030327797\n",
      "Epoch [2/50], Batch [10/168], Loss: 0.05915163829922676\n",
      "Epoch [2/50], Batch [20/168], Loss: 0.12492810189723969\n",
      "Epoch [2/50], Batch [30/168], Loss: 0.06183920055627823\n",
      "Epoch [2/50], Batch [40/168], Loss: 0.035936418920755386\n",
      "Epoch [2/50], Batch [50/168], Loss: 0.009449023753404617\n",
      "Epoch [2/50], Batch [60/168], Loss: 0.08239029347896576\n",
      "Epoch [2/50], Batch [70/168], Loss: 0.045093096792697906\n",
      "Epoch [2/50], Batch [80/168], Loss: 0.07894492149353027\n",
      "Epoch [2/50], Batch [90/168], Loss: 0.042878564447164536\n",
      "Epoch [2/50], Batch [100/168], Loss: 0.06462674587965012\n",
      "Epoch [2/50], Batch [110/168], Loss: 0.09886384010314941\n",
      "Epoch [2/50], Batch [120/168], Loss: 0.025004684925079346\n",
      "Epoch [2/50], Batch [130/168], Loss: 0.07881546765565872\n",
      "Epoch [2/50], Batch [140/168], Loss: 0.08801496773958206\n",
      "Epoch [2/50], Batch [150/168], Loss: 0.01916232518851757\n",
      "Epoch [2/50], Batch [160/168], Loss: 0.02502419427037239\n",
      "Epoch [2/50], Validation Loss: 0.0646829863671552\n",
      "Epoch [3/50], Batch [0/168], Loss: 0.04662832245230675\n",
      "Epoch [3/50], Batch [10/168], Loss: 0.04951174184679985\n",
      "Epoch [3/50], Batch [20/168], Loss: 0.1299538016319275\n",
      "Epoch [3/50], Batch [30/168], Loss: 0.05114743486046791\n",
      "Epoch [3/50], Batch [40/168], Loss: 0.03332595154643059\n",
      "Epoch [3/50], Batch [50/168], Loss: 0.00769580015912652\n",
      "Epoch [3/50], Batch [60/168], Loss: 0.07220332324504852\n",
      "Epoch [3/50], Batch [70/168], Loss: 0.041410017758607864\n",
      "Epoch [3/50], Batch [80/168], Loss: 0.07053925842046738\n",
      "Epoch [3/50], Batch [90/168], Loss: 0.042696528136730194\n",
      "Epoch [3/50], Batch [100/168], Loss: 0.06374584138393402\n",
      "Epoch [3/50], Batch [110/168], Loss: 0.08669382333755493\n",
      "Epoch [3/50], Batch [120/168], Loss: 0.023738449439406395\n",
      "Epoch [3/50], Batch [130/168], Loss: 0.06923627853393555\n",
      "Epoch [3/50], Batch [140/168], Loss: 0.08800418674945831\n",
      "Epoch [3/50], Batch [150/168], Loss: 0.014019102789461613\n",
      "Epoch [3/50], Batch [160/168], Loss: 0.024856485426425934\n",
      "Epoch [3/50], Validation Loss: 0.06230799744582989\n",
      "Epoch [4/50], Batch [0/168], Loss: 0.049007829278707504\n",
      "Epoch [4/50], Batch [10/168], Loss: 0.045518822968006134\n",
      "Epoch [4/50], Batch [20/168], Loss: 0.1287083774805069\n",
      "Epoch [4/50], Batch [30/168], Loss: 0.051238272339105606\n",
      "Epoch [4/50], Batch [40/168], Loss: 0.0334855392575264\n",
      "Epoch [4/50], Batch [50/168], Loss: 0.005419396795332432\n",
      "Epoch [4/50], Batch [60/168], Loss: 0.07241473346948624\n",
      "Epoch [4/50], Batch [70/168], Loss: 0.041191644966602325\n",
      "Epoch [4/50], Batch [80/168], Loss: 0.06942339986562729\n",
      "Epoch [4/50], Batch [90/168], Loss: 0.04270022362470627\n",
      "Epoch [4/50], Batch [100/168], Loss: 0.062406860291957855\n",
      "Epoch [4/50], Batch [110/168], Loss: 0.08755125105381012\n",
      "Epoch [4/50], Batch [120/168], Loss: 0.023782985284924507\n",
      "Epoch [4/50], Batch [130/168], Loss: 0.06520068645477295\n",
      "Epoch [4/50], Batch [140/168], Loss: 0.08799228072166443\n",
      "Epoch [4/50], Batch [150/168], Loss: 0.014020484872162342\n",
      "Epoch [4/50], Batch [160/168], Loss: 0.02249807119369507\n",
      "Epoch [4/50], Validation Loss: 0.062360473688353193\n",
      "Epoch [5/50], Batch [0/168], Loss: 0.048297613859176636\n",
      "Epoch [5/50], Batch [10/168], Loss: 0.04485161975026131\n",
      "Epoch [5/50], Batch [20/168], Loss: 0.12667666375637054\n",
      "Epoch [5/50], Batch [30/168], Loss: 0.05127326399087906\n",
      "Epoch [5/50], Batch [40/168], Loss: 0.03339310735464096\n",
      "Epoch [5/50], Batch [50/168], Loss: 0.005495322402566671\n",
      "Epoch [5/50], Batch [60/168], Loss: 0.07351883500814438\n",
      "Epoch [5/50], Batch [70/168], Loss: 0.04415593296289444\n",
      "Epoch [5/50], Batch [80/168], Loss: 0.07064686715602875\n",
      "Epoch [5/50], Batch [90/168], Loss: 0.04274556040763855\n",
      "Epoch [5/50], Batch [100/168], Loss: 0.06215139105916023\n",
      "Epoch [5/50], Batch [110/168], Loss: 0.08648528903722763\n",
      "Epoch [5/50], Batch [120/168], Loss: 0.023694215342402458\n",
      "Epoch [5/50], Batch [130/168], Loss: 0.06307125091552734\n",
      "Epoch [5/50], Batch [140/168], Loss: 0.08798212558031082\n",
      "Epoch [5/50], Batch [150/168], Loss: 0.014024656265974045\n",
      "Epoch [5/50], Batch [160/168], Loss: 0.021572303026914597\n",
      "Epoch [5/50], Validation Loss: 0.06275011732835661\n",
      "Epoch [6/50], Batch [0/168], Loss: 0.04771147668361664\n",
      "Epoch [6/50], Batch [10/168], Loss: 0.0448620580136776\n",
      "Epoch [6/50], Batch [20/168], Loss: 0.12601123750209808\n",
      "Epoch [6/50], Batch [30/168], Loss: 0.051460590213537216\n",
      "Epoch [6/50], Batch [40/168], Loss: 0.03336527943611145\n",
      "Epoch [6/50], Batch [50/168], Loss: 0.005555420182645321\n",
      "Epoch [6/50], Batch [60/168], Loss: 0.07415123283863068\n",
      "Epoch [6/50], Batch [70/168], Loss: 0.04477071762084961\n",
      "Epoch [6/50], Batch [80/168], Loss: 0.07025007903575897\n",
      "Epoch [6/50], Batch [90/168], Loss: 0.04274247959256172\n",
      "Epoch [6/50], Batch [100/168], Loss: 0.061821311712265015\n",
      "Epoch [6/50], Batch [110/168], Loss: 0.08636542409658432\n",
      "Epoch [6/50], Batch [120/168], Loss: 0.02369973435997963\n",
      "Epoch [6/50], Batch [130/168], Loss: 0.062180109322071075\n",
      "Epoch [6/50], Batch [140/168], Loss: 0.08798157423734665\n",
      "Epoch [6/50], Batch [150/168], Loss: 0.014019357971847057\n",
      "Epoch [6/50], Batch [160/168], Loss: 0.021009104326367378\n",
      "Epoch [6/50], Validation Loss: 0.06340417818758975\n",
      "Epoch [7/50], Batch [0/168], Loss: 0.04727298766374588\n",
      "Epoch [7/50], Batch [10/168], Loss: 0.04490112513303757\n",
      "Epoch [7/50], Batch [20/168], Loss: 0.12570254504680634\n",
      "Epoch [7/50], Batch [30/168], Loss: 0.051628611981868744\n",
      "Epoch [7/50], Batch [40/168], Loss: 0.0333549864590168\n",
      "Epoch [7/50], Batch [50/168], Loss: 0.005541033111512661\n",
      "Epoch [7/50], Batch [60/168], Loss: 0.07450759410858154\n",
      "Epoch [7/50], Batch [70/168], Loss: 0.04451875016093254\n",
      "Epoch [7/50], Batch [80/168], Loss: 0.06967053562402725\n",
      "Epoch [7/50], Batch [90/168], Loss: 0.04273904860019684\n",
      "Epoch [7/50], Batch [100/168], Loss: 0.061595380306243896\n",
      "Epoch [7/50], Batch [110/168], Loss: 0.08650730550289154\n",
      "Epoch [7/50], Batch [120/168], Loss: 0.023747939616441727\n",
      "Epoch [7/50], Batch [130/168], Loss: 0.06183982640504837\n",
      "Epoch [7/50], Batch [140/168], Loss: 0.08799483627080917\n",
      "Epoch [7/50], Batch [150/168], Loss: 0.014034363441169262\n",
      "Epoch [7/50], Batch [160/168], Loss: 0.020671939477324486\n",
      "Epoch [7/50], Validation Loss: 0.06387610067190094\n",
      "Epoch [8/50], Batch [0/168], Loss: 0.047025687992572784\n",
      "Epoch [8/50], Batch [10/168], Loss: 0.0449141226708889\n",
      "Epoch [8/50], Batch [20/168], Loss: 0.1255548745393753\n",
      "Epoch [8/50], Batch [30/168], Loss: 0.05173715949058533\n",
      "Epoch [8/50], Batch [40/168], Loss: 0.03334910795092583\n",
      "Epoch [8/50], Batch [50/168], Loss: 0.005519685801118612\n",
      "Epoch [8/50], Batch [60/168], Loss: 0.07474803924560547\n",
      "Epoch [8/50], Batch [70/168], Loss: 0.04404798150062561\n",
      "Epoch [8/50], Batch [80/168], Loss: 0.0692761093378067\n",
      "Epoch [8/50], Batch [90/168], Loss: 0.04273659735918045\n",
      "Epoch [8/50], Batch [100/168], Loss: 0.061464592814445496\n",
      "Epoch [8/50], Batch [110/168], Loss: 0.08661067485809326\n",
      "Epoch [8/50], Batch [120/168], Loss: 0.0237882062792778\n",
      "Epoch [8/50], Batch [130/168], Loss: 0.06171241030097008\n",
      "Epoch [8/50], Batch [140/168], Loss: 0.08801006525754929\n",
      "Epoch [8/50], Batch [150/168], Loss: 0.014051216654479504\n",
      "Epoch [8/50], Batch [160/168], Loss: 0.020473679527640343\n",
      "Epoch [8/50], Validation Loss: 0.0640991745177995\n",
      "Epoch [9/50], Batch [0/168], Loss: 0.04690130054950714\n",
      "Epoch [9/50], Batch [10/168], Loss: 0.04491376876831055\n",
      "Epoch [9/50], Batch [20/168], Loss: 0.12546877562999725\n",
      "Epoch [9/50], Batch [30/168], Loss: 0.05180557817220688\n",
      "Epoch [9/50], Batch [40/168], Loss: 0.03334391489624977\n",
      "Epoch [9/50], Batch [50/168], Loss: 0.005506915971636772\n",
      "Epoch [9/50], Batch [60/168], Loss: 0.07490134984254837\n",
      "Epoch [9/50], Batch [70/168], Loss: 0.04356063902378082\n",
      "Epoch [9/50], Batch [80/168], Loss: 0.0689898133277893\n",
      "Epoch [9/50], Batch [90/168], Loss: 0.04273262247443199\n",
      "Epoch [9/50], Batch [100/168], Loss: 0.06138774752616882\n",
      "Epoch [9/50], Batch [110/168], Loss: 0.08665589243173599\n",
      "Epoch [9/50], Batch [120/168], Loss: 0.023814888671040535\n",
      "Epoch [9/50], Batch [130/168], Loss: 0.061664942651987076\n",
      "Epoch [9/50], Batch [140/168], Loss: 0.08802285045385361\n",
      "Epoch [9/50], Batch [150/168], Loss: 0.01406171452254057\n",
      "Epoch [9/50], Batch [160/168], Loss: 0.02035480923950672\n",
      "Epoch [9/50], Validation Loss: 0.06421763987534425\n",
      "Epoch [10/50], Batch [0/168], Loss: 0.046829525381326675\n",
      "Epoch [10/50], Batch [10/168], Loss: 0.044908661395311356\n",
      "Epoch [10/50], Batch [20/168], Loss: 0.1253996342420578\n",
      "Epoch [10/50], Batch [30/168], Loss: 0.051862217485904694\n",
      "Epoch [10/50], Batch [40/168], Loss: 0.03333786502480507\n",
      "Epoch [10/50], Batch [50/168], Loss: 0.005501647479832172\n",
      "Epoch [10/50], Batch [60/168], Loss: 0.07496967166662216\n",
      "Epoch [10/50], Batch [70/168], Loss: 0.04309452325105667\n",
      "Epoch [10/50], Batch [80/168], Loss: 0.06874452531337738\n",
      "Epoch [10/50], Batch [90/168], Loss: 0.042726319283246994\n",
      "Epoch [10/50], Batch [100/168], Loss: 0.06134109944105148\n",
      "Epoch [10/50], Batch [110/168], Loss: 0.08666330575942993\n",
      "Epoch [10/50], Batch [120/168], Loss: 0.023829994723200798\n",
      "Epoch [10/50], Batch [130/168], Loss: 0.061651766300201416\n",
      "Epoch [10/50], Batch [140/168], Loss: 0.08803312480449677\n",
      "Epoch [10/50], Batch [150/168], Loss: 0.014067131094634533\n",
      "Epoch [10/50], Batch [160/168], Loss: 0.020282261073589325\n",
      "Epoch [10/50], Validation Loss: 0.0643125401979143\n",
      "Epoch [11/50], Batch [0/168], Loss: 0.04678264260292053\n",
      "Epoch [11/50], Batch [10/168], Loss: 0.04490148648619652\n",
      "Epoch [11/50], Batch [20/168], Loss: 0.1253371238708496\n",
      "Epoch [11/50], Batch [30/168], Loss: 0.051918745040893555\n",
      "Epoch [11/50], Batch [40/168], Loss: 0.03333162143826485\n",
      "Epoch [11/50], Batch [50/168], Loss: 0.00550060672685504\n",
      "Epoch [11/50], Batch [60/168], Loss: 0.07496163249015808\n",
      "Epoch [11/50], Batch [70/168], Loss: 0.04266111180186272\n",
      "Epoch [11/50], Batch [80/168], Loss: 0.068518728017807\n",
      "Epoch [11/50], Batch [90/168], Loss: 0.042718276381492615\n",
      "Epoch [11/50], Batch [100/168], Loss: 0.06131261959671974\n",
      "Epoch [11/50], Batch [110/168], Loss: 0.08664952218532562\n",
      "Epoch [11/50], Batch [120/168], Loss: 0.02383618988096714\n",
      "Epoch [11/50], Batch [130/168], Loss: 0.06165457144379616\n",
      "Epoch [11/50], Batch [140/168], Loss: 0.08804157376289368\n",
      "Epoch [11/50], Batch [150/168], Loss: 0.014069261960685253\n",
      "Epoch [11/50], Batch [160/168], Loss: 0.020237615332007408\n",
      "Epoch [11/50], Validation Loss: 0.06441316431049596\n",
      "Epoch [12/50], Batch [0/168], Loss: 0.046750202775001526\n",
      "Epoch [12/50], Batch [10/168], Loss: 0.044893115758895874\n",
      "Epoch [12/50], Batch [20/168], Loss: 0.1252819448709488\n",
      "Epoch [12/50], Batch [30/168], Loss: 0.05198007449507713\n",
      "Epoch [12/50], Batch [40/168], Loss: 0.033326271921396255\n",
      "Epoch [12/50], Batch [50/168], Loss: 0.005501361098140478\n",
      "Epoch [12/50], Batch [60/168], Loss: 0.07489033043384552\n",
      "Epoch [12/50], Batch [70/168], Loss: 0.042267948389053345\n",
      "Epoch [12/50], Batch [80/168], Loss: 0.06831002980470657\n",
      "Epoch [12/50], Batch [90/168], Loss: 0.04270971193909645\n",
      "Epoch [12/50], Batch [100/168], Loss: 0.06129559129476547\n",
      "Epoch [12/50], Batch [110/168], Loss: 0.08662571012973785\n",
      "Epoch [12/50], Batch [120/168], Loss: 0.02383597195148468\n",
      "Epoch [12/50], Batch [130/168], Loss: 0.06166474148631096\n",
      "Epoch [12/50], Batch [140/168], Loss: 0.08804893493652344\n",
      "Epoch [12/50], Batch [150/168], Loss: 0.014069360680878162\n",
      "Epoch [12/50], Batch [160/168], Loss: 0.020210064947605133\n",
      "Epoch [12/50], Validation Loss: 0.06452755265107209\n",
      "Epoch [13/50], Batch [0/168], Loss: 0.04672757536172867\n",
      "Epoch [13/50], Batch [10/168], Loss: 0.044884104281663895\n",
      "Epoch [13/50], Batch [20/168], Loss: 0.12523560225963593\n",
      "Epoch [13/50], Batch [30/168], Loss: 0.05204879492521286\n",
      "Epoch [13/50], Batch [40/168], Loss: 0.03332265093922615\n",
      "Epoch [13/50], Batch [50/168], Loss: 0.005502273794263601\n",
      "Epoch [13/50], Batch [60/168], Loss: 0.07476954907178879\n",
      "Epoch [13/50], Batch [70/168], Loss: 0.041921891272068024\n",
      "Epoch [13/50], Batch [80/168], Loss: 0.06812191009521484\n",
      "Epoch [13/50], Batch [90/168], Loss: 0.042702168226242065\n",
      "Epoch [13/50], Batch [100/168], Loss: 0.061285845935344696\n",
      "Epoch [13/50], Batch [110/168], Loss: 0.08659913390874863\n",
      "Epoch [13/50], Batch [120/168], Loss: 0.02383156679570675\n",
      "Epoch [13/50], Batch [130/168], Loss: 0.06167794018983841\n",
      "Epoch [13/50], Batch [140/168], Loss: 0.08805575966835022\n",
      "Epoch [13/50], Batch [150/168], Loss: 0.014068338088691235\n",
      "Epoch [13/50], Batch [160/168], Loss: 0.020193113014101982\n",
      "Epoch [13/50], Validation Loss: 0.06465592028742487\n",
      "Epoch [14/50], Batch [0/168], Loss: 0.04671228677034378\n",
      "Epoch [14/50], Batch [10/168], Loss: 0.04487500712275505\n",
      "Epoch [14/50], Batch [20/168], Loss: 0.12519851326942444\n",
      "Epoch [14/50], Batch [30/168], Loss: 0.05212607979774475\n",
      "Epoch [14/50], Batch [40/168], Loss: 0.03332135081291199\n",
      "Epoch [14/50], Batch [50/168], Loss: 0.00550225330516696\n",
      "Epoch [14/50], Batch [60/168], Loss: 0.0746113583445549\n",
      "Epoch [14/50], Batch [70/168], Loss: 0.04162873327732086\n",
      "Epoch [14/50], Batch [80/168], Loss: 0.06795896589756012\n",
      "Epoch [14/50], Batch [90/168], Loss: 0.04269718751311302\n",
      "Epoch [14/50], Batch [100/168], Loss: 0.06128066033124924\n",
      "Epoch [14/50], Batch [110/168], Loss: 0.08657439798116684\n",
      "Epoch [14/50], Batch [120/168], Loss: 0.02382483333349228\n",
      "Epoch [14/50], Batch [130/168], Loss: 0.06169203668832779\n",
      "Epoch [14/50], Batch [140/168], Loss: 0.08806260675191879\n",
      "Epoch [14/50], Batch [150/168], Loss: 0.014066825620830059\n",
      "Epoch [14/50], Batch [160/168], Loss: 0.02018275484442711\n",
      "Epoch [14/50], Validation Loss: 0.06479473875158212\n",
      "Epoch [15/50], Batch [0/168], Loss: 0.046702831983566284\n",
      "Epoch [15/50], Batch [10/168], Loss: 0.04486635699868202\n",
      "Epoch [15/50], Batch [20/168], Loss: 0.12517011165618896\n",
      "Epoch [15/50], Batch [30/168], Loss: 0.052212174981832504\n",
      "Epoch [15/50], Batch [40/168], Loss: 0.03332284465432167\n",
      "Epoch [15/50], Batch [50/168], Loss: 0.005500578787177801\n",
      "Epoch [15/50], Batch [60/168], Loss: 0.07442676275968552\n",
      "Epoch [15/50], Batch [70/168], Loss: 0.041392650455236435\n",
      "Epoch [15/50], Batch [80/168], Loss: 0.06782504171133041\n",
      "Epoch [15/50], Batch [90/168], Loss: 0.04269609600305557\n",
      "Epoch [15/50], Batch [100/168], Loss: 0.06127817928791046\n",
      "Epoch [15/50], Batch [110/168], Loss: 0.08655427396297455\n",
      "Epoch [15/50], Batch [120/168], Loss: 0.02381732501089573\n",
      "Epoch [15/50], Batch [130/168], Loss: 0.061706122010946274\n",
      "Epoch [15/50], Batch [140/168], Loss: 0.08806999027729034\n",
      "Epoch [15/50], Batch [150/168], Loss: 0.014065306633710861\n",
      "Epoch [15/50], Batch [160/168], Loss: 0.02017652615904808\n",
      "Epoch [15/50], Validation Loss: 0.06493936441838741\n",
      "Epoch [16/50], Batch [0/168], Loss: 0.04669817537069321\n",
      "Epoch [16/50], Batch [10/168], Loss: 0.044858574867248535\n",
      "Epoch [16/50], Batch [20/168], Loss: 0.1251494139432907\n",
      "Epoch [16/50], Batch [30/168], Loss: 0.05230650678277016\n",
      "Epoch [16/50], Batch [40/168], Loss: 0.033327557146549225\n",
      "Epoch [16/50], Batch [50/168], Loss: 0.005496807396411896\n",
      "Epoch [16/50], Batch [60/168], Loss: 0.07422500848770142\n",
      "Epoch [16/50], Batch [70/168], Loss: 0.041215166449546814\n",
      "Epoch [16/50], Batch [80/168], Loss: 0.06772204488515854\n",
      "Epoch [16/50], Batch [90/168], Loss: 0.04269977658987045\n",
      "Epoch [16/50], Batch [100/168], Loss: 0.06127715855836868\n",
      "Epoch [16/50], Batch [110/168], Loss: 0.08654047548770905\n",
      "Epoch [16/50], Batch [120/168], Loss: 0.023810284212231636\n",
      "Epoch [16/50], Batch [130/168], Loss: 0.06171996146440506\n",
      "Epoch [16/50], Batch [140/168], Loss: 0.08807846158742905\n",
      "Epoch [16/50], Batch [150/168], Loss: 0.014064108021557331\n",
      "Epoch [16/50], Batch [160/168], Loss: 0.02017286978662014\n",
      "Epoch [16/50], Validation Loss: 0.06508476437831467\n",
      "Epoch [17/50], Batch [0/168], Loss: 0.04669760540127754\n",
      "Epoch [17/50], Batch [10/168], Loss: 0.04485198110342026\n",
      "Epoch [17/50], Batch [20/168], Loss: 0.12513503432273865\n",
      "Epoch [17/50], Batch [30/168], Loss: 0.05240754410624504\n",
      "Epoch [17/50], Batch [40/168], Loss: 0.03333586826920509\n",
      "Epoch [17/50], Batch [50/168], Loss: 0.0054907770827412605\n",
      "Epoch [17/50], Batch [60/168], Loss: 0.07401396334171295\n",
      "Epoch [17/50], Batch [70/168], Loss: 0.04109518229961395\n",
      "Epoch [17/50], Batch [80/168], Loss: 0.06764959543943405\n",
      "Epoch [17/50], Batch [90/168], Loss: 0.04270846024155617\n",
      "Epoch [17/50], Batch [100/168], Loss: 0.061276815831661224\n",
      "Epoch [17/50], Batch [110/168], Loss: 0.08653368055820465\n",
      "Epoch [17/50], Batch [120/168], Loss: 0.02380465157330036\n",
      "Epoch [17/50], Batch [130/168], Loss: 0.06173369660973549\n",
      "Epoch [17/50], Batch [140/168], Loss: 0.08808862417936325\n",
      "Epoch [17/50], Batch [150/168], Loss: 0.014063444919884205\n",
      "Epoch [17/50], Batch [160/168], Loss: 0.02017083205282688\n",
      "Epoch [17/50], Validation Loss: 0.0652261175553907\n",
      "Epoch [18/50], Batch [0/168], Loss: 0.04670055955648422\n",
      "Epoch [18/50], Batch [10/168], Loss: 0.04484674334526062\n",
      "Epoch [18/50], Batch [20/168], Loss: 0.12512549757957458\n",
      "Epoch [18/50], Batch [30/168], Loss: 0.052513010799884796\n",
      "Epoch [18/50], Batch [40/168], Loss: 0.03334809094667435\n",
      "Epoch [18/50], Batch [50/168], Loss: 0.005482612177729607\n",
      "Epoch [18/50], Batch [60/168], Loss: 0.07380035519599915\n",
      "Epoch [18/50], Batch [70/168], Loss: 0.04102896898984909\n",
      "Epoch [18/50], Batch [80/168], Loss: 0.06760504841804504\n",
      "Epoch [18/50], Batch [90/168], Loss: 0.04272162914276123\n",
      "Epoch [18/50], Batch [100/168], Loss: 0.061276745051145554\n",
      "Epoch [18/50], Batch [110/168], Loss: 0.08653432130813599\n",
      "Epoch [18/50], Batch [120/168], Loss: 0.02380107156932354\n",
      "Epoch [18/50], Batch [130/168], Loss: 0.061747655272483826\n",
      "Epoch [18/50], Batch [140/168], Loss: 0.08810116350650787\n",
      "Epoch [18/50], Batch [150/168], Loss: 0.014063453301787376\n",
      "Epoch [18/50], Batch [160/168], Loss: 0.02016981691122055\n",
      "Epoch [18/50], Validation Loss: 0.06535882667045702\n",
      "Epoch [19/50], Batch [0/168], Loss: 0.04670663923025131\n",
      "Epoch [19/50], Batch [10/168], Loss: 0.04484287276864052\n",
      "Epoch [19/50], Batch [20/168], Loss: 0.1251194179058075\n",
      "Epoch [19/50], Batch [30/168], Loss: 0.052620209753513336\n",
      "Epoch [19/50], Batch [40/168], Loss: 0.033364370465278625\n",
      "Epoch [19/50], Batch [50/168], Loss: 0.0054727294482290745\n",
      "Epoch [19/50], Batch [60/168], Loss: 0.07358987629413605\n",
      "Epoch [19/50], Batch [70/168], Loss: 0.04101051762700081\n",
      "Epoch [19/50], Batch [80/168], Loss: 0.0675838366150856\n",
      "Epoch [19/50], Batch [90/168], Loss: 0.04273802042007446\n",
      "Epoch [19/50], Batch [100/168], Loss: 0.061276793479919434\n",
      "Epoch [19/50], Batch [110/168], Loss: 0.08654235303401947\n",
      "Epoch [19/50], Batch [120/168], Loss: 0.02379992976784706\n",
      "Epoch [19/50], Batch [130/168], Loss: 0.061762139201164246\n",
      "Epoch [19/50], Batch [140/168], Loss: 0.08811664581298828\n",
      "Epoch [19/50], Batch [150/168], Loss: 0.014064210467040539\n",
      "Epoch [19/50], Batch [160/168], Loss: 0.020169496536254883\n",
      "Epoch [19/50], Validation Loss: 0.0654791471971707\n",
      "Epoch [20/50], Batch [0/168], Loss: 0.046715471893548965\n",
      "Epoch [20/50], Batch [10/168], Loss: 0.044840257614851\n",
      "Epoch [20/50], Batch [20/168], Loss: 0.12511539459228516\n",
      "Epoch [20/50], Batch [30/168], Loss: 0.05272596329450607\n",
      "Epoch [20/50], Batch [40/168], Loss: 0.033384595066308975\n",
      "Epoch [20/50], Batch [50/168], Loss: 0.005461782682687044\n",
      "Epoch [20/50], Batch [60/168], Loss: 0.07338719815015793\n",
      "Epoch [20/50], Batch [70/168], Loss: 0.04103195667266846\n",
      "Epoch [20/50], Batch [80/168], Loss: 0.0675802230834961\n",
      "Epoch [20/50], Batch [90/168], Loss: 0.04275580123066902\n",
      "Epoch [20/50], Batch [100/168], Loss: 0.06127699092030525\n",
      "Epoch [20/50], Batch [110/168], Loss: 0.08655748516321182\n",
      "Epoch [20/50], Batch [120/168], Loss: 0.02380136027932167\n",
      "Epoch [20/50], Batch [130/168], Loss: 0.061777353286743164\n",
      "Epoch [20/50], Batch [140/168], Loss: 0.08813552558422089\n",
      "Epoch [20/50], Batch [150/168], Loss: 0.014065713621675968\n",
      "Epoch [20/50], Batch [160/168], Loss: 0.020169705152511597\n",
      "Epoch [20/50], Validation Loss: 0.0655835643580014\n",
      "Epoch [21/50], Batch [0/168], Loss: 0.0467267781496048\n",
      "Epoch [21/50], Batch [10/168], Loss: 0.04483870416879654\n",
      "Epoch [21/50], Batch [20/168], Loss: 0.12511233985424042\n",
      "Epoch [21/50], Batch [30/168], Loss: 0.05282735824584961\n",
      "Epoch [21/50], Batch [40/168], Loss: 0.03340830281376839\n",
      "Epoch [21/50], Batch [50/168], Loss: 0.005450598429888487\n",
      "Epoch [21/50], Batch [60/168], Loss: 0.07319627702236176\n",
      "Epoch [21/50], Batch [70/168], Loss: 0.041084110736846924\n",
      "Epoch [21/50], Batch [80/168], Loss: 0.06758815050125122\n",
      "Epoch [21/50], Batch [90/168], Loss: 0.042772822082042694\n",
      "Epoch [21/50], Batch [100/168], Loss: 0.0612773597240448\n",
      "Epoch [21/50], Batch [110/168], Loss: 0.0865788608789444\n",
      "Epoch [21/50], Batch [120/168], Loss: 0.02380526065826416\n",
      "Epoch [21/50], Batch [130/168], Loss: 0.061793237924575806\n",
      "Epoch [21/50], Batch [140/168], Loss: 0.08815790712833405\n",
      "Epoch [21/50], Batch [150/168], Loss: 0.014067926444113255\n",
      "Epoch [21/50], Batch [160/168], Loss: 0.02017039619386196\n",
      "Epoch [21/50], Validation Loss: 0.06566940864378756\n",
      "Epoch [22/50], Batch [0/168], Loss: 0.04674026370048523\n",
      "Epoch [22/50], Batch [10/168], Loss: 0.04483795911073685\n",
      "Epoch [22/50], Batch [20/168], Loss: 0.12510962784290314\n",
      "Epoch [22/50], Batch [30/168], Loss: 0.05292171612381935\n",
      "Epoch [22/50], Batch [40/168], Loss: 0.03343470022082329\n",
      "Epoch [22/50], Batch [50/168], Loss: 0.005440013017505407\n",
      "Epoch [22/50], Batch [60/168], Loss: 0.07302016764879227\n",
      "Epoch [22/50], Batch [70/168], Loss: 0.04115740582346916\n",
      "Epoch [22/50], Batch [80/168], Loss: 0.06760206818580627\n",
      "Epoch [22/50], Batch [90/168], Loss: 0.042787104845047\n",
      "Epoch [22/50], Batch [100/168], Loss: 0.06127794831991196\n",
      "Epoch [22/50], Batch [110/168], Loss: 0.08660496771335602\n",
      "Epoch [22/50], Batch [120/168], Loss: 0.023811286315321922\n",
      "Epoch [22/50], Batch [130/168], Loss: 0.06180949509143829\n",
      "Epoch [22/50], Batch [140/168], Loss: 0.0881834551692009\n",
      "Epoch [22/50], Batch [150/168], Loss: 0.01407073438167572\n",
      "Epoch [22/50], Batch [160/168], Loss: 0.020171571522951126\n",
      "Epoch [22/50], Validation Loss: 0.06573480277914892\n",
      "Epoch [23/50], Batch [0/168], Loss: 0.0467555969953537\n",
      "Epoch [23/50], Batch [10/168], Loss: 0.04483781009912491\n",
      "Epoch [23/50], Batch [20/168], Loss: 0.12510676681995392\n",
      "Epoch [23/50], Batch [30/168], Loss: 0.053007036447525024\n",
      "Epoch [23/50], Batch [40/168], Loss: 0.03346271440386772\n",
      "Epoch [23/50], Batch [50/168], Loss: 0.005430739372968674\n",
      "Epoch [23/50], Batch [60/168], Loss: 0.07286109775304794\n",
      "Epoch [23/50], Batch [70/168], Loss: 0.041242584586143494\n",
      "Epoch [23/50], Batch [80/168], Loss: 0.06761761754751205\n",
      "Epoch [23/50], Batch [90/168], Loss: 0.04279724881052971\n",
      "Epoch [23/50], Batch [100/168], Loss: 0.06127864494919777\n",
      "Epoch [23/50], Batch [110/168], Loss: 0.08663377165794373\n",
      "Epoch [23/50], Batch [120/168], Loss: 0.023818889632821083\n",
      "Epoch [23/50], Batch [130/168], Loss: 0.06182564049959183\n",
      "Epoch [23/50], Batch [140/168], Loss: 0.088211290538311\n",
      "Epoch [23/50], Batch [150/168], Loss: 0.014073972590267658\n",
      "Epoch [23/50], Batch [160/168], Loss: 0.02017323672771454\n",
      "Epoch [23/50], Validation Loss: 0.06577884990044615\n",
      "Epoch [24/50], Batch [0/168], Loss: 0.04677240177989006\n",
      "Epoch [24/50], Batch [10/168], Loss: 0.04483802616596222\n",
      "Epoch [24/50], Batch [20/168], Loss: 0.12510362267494202\n",
      "Epoch [24/50], Batch [30/168], Loss: 0.053081873804330826\n",
      "Epoch [24/50], Batch [40/168], Loss: 0.033491119742393494\n",
      "Epoch [24/50], Batch [50/168], Loss: 0.005423249676823616\n",
      "Epoch [24/50], Batch [60/168], Loss: 0.07272026687860489\n",
      "Epoch [24/50], Batch [70/168], Loss: 0.04133192449808121\n",
      "Epoch [24/50], Batch [80/168], Loss: 0.06763190031051636\n",
      "Epoch [24/50], Batch [90/168], Loss: 0.04280269518494606\n",
      "Epoch [24/50], Batch [100/168], Loss: 0.06127932667732239\n",
      "Epoch [24/50], Batch [110/168], Loss: 0.08666273951530457\n",
      "Epoch [24/50], Batch [120/168], Loss: 0.023827387019991875\n",
      "Epoch [24/50], Batch [130/168], Loss: 0.06184104457497597\n",
      "Epoch [24/50], Batch [140/168], Loss: 0.0882401317358017\n",
      "Epoch [24/50], Batch [150/168], Loss: 0.01407743338495493\n",
      "Epoch [24/50], Batch [160/168], Loss: 0.020175401121377945\n",
      "Epoch [24/50], Validation Loss: 0.06580220743675123\n",
      "Epoch [25/50], Batch [0/168], Loss: 0.04679007828235626\n",
      "Epoch [25/50], Batch [10/168], Loss: 0.04483843967318535\n",
      "Epoch [25/50], Batch [20/168], Loss: 0.12509991228580475\n",
      "Epoch [25/50], Batch [30/168], Loss: 0.05314512923359871\n",
      "Epoch [25/50], Batch [40/168], Loss: 0.033518627285957336\n",
      "Epoch [25/50], Batch [50/168], Loss: 0.0054177273996174335\n",
      "Epoch [25/50], Batch [60/168], Loss: 0.07259775698184967\n",
      "Epoch [25/50], Batch [70/168], Loss: 0.0414196141064167\n",
      "Epoch [25/50], Batch [80/168], Loss: 0.06764353811740875\n",
      "Epoch [25/50], Batch [90/168], Loss: 0.042803727090358734\n",
      "Epoch [25/50], Batch [100/168], Loss: 0.06127987802028656\n",
      "Epoch [25/50], Batch [110/168], Loss: 0.0866895392537117\n",
      "Epoch [25/50], Batch [120/168], Loss: 0.02383607067167759\n",
      "Epoch [25/50], Batch [130/168], Loss: 0.061855170875787735\n",
      "Epoch [25/50], Batch [140/168], Loss: 0.08826836943626404\n",
      "Epoch [25/50], Batch [150/168], Loss: 0.014080896973609924\n",
      "Epoch [25/50], Batch [160/168], Loss: 0.020178060978651047\n",
      "Epoch [25/50], Validation Loss: 0.06580717053941705\n",
      "Epoch [26/50], Batch [0/168], Loss: 0.04680785909295082\n",
      "Epoch [26/50], Batch [10/168], Loss: 0.04483887925744057\n",
      "Epoch [26/50], Batch [20/168], Loss: 0.12509526312351227\n",
      "Epoch [26/50], Batch [30/168], Loss: 0.053196247667074203\n",
      "Epoch [26/50], Batch [40/168], Loss: 0.0335441529750824\n",
      "Epoch [26/50], Batch [50/168], Loss: 0.005414081737399101\n",
      "Epoch [26/50], Batch [60/168], Loss: 0.07249287515878677\n",
      "Epoch [26/50], Batch [70/168], Loss: 0.041502099484205246\n",
      "Epoch [26/50], Batch [80/168], Loss: 0.06765224784612656\n",
      "Epoch [26/50], Batch [90/168], Loss: 0.04280123859643936\n",
      "Epoch [26/50], Batch [100/168], Loss: 0.061280202120542526\n",
      "Epoch [26/50], Batch [110/168], Loss: 0.0867122933268547\n",
      "Epoch [26/50], Batch [120/168], Loss: 0.023844335228204727\n",
      "Epoch [26/50], Batch [130/168], Loss: 0.061867617070674896\n",
      "Epoch [26/50], Batch [140/168], Loss: 0.08829452097415924\n",
      "Epoch [26/50], Batch [150/168], Loss: 0.014084146358072758\n",
      "Epoch [26/50], Batch [160/168], Loss: 0.020181171596050262\n",
      "Epoch [26/50], Validation Loss: 0.06579701444980773\n",
      "Epoch [27/50], Batch [0/168], Loss: 0.04682484269142151\n",
      "Epoch [27/50], Batch [10/168], Loss: 0.04483924061059952\n",
      "Epoch [27/50], Batch [20/168], Loss: 0.1250893920660019\n",
      "Epoch [27/50], Batch [30/168], Loss: 0.05323507636785507\n",
      "Epoch [27/50], Batch [40/168], Loss: 0.03356686607003212\n",
      "Epoch [27/50], Batch [50/168], Loss: 0.00541202537715435\n",
      "Epoch [27/50], Batch [60/168], Loss: 0.07240402698516846\n",
      "Epoch [27/50], Batch [70/168], Loss: 0.04157796502113342\n",
      "Epoch [27/50], Batch [80/168], Loss: 0.06765840202569962\n",
      "Epoch [27/50], Batch [90/168], Loss: 0.042796358466148376\n",
      "Epoch [27/50], Batch [100/168], Loss: 0.061280298978090286\n",
      "Epoch [27/50], Batch [110/168], Loss: 0.08672994375228882\n",
      "Epoch [27/50], Batch [120/168], Loss: 0.02385174110531807\n",
      "Epoch [27/50], Batch [130/168], Loss: 0.0618782714009285\n",
      "Epoch [27/50], Batch [140/168], Loss: 0.08831734955310822\n",
      "Epoch [27/50], Batch [150/168], Loss: 0.01408703438937664\n",
      "Epoch [27/50], Batch [160/168], Loss: 0.020184684544801712\n",
      "Epoch [27/50], Validation Loss: 0.06577619876373898\n",
      "Epoch [28/50], Batch [0/168], Loss: 0.04684009775519371\n",
      "Epoch [28/50], Batch [10/168], Loss: 0.04483941197395325\n",
      "Epoch [28/50], Batch [20/168], Loss: 0.1250815987586975\n",
      "Epoch [28/50], Batch [30/168], Loss: 0.05326167121529579\n",
      "Epoch [28/50], Batch [40/168], Loss: 0.03358618542551994\n",
      "Epoch [28/50], Batch [50/168], Loss: 0.005411171820014715\n",
      "Epoch [28/50], Batch [60/168], Loss: 0.07232929766178131\n",
      "Epoch [28/50], Batch [70/168], Loss: 0.04164706915616989\n",
      "Epoch [28/50], Batch [80/168], Loss: 0.06766269356012344\n",
      "Epoch [28/50], Batch [90/168], Loss: 0.04279019311070442\n",
      "Epoch [28/50], Batch [100/168], Loss: 0.061280183494091034\n",
      "Epoch [28/50], Batch [110/168], Loss: 0.08674227446317673\n",
      "Epoch [28/50], Batch [120/168], Loss: 0.023858070373535156\n",
      "Epoch [28/50], Batch [130/168], Loss: 0.061887189745903015\n",
      "Epoch [28/50], Batch [140/168], Loss: 0.08833620697259903\n",
      "Epoch [28/50], Batch [150/168], Loss: 0.014089475385844707\n",
      "Epoch [28/50], Batch [160/168], Loss: 0.02018853835761547\n",
      "Epoch [28/50], Validation Loss: 0.0657495415346189\n",
      "Epoch [29/50], Batch [0/168], Loss: 0.04685277119278908\n",
      "Epoch [29/50], Batch [10/168], Loss: 0.04483935609459877\n",
      "Epoch [29/50], Batch [20/168], Loss: 0.1250714659690857\n",
      "Epoch [29/50], Batch [30/168], Loss: 0.05327653884887695\n",
      "Epoch [29/50], Batch [40/168], Loss: 0.033601902425289154\n",
      "Epoch [29/50], Batch [50/168], Loss: 0.005411128513514996\n",
      "Epoch [29/50], Batch [60/168], Loss: 0.07226651161909103\n",
      "Epoch [29/50], Batch [70/168], Loss: 0.04171016067266464\n",
      "Epoch [29/50], Batch [80/168], Loss: 0.06766581535339355\n",
      "Epoch [29/50], Batch [90/168], Loss: 0.04278359189629555\n",
      "Epoch [29/50], Batch [100/168], Loss: 0.06127991899847984\n",
      "Epoch [29/50], Batch [110/168], Loss: 0.08674968034029007\n",
      "Epoch [29/50], Batch [120/168], Loss: 0.023863263428211212\n",
      "Epoch [29/50], Batch [130/168], Loss: 0.06189458817243576\n",
      "Epoch [29/50], Batch [140/168], Loss: 0.088350810110569\n",
      "Epoch [29/50], Batch [150/168], Loss: 0.014091437682509422\n",
      "Epoch [29/50], Batch [160/168], Loss: 0.020192667841911316\n",
      "Epoch [29/50], Validation Loss: 0.06572106814181262\n",
      "Epoch [30/50], Batch [0/168], Loss: 0.04686223715543747\n",
      "Epoch [30/50], Batch [10/168], Loss: 0.044839099049568176\n",
      "Epoch [30/50], Batch [20/168], Loss: 0.12505868077278137\n",
      "Epoch [30/50], Batch [30/168], Loss: 0.05328059196472168\n",
      "Epoch [30/50], Batch [40/168], Loss: 0.03361405432224274\n",
      "Epoch [30/50], Batch [50/168], Loss: 0.005411557387560606\n",
      "Epoch [30/50], Batch [60/168], Loss: 0.07221350818872452\n",
      "Epoch [30/50], Batch [70/168], Loss: 0.04176836833357811\n",
      "Epoch [30/50], Batch [80/168], Loss: 0.06766832619905472\n",
      "Epoch [30/50], Batch [90/168], Loss: 0.04277712106704712\n",
      "Epoch [30/50], Batch [100/168], Loss: 0.06127956509590149\n",
      "Epoch [30/50], Batch [110/168], Loss: 0.08675297349691391\n",
      "Epoch [30/50], Batch [120/168], Loss: 0.023867402225732803\n",
      "Epoch [30/50], Batch [130/168], Loss: 0.061900731176137924\n",
      "Epoch [30/50], Batch [140/168], Loss: 0.08836125582456589\n",
      "Epoch [30/50], Batch [150/168], Loss: 0.014092959463596344\n",
      "Epoch [30/50], Batch [160/168], Loss: 0.020197013393044472\n",
      "Epoch [30/50], Validation Loss: 0.06569446123797786\n",
      "Epoch [31/50], Batch [0/168], Loss: 0.04686808958649635\n",
      "Epoch [31/50], Batch [10/168], Loss: 0.04483870416879654\n",
      "Epoch [31/50], Batch [20/168], Loss: 0.1250430792570114\n",
      "Epoch [31/50], Batch [30/168], Loss: 0.05327480658888817\n",
      "Epoch [31/50], Batch [40/168], Loss: 0.033622872084379196\n",
      "Epoch [31/50], Batch [50/168], Loss: 0.0054122027941048145\n",
      "Epoch [31/50], Batch [60/168], Loss: 0.07216838747262955\n",
      "Epoch [31/50], Batch [70/168], Loss: 0.04182277247309685\n",
      "Epoch [31/50], Batch [80/168], Loss: 0.06767061352729797\n",
      "Epoch [31/50], Batch [90/168], Loss: 0.0427711047232151\n",
      "Epoch [31/50], Batch [100/168], Loss: 0.06127918139100075\n",
      "Epoch [31/50], Batch [110/168], Loss: 0.08675306290388107\n",
      "Epoch [31/50], Batch [120/168], Loss: 0.023870637640357018\n",
      "Epoch [31/50], Batch [130/168], Loss: 0.0619058795273304\n",
      "Epoch [31/50], Batch [140/168], Loss: 0.08836792409420013\n",
      "Epoch [31/50], Batch [150/168], Loss: 0.014094087295234203\n",
      "Epoch [31/50], Batch [160/168], Loss: 0.02020150236785412\n",
      "Epoch [31/50], Validation Loss: 0.0656720817597075\n",
      "Epoch [32/50], Batch [0/168], Loss: 0.04687024652957916\n",
      "Epoch [32/50], Batch [10/168], Loss: 0.044838275760412216\n",
      "Epoch [32/50], Batch [20/168], Loss: 0.1250247061252594\n",
      "Epoch [32/50], Batch [30/168], Loss: 0.05326029285788536\n",
      "Epoch [32/50], Batch [40/168], Loss: 0.0336286798119545\n",
      "Epoch [32/50], Batch [50/168], Loss: 0.005412890575826168\n",
      "Epoch [32/50], Batch [60/168], Loss: 0.07212940603494644\n",
      "Epoch [32/50], Batch [70/168], Loss: 0.04187446087598801\n",
      "Epoch [32/50], Batch [80/168], Loss: 0.06767288595438004\n",
      "Epoch [32/50], Batch [90/168], Loss: 0.04276565834879875\n",
      "Epoch [32/50], Batch [100/168], Loss: 0.0612788051366806\n",
      "Epoch [32/50], Batch [110/168], Loss: 0.08675075322389603\n",
      "Epoch [32/50], Batch [120/168], Loss: 0.023873133584856987\n",
      "Epoch [32/50], Batch [130/168], Loss: 0.0619102381169796\n",
      "Epoch [32/50], Batch [140/168], Loss: 0.08837126195430756\n",
      "Epoch [32/50], Batch [150/168], Loss: 0.014094864018261433\n",
      "Epoch [32/50], Batch [160/168], Loss: 0.02020609937608242\n",
      "Epoch [32/50], Validation Loss: 0.06565562232651494\n",
      "Epoch [33/50], Batch [0/168], Loss: 0.04686878249049187\n",
      "Epoch [33/50], Batch [10/168], Loss: 0.04483793303370476\n",
      "Epoch [33/50], Batch [20/168], Loss: 0.12500376999378204\n",
      "Epoch [33/50], Batch [30/168], Loss: 0.05323825404047966\n",
      "Epoch [33/50], Batch [40/168], Loss: 0.03363189846277237\n",
      "Epoch [33/50], Batch [50/168], Loss: 0.005413518752902746\n",
      "Epoch [33/50], Batch [60/168], Loss: 0.07209519296884537\n",
      "Epoch [33/50], Batch [70/168], Loss: 0.04192439839243889\n",
      "Epoch [33/50], Batch [80/168], Loss: 0.06767527759075165\n",
      "Epoch [33/50], Batch [90/168], Loss: 0.04276079684495926\n",
      "Epoch [33/50], Batch [100/168], Loss: 0.061278440058231354\n",
      "Epoch [33/50], Batch [110/168], Loss: 0.08674682676792145\n",
      "Epoch [33/50], Batch [120/168], Loss: 0.023875048384070396\n",
      "Epoch [33/50], Batch [130/168], Loss: 0.06191403046250343\n",
      "Epoch [33/50], Batch [140/168], Loss: 0.08837181329727173\n",
      "Epoch [33/50], Batch [150/168], Loss: 0.014095360413193703\n",
      "Epoch [33/50], Batch [160/168], Loss: 0.020210759714245796\n",
      "Epoch [33/50], Validation Loss: 0.06564572536471215\n",
      "Epoch [34/50], Batch [0/168], Loss: 0.04686398804187775\n",
      "Epoch [34/50], Batch [10/168], Loss: 0.04483780264854431\n",
      "Epoch [34/50], Batch [20/168], Loss: 0.12498054653406143\n",
      "Epoch [34/50], Batch [30/168], Loss: 0.053209759294986725\n",
      "Epoch [34/50], Batch [40/168], Loss: 0.033632971346378326\n",
      "Epoch [34/50], Batch [50/168], Loss: 0.005414037965238094\n",
      "Epoch [34/50], Batch [60/168], Loss: 0.07206464558839798\n",
      "Epoch [34/50], Batch [70/168], Loss: 0.041973140090703964\n",
      "Epoch [34/50], Batch [80/168], Loss: 0.06767784059047699\n",
      "Epoch [34/50], Batch [90/168], Loss: 0.04275648668408394\n",
      "Epoch [34/50], Batch [100/168], Loss: 0.06127811595797539\n",
      "Epoch [34/50], Batch [110/168], Loss: 0.08674193918704987\n",
      "Epoch [34/50], Batch [120/168], Loss: 0.023876555263996124\n",
      "Epoch [34/50], Batch [130/168], Loss: 0.06191738694906235\n",
      "Epoch [34/50], Batch [140/168], Loss: 0.08837004005908966\n",
      "Epoch [34/50], Batch [150/168], Loss: 0.014095637947320938\n",
      "Epoch [34/50], Batch [160/168], Loss: 0.02021545171737671\n",
      "Epoch [34/50], Validation Loss: 0.06564295171675356\n",
      "Epoch [35/50], Batch [0/168], Loss: 0.046856191009283066\n",
      "Epoch [35/50], Batch [10/168], Loss: 0.044837988913059235\n",
      "Epoch [35/50], Batch [20/168], Loss: 0.12495548278093338\n",
      "Epoch [35/50], Batch [30/168], Loss: 0.05317583680152893\n",
      "Epoch [35/50], Batch [40/168], Loss: 0.03363228589296341\n",
      "Epoch [35/50], Batch [50/168], Loss: 0.005414431449025869\n",
      "Epoch [35/50], Batch [60/168], Loss: 0.072036974132061\n",
      "Epoch [35/50], Batch [70/168], Loss: 0.042021509259939194\n",
      "Epoch [35/50], Batch [80/168], Loss: 0.06768055260181427\n",
      "Epoch [35/50], Batch [90/168], Loss: 0.042752642184495926\n",
      "Epoch [35/50], Batch [100/168], Loss: 0.06127782538533211\n",
      "Epoch [35/50], Batch [110/168], Loss: 0.0867365300655365\n",
      "Epoch [35/50], Batch [120/168], Loss: 0.023877760395407677\n",
      "Epoch [35/50], Batch [130/168], Loss: 0.06192038953304291\n",
      "Epoch [35/50], Batch [140/168], Loss: 0.08836640417575836\n",
      "Epoch [35/50], Batch [150/168], Loss: 0.014095718041062355\n",
      "Epoch [35/50], Batch [160/168], Loss: 0.020220134407281876\n",
      "Epoch [35/50], Validation Loss: 0.06564684195274656\n",
      "Epoch [36/50], Batch [0/168], Loss: 0.046845871955156326\n",
      "Epoch [36/50], Batch [10/168], Loss: 0.044838566333055496\n",
      "Epoch [36/50], Batch [20/168], Loss: 0.12492892891168594\n",
      "Epoch [36/50], Batch [30/168], Loss: 0.053137414157390594\n",
      "Epoch [36/50], Batch [40/168], Loss: 0.033630236983299255\n",
      "Epoch [36/50], Batch [50/168], Loss: 0.0054147024638950825\n",
      "Epoch [36/50], Batch [60/168], Loss: 0.0720115527510643\n",
      "Epoch [36/50], Batch [70/168], Loss: 0.0420696921646595\n",
      "Epoch [36/50], Batch [80/168], Loss: 0.0676833987236023\n",
      "Epoch [36/50], Batch [90/168], Loss: 0.042749181389808655\n",
      "Epoch [36/50], Batch [100/168], Loss: 0.061277586966753006\n",
      "Epoch [36/50], Batch [110/168], Loss: 0.08673095703125\n",
      "Epoch [36/50], Batch [120/168], Loss: 0.023878782987594604\n",
      "Epoch [36/50], Batch [130/168], Loss: 0.06192311644554138\n",
      "Epoch [36/50], Batch [140/168], Loss: 0.08836132287979126\n",
      "Epoch [36/50], Batch [150/168], Loss: 0.014095652848482132\n",
      "Epoch [36/50], Batch [160/168], Loss: 0.02022477798163891\n",
      "Epoch [36/50], Validation Loss: 0.06565743561156771\n",
      "Epoch [37/50], Batch [0/168], Loss: 0.046833451837301254\n",
      "Epoch [37/50], Batch [10/168], Loss: 0.04483959078788757\n",
      "Epoch [37/50], Batch [20/168], Loss: 0.12490136921405792\n",
      "Epoch [37/50], Batch [30/168], Loss: 0.05309534817934036\n",
      "Epoch [37/50], Batch [40/168], Loss: 0.03362713009119034\n",
      "Epoch [37/50], Batch [50/168], Loss: 0.005414863117039204\n",
      "Epoch [37/50], Batch [60/168], Loss: 0.07198799401521683\n",
      "Epoch [37/50], Batch [70/168], Loss: 0.04211781546473503\n",
      "Epoch [37/50], Batch [80/168], Loss: 0.06768632680177689\n",
      "Epoch [37/50], Batch [90/168], Loss: 0.04274603724479675\n",
      "Epoch [37/50], Batch [100/168], Loss: 0.061277374625205994\n",
      "Epoch [37/50], Batch [110/168], Loss: 0.08672545850276947\n",
      "Epoch [37/50], Batch [120/168], Loss: 0.02387968637049198\n",
      "Epoch [37/50], Batch [130/168], Loss: 0.061925552785396576\n",
      "Epoch [37/50], Batch [140/168], Loss: 0.08835509419441223\n",
      "Epoch [37/50], Batch [150/168], Loss: 0.014095457270741463\n",
      "Epoch [37/50], Batch [160/168], Loss: 0.020229339599609375\n",
      "Epoch [37/50], Validation Loss: 0.06567400272258303\n",
      "Epoch [38/50], Batch [0/168], Loss: 0.046819448471069336\n",
      "Epoch [38/50], Batch [10/168], Loss: 0.04484109953045845\n",
      "Epoch [38/50], Batch [20/168], Loss: 0.12487321346998215\n",
      "Epoch [38/50], Batch [30/168], Loss: 0.05305040627717972\n",
      "Epoch [38/50], Batch [40/168], Loss: 0.03362323343753815\n",
      "Epoch [38/50], Batch [50/168], Loss: 0.005414929706603289\n",
      "Epoch [38/50], Batch [60/168], Loss: 0.07196604460477829\n",
      "Epoch [38/50], Batch [70/168], Loss: 0.04216599091887474\n",
      "Epoch [38/50], Batch [80/168], Loss: 0.06768932193517685\n",
      "Epoch [38/50], Batch [90/168], Loss: 0.04274315759539604\n",
      "Epoch [38/50], Batch [100/168], Loss: 0.06127720698714256\n",
      "Epoch [38/50], Batch [110/168], Loss: 0.08672026544809341\n",
      "Epoch [38/50], Batch [120/168], Loss: 0.023880504071712494\n",
      "Epoch [38/50], Batch [130/168], Loss: 0.06192772462964058\n",
      "Epoch [38/50], Batch [140/168], Loss: 0.08834803849458694\n",
      "Epoch [38/50], Batch [150/168], Loss: 0.014095156453549862\n",
      "Epoch [38/50], Batch [160/168], Loss: 0.020233774557709694\n",
      "Epoch [38/50], Validation Loss: 0.0656961006874388\n",
      "Epoch [39/50], Batch [0/168], Loss: 0.046804316341876984\n",
      "Epoch [39/50], Batch [10/168], Loss: 0.044843096286058426\n",
      "Epoch [39/50], Batch [20/168], Loss: 0.12484488636255264\n",
      "Epoch [39/50], Batch [30/168], Loss: 0.053003229200839996\n",
      "Epoch [39/50], Batch [40/168], Loss: 0.03361876681447029\n",
      "Epoch [39/50], Batch [50/168], Loss: 0.005414915271103382\n",
      "Epoch [39/50], Batch [60/168], Loss: 0.07194563001394272\n",
      "Epoch [39/50], Batch [70/168], Loss: 0.04221381992101669\n",
      "Epoch [39/50], Batch [80/168], Loss: 0.0676923394203186\n",
      "Epoch [39/50], Batch [90/168], Loss: 0.042740482836961746\n",
      "Epoch [39/50], Batch [100/168], Loss: 0.06127706170082092\n",
      "Epoch [39/50], Batch [110/168], Loss: 0.0867154523730278\n",
      "Epoch [39/50], Batch [120/168], Loss: 0.023881280794739723\n",
      "Epoch [39/50], Batch [130/168], Loss: 0.06192957982420921\n",
      "Epoch [39/50], Batch [140/168], Loss: 0.08834036439657211\n",
      "Epoch [39/50], Batch [150/168], Loss: 0.01409476064145565\n",
      "Epoch [39/50], Batch [160/168], Loss: 0.020238013938069344\n",
      "Epoch [39/50], Validation Loss: 0.06572292013601823\n",
      "Epoch [40/50], Batch [0/168], Loss: 0.046788547188043594\n",
      "Epoch [40/50], Batch [10/168], Loss: 0.04484552890062332\n",
      "Epoch [40/50], Batch [20/168], Loss: 0.12481673806905746\n",
      "Epoch [40/50], Batch [30/168], Loss: 0.05295472592115402\n",
      "Epoch [40/50], Batch [40/168], Loss: 0.033613935112953186\n",
      "Epoch [40/50], Batch [50/168], Loss: 0.00541483610868454\n",
      "Epoch [40/50], Batch [60/168], Loss: 0.07192665338516235\n",
      "Epoch [40/50], Batch [70/168], Loss: 0.042260970920324326\n",
      "Epoch [40/50], Batch [80/168], Loss: 0.06769534200429916\n",
      "Epoch [40/50], Batch [90/168], Loss: 0.042737968266010284\n",
      "Epoch [40/50], Batch [100/168], Loss: 0.06127695366740227\n",
      "Epoch [40/50], Batch [110/168], Loss: 0.08671112358570099\n",
      "Epoch [40/50], Batch [120/168], Loss: 0.023882007226347923\n",
      "Epoch [40/50], Batch [130/168], Loss: 0.06193108856678009\n",
      "Epoch [40/50], Batch [140/168], Loss: 0.08833233267068863\n",
      "Epoch [40/50], Batch [150/168], Loss: 0.014094270765781403\n",
      "Epoch [40/50], Batch [160/168], Loss: 0.020241981372237206\n",
      "Epoch [40/50], Validation Loss: 0.06575365516949784\n",
      "Epoch [41/50], Batch [0/168], Loss: 0.04677257314324379\n",
      "Epoch [41/50], Batch [10/168], Loss: 0.04484836012125015\n",
      "Epoch [41/50], Batch [20/168], Loss: 0.12478922307491302\n",
      "Epoch [41/50], Batch [30/168], Loss: 0.05290543660521507\n",
      "Epoch [41/50], Batch [40/168], Loss: 0.03360887989401817\n",
      "Epoch [41/50], Batch [50/168], Loss: 0.005414705723524094\n",
      "Epoch [41/50], Batch [60/168], Loss: 0.07190919667482376\n",
      "Epoch [41/50], Batch [70/168], Loss: 0.04230674356222153\n",
      "Epoch [41/50], Batch [80/168], Loss: 0.06769835203886032\n",
      "Epoch [41/50], Batch [90/168], Loss: 0.04273563623428345\n",
      "Epoch [41/50], Batch [100/168], Loss: 0.061276860535144806\n",
      "Epoch [41/50], Batch [110/168], Loss: 0.08670732378959656\n",
      "Epoch [41/50], Batch [120/168], Loss: 0.023882662877440453\n",
      "Epoch [41/50], Batch [130/168], Loss: 0.061932191252708435\n",
      "Epoch [41/50], Batch [140/168], Loss: 0.08832406252622604\n",
      "Epoch [41/50], Batch [150/168], Loss: 0.014093668200075626\n",
      "Epoch [41/50], Batch [160/168], Loss: 0.020245598629117012\n",
      "Epoch [41/50], Validation Loss: 0.06578749418258667\n",
      "Epoch [42/50], Batch [0/168], Loss: 0.04675682634115219\n",
      "Epoch [42/50], Batch [10/168], Loss: 0.044851504266262054\n",
      "Epoch [42/50], Batch [20/168], Loss: 0.12476254254579544\n",
      "Epoch [42/50], Batch [30/168], Loss: 0.05285618081688881\n",
      "Epoch [42/50], Batch [40/168], Loss: 0.033603716641664505\n",
      "Epoch [42/50], Batch [50/168], Loss: 0.005414528306573629\n",
      "Epoch [42/50], Batch [60/168], Loss: 0.07189328223466873\n",
      "Epoch [42/50], Batch [70/168], Loss: 0.04235031083226204\n",
      "Epoch [42/50], Batch [80/168], Loss: 0.06770136207342148\n",
      "Epoch [42/50], Batch [90/168], Loss: 0.04273344948887825\n",
      "Epoch [42/50], Batch [100/168], Loss: 0.06127680093050003\n",
      "Epoch [42/50], Batch [110/168], Loss: 0.0867040753364563\n",
      "Epoch [42/50], Batch [120/168], Loss: 0.02388322539627552\n",
      "Epoch [42/50], Batch [130/168], Loss: 0.06193282827734947\n",
      "Epoch [42/50], Batch [140/168], Loss: 0.0883156955242157\n",
      "Epoch [42/50], Batch [150/168], Loss: 0.014092947356402874\n",
      "Epoch [42/50], Batch [160/168], Loss: 0.020248781889677048\n",
      "Epoch [42/50], Validation Loss: 0.06582373826002533\n",
      "Epoch [43/50], Batch [0/168], Loss: 0.04674163833260536\n",
      "Epoch [43/50], Batch [10/168], Loss: 0.04485484957695007\n",
      "Epoch [43/50], Batch [20/168], Loss: 0.12473700195550919\n",
      "Epoch [43/50], Batch [30/168], Loss: 0.052807532250881195\n",
      "Epoch [43/50], Batch [40/168], Loss: 0.03359857201576233\n",
      "Epoch [43/50], Batch [50/168], Loss: 0.005414319224655628\n",
      "Epoch [43/50], Batch [60/168], Loss: 0.07187902927398682\n",
      "Epoch [43/50], Batch [70/168], Loss: 0.04239094257354736\n",
      "Epoch [43/50], Batch [80/168], Loss: 0.06770441681146622\n",
      "Epoch [43/50], Batch [90/168], Loss: 0.04273142293095589\n",
      "Epoch [43/50], Batch [100/168], Loss: 0.061276745051145554\n",
      "Epoch [43/50], Batch [110/168], Loss: 0.08670132607221603\n",
      "Epoch [43/50], Batch [120/168], Loss: 0.0238836407661438\n",
      "Epoch [43/50], Batch [130/168], Loss: 0.06193295121192932\n",
      "Epoch [43/50], Batch [140/168], Loss: 0.08830730617046356\n",
      "Epoch [43/50], Batch [150/168], Loss: 0.014092054218053818\n",
      "Epoch [43/50], Batch [160/168], Loss: 0.02025144174695015\n",
      "Epoch [43/50], Validation Loss: 0.06586144796826622\n",
      "Epoch [44/50], Batch [0/168], Loss: 0.04672729969024658\n",
      "Epoch [44/50], Batch [10/168], Loss: 0.04485830292105675\n",
      "Epoch [44/50], Batch [20/168], Loss: 0.12471282482147217\n",
      "Epoch [44/50], Batch [30/168], Loss: 0.05276024341583252\n",
      "Epoch [44/50], Batch [40/168], Loss: 0.03359353169798851\n",
      "Epoch [44/50], Batch [50/168], Loss: 0.0054140822030603886\n",
      "Epoch [44/50], Batch [60/168], Loss: 0.07186641544103622\n",
      "Epoch [44/50], Batch [70/168], Loss: 0.042427755892276764\n",
      "Epoch [44/50], Batch [80/168], Loss: 0.06770756840705872\n",
      "Epoch [44/50], Batch [90/168], Loss: 0.042729564011096954\n",
      "Epoch [44/50], Batch [100/168], Loss: 0.061276715248823166\n",
      "Epoch [44/50], Batch [110/168], Loss: 0.0866989716887474\n",
      "Epoch [44/50], Batch [120/168], Loss: 0.02388387732207775\n",
      "Epoch [44/50], Batch [130/168], Loss: 0.06193256750702858\n",
      "Epoch [44/50], Batch [140/168], Loss: 0.0882989764213562\n",
      "Epoch [44/50], Batch [150/168], Loss: 0.014090978540480137\n",
      "Epoch [44/50], Batch [160/168], Loss: 0.020253509283065796\n",
      "Epoch [44/50], Validation Loss: 0.06589989631690762\n",
      "Epoch [45/50], Batch [0/168], Loss: 0.046714022755622864\n",
      "Epoch [45/50], Batch [10/168], Loss: 0.044861726462841034\n",
      "Epoch [45/50], Batch [20/168], Loss: 0.12469010800123215\n",
      "Epoch [45/50], Batch [30/168], Loss: 0.05271482840180397\n",
      "Epoch [45/50], Batch [40/168], Loss: 0.03358864411711693\n",
      "Epoch [45/50], Batch [50/168], Loss: 0.005413828417658806\n",
      "Epoch [45/50], Batch [60/168], Loss: 0.07185548543930054\n",
      "Epoch [45/50], Batch [70/168], Loss: 0.04246002063155174\n",
      "Epoch [45/50], Batch [80/168], Loss: 0.06771091371774673\n",
      "Epoch [45/50], Batch [90/168], Loss: 0.04272788017988205\n",
      "Epoch [45/50], Batch [100/168], Loss: 0.06127668544650078\n",
      "Epoch [45/50], Batch [110/168], Loss: 0.08669708669185638\n",
      "Epoch [45/50], Batch [120/168], Loss: 0.02388390153646469\n",
      "Epoch [45/50], Batch [130/168], Loss: 0.06193162500858307\n",
      "Epoch [45/50], Batch [140/168], Loss: 0.08829078823328018\n",
      "Epoch [45/50], Batch [150/168], Loss: 0.014089697040617466\n",
      "Epoch [45/50], Batch [160/168], Loss: 0.02025495283305645\n",
      "Epoch [45/50], Validation Loss: 0.06593900148502806\n",
      "Epoch [46/50], Batch [0/168], Loss: 0.046701885759830475\n",
      "Epoch [46/50], Batch [10/168], Loss: 0.04486500844359398\n",
      "Epoch [46/50], Batch [20/168], Loss: 0.12466885894536972\n",
      "Epoch [46/50], Batch [30/168], Loss: 0.05267166718840599\n",
      "Epoch [46/50], Batch [40/168], Loss: 0.03358390927314758\n",
      "Epoch [46/50], Batch [50/168], Loss: 0.005413564387708902\n",
      "Epoch [46/50], Batch [60/168], Loss: 0.07184620946645737\n",
      "Epoch [46/50], Batch [70/168], Loss: 0.042486850172281265\n",
      "Epoch [46/50], Batch [80/168], Loss: 0.06771454215049744\n",
      "Epoch [46/50], Batch [90/168], Loss: 0.04272637516260147\n",
      "Epoch [46/50], Batch [100/168], Loss: 0.061276670545339584\n",
      "Epoch [46/50], Batch [110/168], Loss: 0.08669544011354446\n",
      "Epoch [46/50], Batch [120/168], Loss: 0.023883672431111336\n",
      "Epoch [46/50], Batch [130/168], Loss: 0.06193017587065697\n",
      "Epoch [46/50], Batch [140/168], Loss: 0.08828272670507431\n",
      "Epoch [46/50], Batch [150/168], Loss: 0.014088178984820843\n",
      "Epoch [46/50], Batch [160/168], Loss: 0.02025577239692211\n",
      "Epoch [46/50], Validation Loss: 0.06597853612832048\n",
      "Epoch [47/50], Batch [0/168], Loss: 0.04669089987874031\n",
      "Epoch [47/50], Batch [10/168], Loss: 0.044868048280477524\n",
      "Epoch [47/50], Batch [20/168], Loss: 0.1246490627527237\n",
      "Epoch [47/50], Batch [30/168], Loss: 0.0526309534907341\n",
      "Epoch [47/50], Batch [40/168], Loss: 0.033579349517822266\n",
      "Epoch [47/50], Batch [50/168], Loss: 0.00541329849511385\n",
      "Epoch [47/50], Batch [60/168], Loss: 0.07183848321437836\n",
      "Epoch [47/50], Batch [70/168], Loss: 0.042507924139499664\n",
      "Epoch [47/50], Batch [80/168], Loss: 0.06771848350763321\n",
      "Epoch [47/50], Batch [90/168], Loss: 0.04272504150867462\n",
      "Epoch [47/50], Batch [100/168], Loss: 0.06127665564417839\n",
      "Epoch [47/50], Batch [110/168], Loss: 0.08669396489858627\n",
      "Epoch [47/50], Batch [120/168], Loss: 0.023883169516921043\n",
      "Epoch [47/50], Batch [130/168], Loss: 0.061928171664476395\n",
      "Epoch [47/50], Batch [140/168], Loss: 0.08827482908964157\n",
      "Epoch [47/50], Batch [150/168], Loss: 0.01408641692250967\n",
      "Epoch [47/50], Batch [160/168], Loss: 0.020255979150533676\n",
      "Epoch [47/50], Validation Loss: 0.06601811273192817\n",
      "Epoch [48/50], Batch [0/168], Loss: 0.04668109491467476\n",
      "Epoch [48/50], Batch [10/168], Loss: 0.04487074539065361\n",
      "Epoch [48/50], Batch [20/168], Loss: 0.1246306523680687\n",
      "Epoch [48/50], Batch [30/168], Loss: 0.05259297043085098\n",
      "Epoch [48/50], Batch [40/168], Loss: 0.033574968576431274\n",
      "Epoch [48/50], Batch [50/168], Loss: 0.0054130395874381065\n",
      "Epoch [48/50], Batch [60/168], Loss: 0.07183215767145157\n",
      "Epoch [48/50], Batch [70/168], Loss: 0.042523350566625595\n",
      "Epoch [48/50], Batch [80/168], Loss: 0.06772281229496002\n",
      "Epoch [48/50], Batch [90/168], Loss: 0.04272385686635971\n",
      "Epoch [48/50], Batch [100/168], Loss: 0.061276648193597794\n",
      "Epoch [48/50], Batch [110/168], Loss: 0.08669251948595047\n",
      "Epoch [48/50], Batch [120/168], Loss: 0.023882372304797173\n",
      "Epoch [48/50], Batch [130/168], Loss: 0.061925679445266724\n",
      "Epoch [48/50], Batch [140/168], Loss: 0.08826712518930435\n",
      "Epoch [48/50], Batch [150/168], Loss: 0.01408443320542574\n",
      "Epoch [48/50], Batch [160/168], Loss: 0.02025565132498741\n",
      "Epoch [48/50], Validation Loss: 0.06605842572382906\n",
      "Epoch [49/50], Batch [0/168], Loss: 0.04667234048247337\n",
      "Epoch [49/50], Batch [10/168], Loss: 0.04487305507063866\n",
      "Epoch [49/50], Batch [20/168], Loss: 0.12461342662572861\n",
      "Epoch [49/50], Batch [30/168], Loss: 0.05255751684308052\n",
      "Epoch [49/50], Batch [40/168], Loss: 0.03357073292136192\n",
      "Epoch [49/50], Batch [50/168], Loss: 0.005412793252617121\n",
      "Epoch [49/50], Batch [60/168], Loss: 0.07182705402374268\n",
      "Epoch [49/50], Batch [70/168], Loss: 0.042533066123723984\n",
      "Epoch [49/50], Batch [80/168], Loss: 0.06772750616073608\n",
      "Epoch [49/50], Batch [90/168], Loss: 0.04272279515862465\n",
      "Epoch [49/50], Batch [100/168], Loss: 0.061276648193597794\n",
      "Epoch [49/50], Batch [110/168], Loss: 0.08669102936983109\n",
      "Epoch [49/50], Batch [120/168], Loss: 0.023881295695900917\n",
      "Epoch [49/50], Batch [130/168], Loss: 0.06192273274064064\n",
      "Epoch [49/50], Batch [140/168], Loss: 0.08825966715812683\n",
      "Epoch [49/50], Batch [150/168], Loss: 0.014082220382988453\n",
      "Epoch [49/50], Batch [160/168], Loss: 0.020254837349057198\n",
      "Epoch [49/50], Validation Loss: 0.0660992280156775\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrain the model using the best hyperparameters found during the search\n",
    "best_model = StackedLSTMWithAttention(input_size, best_hyperparameters['hidden_size'],\n",
    "                                      best_hyperparameters['num_layers'],\n",
    "                                      attention_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_hyperparameters['lr'])\n",
    "\n",
    "train_losses = []  # Store training losses for plotting\n",
    "valid_losses = []  # Store validation losses for plotting\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Reshape data to (batch_size, sequence_length, input_size)\n",
    "        data = data.view(-1, 526, 64)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = best_model(data)\n",
    "\n",
    "        # Flatten the predictions and targets for loss calculation\n",
    "        outputs = outputs.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the training loss\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Print batch loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Validation loop\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for data, target in valid_loader:\n",
    "            # Reshape data to (batch_size, sequence_length, input_size)\n",
    "            data = data.view(-1, 526, 64)\n",
    "\n",
    "            outputs = best_model(data)\n",
    "            outputs = outputs.view(-1)\n",
    "            target = target.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(valid_loader)\n",
    "        valid_losses.append(average_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Validation Loss: {average_loss}\")\n",
    "\n",
    "# Plot the training and validation losses over epochs\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the model predictions against true target values\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in valid_loader:\n",
    "        # Reshape data to (batch_size, sequence_length, input_size)\n",
    "        data = data.view(-1, 526, 64)\n",
    "\n",
    "        outputs = best_model(data)\n",
    "        predicted_values = outputs.view(-1).cpu().numpy()\n",
    "        true_values = target.view(-1).cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        #plt.plot(true_values, label='True Values')\n",
    "        plt.plot(predicted_values, label='Predicted Values')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('True vs. Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        break  # Only visualize the first batch of data from the validation loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
